[{"title":"Autostitch is witchcraft","content":"<p>Arthur C Clarke once said that <q>any sufficiently advanced technology is indistinguishable from magic<\/q>.  I always knew that some day something would come along that my brain just couldn't comprehend, I didn't realise that would happen before I was thirty.<\/p>\n\n<p>Stitching panoramas together is something we've all tried to do.  I've in the past spent some unproductive hours in Photoshop trying to scale, skew and match snaps together myself.  I've also spent hours adding 'control points' to images in various shareware applications, all with middling results.<\/p>\n\n<p>However, I appear to have been missing out on a big revolution. Nearly five years ago M. Brown and D. G. Lowe presented a very interesting paper that <a href=\"http:\/\/www.cs.ubc.ca\/~mbrown\/papers\/iccv2003.pdf\">you can read here<\/a> (PDF).  They came up with an algorithm called 'Autostitch' that had some interesting properties - given a large set of photos it can identify which of them have common features and stitch them together on its own - without any user input at all!<\/p>\n\n<p>Frankly I was suspicious that it would work, but I gamely downloaded the demo of <a href=\"http:\/\/www.michaelhanscom.com\/eclecticism\/2006\/04\/05\/calico-autostitch-for-mac-os-x\/\">Calico, a Mac app that implements Autostitch<\/a>.<\/p>\n\n<p>I was amazed by the results enough that I got the full version almost immediately.  The first sequence of photos I gave it was the following:<\/p>\n\n<div class=\"figure\"><a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/2575286811\/\" title=\"Larger version of the photos, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3263\/2575286811_ecbcd8e867.jpg\" width=\"500\" height=\"80\" alt=\"Bukhara panorama - the raw photos\"\/><\/a>\n<p class=\"caption\">A typical set of overlapping photos<\/p>\n<\/div>\n\n<p>With basically no intervention from me aside from selecting the photos in a file dialog, Calico generated the following:<\/p>\n\n<div class=\"figure\"><a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/2576115498\/\" title=\"Larger version of the photo, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3039\/2576115498_4cc989ca2f.jpg\" width=\"500\" height=\"157\" alt=\"Bukhara panorama - the autostitch output\"\/><\/a>\n<p class=\"caption\">The raw output from Autostitch<\/p>\n<\/div>\n\n<p>Pretty impressive stuff!  A bit of cropping in photoshop and it tidied up pretty well:<\/p>\n\n<div class=\"figure\"><a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/2576118350\/\" title=\"Larger version of the photo, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3278\/2576118350_1f7cfd02b7.jpg\" width=\"500\" height=\"140\" alt=\"Bukhara panorama - cropped and filled in\"\/><\/a>\n<p class=\"caption\">Cleaned up a bit and nicely cropped<\/p>\n<\/div>\n\n<p>I can sense that I'm going to spend a lot of time on holiday in future standing in one spot slowly rotating with my camera!<\/p>\n\n<p>A couple more shots I've done, to show how good the results are.  I really can't stress enough how simple the software is - it's a couple of clicks and bingo, a nice high-quality panorama pops out.<\/p>\n\n<div class=\"figure\">\n<a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/2576443000\/\" title=\"Khiva rooftop panorama by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3045\/2576443000_909ceb5d8f.jpg\" width=\"500\" height=\"98\" alt=\"Khiva rooftop panorama\"\/><\/a>\n<\/div>\n\n<div class=\"figure\">\n<a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/2575618313\/\" title=\"Bukhara mosque panorama by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3040\/2575618313_a367fe58c2.jpg\" width=\"500\" height=\"121\" alt=\"Bukhara mosque panorama\"\/><\/a>\n<\/div>","created":"2008-06-13 20:04:00","url":"autostitch-is-witchcraft","tags":["photography"],"comments":[{"name":"Russell","website":"http:\/\/www.rdjs.co.uk","comment":"That quote is great!\r\n\"any sufficiently advanced technology is indistinguishable from magic\"\r\nI always wanted to know how to create a panorama... all I need to do now is save up for that mac.","created":"2008-07-29 20:27:42"}]},{"title":"The iPhone 3G vs the Nokia N95","content":"<p>A few days ago, Apple launched their much-anticipated second revision of the iPhone.  Key amongst its new features are 3G (HSPDA) connectivity and a GPS unit.<\/p>\n\n<div class=\"figure\">\n<a href=\"http:\/\/flickr.com\/photos\/anwer\/2567778438\" title=\"Larger version of the photo, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3120\/2567778438_c25718cfe6.jpg\" width=\"480\" height=\"270\" alt=\"Steve Jobs announcing the 3G iPhone\"\/><\/a>\n<p class=\"caption\">Steve Jobs announcing the 3G iPhone<\/p>\n<\/div>\n\n<p>As a loyal Nokia user as well as a Mac enthusiast, my loyalty was therefore pretty divided.  I was saved from flocking towards the first generation iPhone's hype machine by a reflex reaction of 'if it's not got 3G it can't be any good' and a recent iPod purchase to be bitter about.<\/p>\n\n<p>I've been happy enough with my iPod and N95 sitting next to each other in my pocket, but the question I've been mulling over the last few days is, would I be happier with one iPhone instead?<\/p>\n\n<p>I've come to the conclusion that no, the iPhone is not yet right for me, for the following reasons:<\/p>\n\n<ul>\n<li>\n<p><strong>Apple 'approval' for third-party apps<\/strong><\/p>\n<p>Apple are launching an SDK for iPhone but are insisting that they get to digitally sign every app that runs on it.  The Symbian platform my N95 runs is pretty open - any hobbyist can decide to write a bit of software for it and make it available for download. This has given me access to so many quirky little applications, from Emulators to diet trackers to location sensors - I really can't see the same ecosystem flourishing around iPhone.<\/p>\n<\/li>\n<li>\n<p><strong>No MMS<\/strong><\/p>\n<p>This is a fairly bizarre omission for a modern cellphone.  Admittedly I can count the number of MMS I've sent this year on one hand, but I have sent some and I've received a few as well.  I can only presume that people in the US don't use the things, but seriously Apple, WTF?<\/p>\n<\/li>\n<li>\n<p><strong>Mediocre camera<\/strong><\/p>\n<p>2 Megapixels is ok, but I want my phone to be able to fill the breech when I've forgotten to bring my point-and-shoot camera out with me the way my 5Mpix Zeiss-lensed N95 does.  The lack of a user-facing camera has set the cause of video calls\/chat back a few years but is less vexing.<\/p>\n<\/li>\n<li>\n<p><strong>No modem functionality<\/strong><\/p>\n<p>It seems that if you own an iPhone, you have a dial-up device capable of connecting to the Internet at near-broadband speeds, but no way of using that via laptop.  In short, that's retarded.<\/p>\n<p>When I go away I use my N95 with my MacBook Pro and browse the web at a pretty respectable 1.4Mbit - the idea that an Apple mobile is less capable of talking to my Mac than my Nokia phone is makes me cringe.<\/p>\n<\/li>\n<\/ul>\n\n<p>This might not seem like much, but I can't bring myself to take a step backwards and get an iPhone that can't do some of the things my existing setup does.<\/p>\n\n<p>It's my fond hope that the third-party iPhone development community flourishes, however, and manages to fill in all these gaps well enough.  I'm unsure how much the API exposes and whether MMS etc. are within the realms of realistic hope, but you never know.<\/p>\n\n<div class=\"figure\">\n<a href=\"http:\/\/flickr.com\/photos\/n96\/2261041913\/\" title=\"Larger version of the photo, on Flickr\"><img src=\"http:\/\/farm3.static.flickr.com\/2351\/2261041913_c98cb1a773.jpg\" width=\"500\" height=\"341\" alt=\"N96 product image\"\/><\/a>\n<p class=\"caption\">The N96, coming soon<\/p>\n<\/div>\n\n<p>In the meantime the N96 is out around August time, and that's what I'm pinning my hopes on.  It does everything my N95 does, and does it in a neater casing and on faster hardware.<\/p>","created":"2008-06-12 12:33:00","url":"the-iphone-3g-vs-the-nokia-n95","tags":["mobile","apple"],"comments":[{"name":"Phil","website":"","comment":"12th June 2008 Ciaran: I really can't see the same ecosystem flourishing around iPhone.\r\n\r\n24th April 2009 Apple: 1 billion downloads from the iPhone Appstore.\r\n\r\nFlourish, I think it has :)","created":"2009-04-24 16:16:59"},{"name":"Simon Harris","website":"http:\/\/pointbeing.net\/","comment":"I'd hardly call the Appstore an ecosystem, Phil. It's part of a benign-but-for-how-long dictatorship designed to make damn sure that people - despite spending hundreds of pounds on some piece of tatty hardware - aren't allowed to do anything with it without Apple's approval. And quite frankly, sod that.","created":"2009-06-14 12:12:42"},{"name":"Russell","website":"http:\/\/rdjs.co.uk","comment":"The iPhone is tatty hardware?","created":"2009-06-15 11:17:15"},{"name":"Ciaran McNulty","website":"http:\/\/ciaranmcnulty.com","comment":"Simon - I've found the Apple Store user experience to be about a million times better than my experiences with Nokia and S60 apps, but you're right in that it's frustrating to have to jailbreak the phone to get 'non-Apple-approved' applications on there.","created":"2009-06-15 11:29:44"}]},{"title":"Fire Eagle - Yahoo's location service","content":"<p>Yahoo! recently launched a beta of their <a href=\"http:\/\/fireeagle.yahoo.com\">new Fire Eagle service<\/a> and thanks to the kindness of <a href=\"http:\/\/pointbeing.net\">Simon<\/a> I managed to snag an invite code.<\/p>\n\n<div class=\"figure\">\n<a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/2485972137\/\" title=\"Larger version of the screengrab, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3157\/2485972137_846e936eea.jpg\" width=\"500\" height=\"403\" alt=\"Screen grab of the main Fire Eagle page\"\/><\/a>\n<p class=\"caption\">The main Fire Eagle page<\/p>\n<\/div>\n\n<p>The simple concept behind Fire Eagle is that it's a web service that stores your geographical location.  That's it. There are no other fancypants features to get in the way of the central message, everything else is left as an exercise for third parties.<\/p>\n\n<p>Like Twitter, Fire Eagle straddles a blurry line between a website and an API.  The site itself offers very little - a box to write your location in, and a map showing the last known location (see picture).<\/p>\n\n<p>In my eyes, the real strength of Fire Eagle is the way it treats third-party applications.  An application can be registered with Fire Eagle using <a href=\"http:\/\/en.wikipedia.org\/wiki\/OAuth\">OAuth<\/a>, which means applications can set and read your location without you having to trust them with your Fire Eagle login details.<\/p>\n\n<p>Because you've not given the application your full login details, its access to your data can be revoked at any time.  I can revoke a service's access to my data, or set the accuracy of the data it recieves to something much coarser (for example, I can say a particular service can only read my location to City level).<\/p>\n\n<div class=\"figure\">\n<a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/2486911244\/\" title=\"Larger version of the screengrab, on Flickr\"><img src=\"http:\/\/farm3.static.flickr.com\/2390\/2486911244_16957af614.jpg\" width=\"500\" height=\"379\" alt=\"Screen grab of the Fire Eagle application permissions page\"\/><\/a>\n<p class=\"caption\">Fire Eagle application permissions page<\/p>\n<\/div>\n\n<p>Because of this flexibility, Fire Eagle has almost overnight become the de facto platform for services who want to leverage user locations.  The clear and rich API has meant most of the existing web-based 'where am I' services have very rapidly knocked up pipes to and from their databases into Fire Eagle, and a whole ecosystem of services built on top of it is starting to thrive.<\/p>\n\n<p>A good example of a service that feeds to Fire Eagle is <a href=\"http:\/\/www.navizon.com\/\">Navizon<\/a> who offer a free Symbian client that regularly updates your position from your handset based on cell tower ID, local wi-fi hotspots and GPS, if available on the handset. Walking around all day with Navizon running felt a bit strange (and certainly ran my battery down).  Although I knew that only I could log into Fire Eagle and see my location exactly, my trip around London is still sitting on some Yahoo! server somewhere.<\/p>\n\n<p>As a test of how clean the API was, I tried to knock up a bit of code that took my location and displayed it online.  All in all it took about 30 mins to convert their PHP example code with something I was happy with.  I may add it to my site at some point - obviously I would want to restrict it to a coarse location if I'm publishing it publicly!<\/p>","created":"2008-05-12 18:44:00","url":"fire-eagle-yahoos-location-service","tags":["mobile","web"]},{"title":"New blog","content":"<p>I've been blogging about personal stuff on LiveJournal for a few years now, but I've become more and more disillusioned with using third-party blogging, and the 'audience' there isn't that interested in anything technical.<\/p>\n\n<p>Because of that I've decided to start blogging about tech issues here on my own site starting today - I hope to add a few more bloggish features like tags\/comments\/permalinks, but frankly I figured I'd just get obsessed making that work and not write anything.<\/p>","created":"2008-05-12 13:24:00","url":"new-blog"},{"title":"A new comments system","content":"<p>I've made a little comments system for this blog, and it gave me a chance to look a bit more into <a href=\"http:\/\/www.phpdoctrine.org\/\">Doctrine<\/a>.<\/p>\n\n<p>I keep meaning to blog about how I put this site together, but for now I'll just say that it uses Zend Framework for MVC, with Doctrine for the ORM.  To implement the comments form I used <a href=\"http:\/\/codeutopia.net\/blog\/2008\/06\/02\/autogenerating-forms-from-doctrine-models\/\">a great bit of code from CodeUtopia<\/a>, written by <span class=\"vcard\"><a href=\"http:\/\/codeutopia.net\/blog\/about\/\" class=\"url fn\">Jani Hartikainen<\/a> (a.k.a. 'zomg' on IRC)<\/span> that ties together Doctrine objects and Zend_Form in quite a nice way.<\/p>\n\n<p>I'm hoping to do a quite simple tutorial about how to implement a small blog, but that's for another time when I'm not busy revising for my ZCE!<\/p>","created":"2008-07-10 16:06:23","url":"a-new-comments-system","tags":["php","web"]},{"title":"Some thoughts on Zend PHP5 Certification","content":"\n<div class=\"figure narrow\">\n<img src=\"http:\/\/www.zend.com\/images\/training\/zce_logo.gif\" alt=\"ZCE logo\" width=\"73\" height=\"47\" \/>\n<\/div>\n\n<p>I qualified as a <abbr title=\"Zend Certified Engineer\">ZCE<\/abbr> yesterday. I guess the only tangible benefits of this is I get to write the letters on my CV \/ business cards and use this nifty logo, but I found the overall process of the certification pretty worthwhile.<\/p>\n\n<p>The thing that's put me off certification in the past is the imagined cost, in terms of both time and money. I thought there'd be a dreary course covering things I already knew, and I'd be paying a premium for the privilege.  In fact, I was completely wrong!<\/p>\n\n<p>Once I looked into it, I found that although <a href=\"http:\/\/www.zend.com\/en\/store\/php-training\/certification\">Zend offer a grueling 18-hour course for about \u00a3800<\/a> it's not a requirement for the certification itself, you can <a href=\"http:\/\/www.zend.com\/en\/store\/php-certification\/exam-voucher\/\">buy an exam voucher for about \u00a3100<\/a> and just turn up and take the test, so I did.<\/p>\n\n<p>Well... OK, not quite.  For a start, I didn't pay for it - <a href=\"http:\/\/www.propertymall.com\">work<\/a> kindly agreed to.  Secondly, I wanted a bit of an idea of what the exam was like, so my first step was to buy a set of <a href=\"http:\/\/www.zend.com\/en\/store\/php-certification\/online-practice-testing\">5 practice exams for just over a tenner<\/a> and have a go at one of them.<\/p>\n\n<p>Also, to get an idea of what subjects would be covered, I also bought the <a href=\"http:\/\/www.amazon.co.uk\/architects-Zend-Certification-Study-Guide\/dp\/0973862149\/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1216292243&amp;sr=8-1\">study guide published by php|architect<\/a>.  I'm not sure how much I'd recommend this book.  For a start, it doesn't cover everything the exam will but does have a few gems of wisdom in it, so it's worth picking up if you find it cheaply.<\/p>\n\n<p>Thankfully I passed the first practice exam, and got a nice breakdown of which subject areas I'd done well in and which I'd done badly.  With that as a basis, I knew which areas I was weak on and could try and study up (I also knew that finally committing some of the array and string functions to memory would do me good).<\/p>\n\n<p>In the end I did much less revision than I'd expected and on the day was a bit nervous, but the whole thing was an anticlimax.  It took place in the meeting room of a smallish office using a smallish Dell laptop, and took much less time than I'd expected.  After I'd finished early and checked all my answers I got bored and clicked 'end exam' and a little pop-up told me I'd passed - no fanfare, no fireworks, no ticker-tape parade?  I was given a small laser-printed sheet of paper to prove I'd passed.<\/p>\n\n<p>And the value of the exam?  Well, next time I'm recruiting and see ZCE on a CV I'll know that the applicant has a strong grasp of the most important areas of PHP. Also, studying for the exam did teach me about a lot of the 'nitty gritty' areas of PHP I'd not paid much attention to before.<\/p>\n\n<p>There was another reward too, and that was reassurance that I'm ok at my job.  That may sound silly but aside from a brief 2-year period, I've spent my career at the top of the pile in small teams.  When you don't have senior people around to measure yourself against you have no way of knowing how well you're doing.  Having a bar like the ZCE to aim for, even if it's a relatively low one, let me reassure myself that I'm not too far behind.<\/p>\n\n<p>So what next?  Zend are supposedly going to be doing a Zend Framework certification at some point, so I'll be keeping an eye on that quite closely.  There's no 'Advanced ZCE' to aim for so maybe I'll take a look at the <a href=\"http:\/\/www.mysql.com\/certification\/\">various MySQL certifications<\/a> and see how I can do on that side of things.<\/p>\n\n<p>And of course, I'll report back in future if it turns out that the ZCE actually helps my career in any tangible way!<\/p>","created":"2008-07-17 12:15:24","url":"some-thoughts-on-zend-php5-certification","tags":["php"]},{"title":"Cracking a monkey puzzle","content":"<div class=\"figure narrow\">\n    <a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/2691592257\/\" title=\"The Guardian Crossword on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3262\/2691592257_e796826194_m.jpg\" width=\"180\" height=\"240\" alt=\"The Guardian Crossword\" \/><\/a>\n<\/div>\n\n<p>Today saw <a href=\"http:\/\/fifteensquared.net\/2008\/07\/22\/guardian-24447araucaria-in-hot-water\/\">my debut over at Fifteensquared<\/a> as one of their daily crossword blogging team.  About once a week I'll be blogging a solution for the Guardian crossword, hopefully reasonably early on the day of publication.<\/p>\n\n<p>It's been an interesting experience.  On a normal day I'll buy the Guardian in the morning and do a couple of clues on the way in to work, then have it sitting on my desk for an occasional glance through the morning.  When I have a free lunch I'll finish it off, usually with a bit of help from <a href=\"http:\/\/www.paulgoodwin.com\">Paul<\/a> if he's online.  I hadn't realised how much pressure I'd be adding to myself by committing to solve it on a certain day.<\/p>\n\n<p>I woke up this morning in a vague panic about whether I'd manage to fit it in. When I got the paper at my local corner shop, I turned straight to the crossword page and my heart sank - today's setter was <a href=\"http:\/\/en.wikipedia.org\/wiki\/John_Galbraith_Graham\">Araucaria<\/a>, possibly the hardest setter the Guardian use and certainly the most inventive.  I normally consider it a bit of a triumph to finish his puzzles by the end of the day, let alone in the morning.<\/p>\n\n<p>I calmed down once on the train and cracking on with the puzzle - it seemed far easier than normal, or perhaps I was concentrating a lot harder. I managed about 2\/3 of it on the way into work, and a bit of googling once at my desk polished it off.  I fee like I've dodged a bit of a bullet for now, but I'm painfully aware that I'll have to do the whole thing again pretty soon<\/p>\n\n<p>What have I got myself into?<\/p>","created":"2008-07-22 10:57:18","url":"cracking-a-monkey-puzzle","comments":[{"name":"Simon","website":"http:\/\/pointbeing.net","comment":"Too cryptic for me :) What's the monkey reference, I wonder?","created":"2008-07-22 22:35:16"},{"name":"Ciaran","website":"http:\/\/ciaranmcnulty.com","comment":"Araucaria is the Monkey Puzzle Tree","created":"2008-07-24 16:54:56"}]},{"title":"Optimising a site for iPhone","content":"<div class=\"figure narrow\">\n    <a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/2709794945\/\" title=\"Screengrab of my site on iPhone, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3256\/2709794945_dfc58b0dcf_m.jpg\" width=\"160\" height=\"240\" alt=\"Screengrab of my site on iPhone\" \/><\/a>\n    <p class=\"caption\">The unmodified site<\/p>\n<\/div>\n\n<p>The first thing I should probably mention is that yes, despite <a href=\"http:\/\/ciaranmcnulty.com\/blog\/2008\/06\/the-iphone-3g-vs-the-nokia-n95\">saying I wouldn't<\/a>, I got an iPhone 3G relatively soon after release.  I'll skip the reasons why for now, that's for a future posting. Naturally the first thing I did upon getting my iPhone was to plug in my own site's URL into the browser and see how it did - you can see the result in the screengrab.<\/p>\n\n<p>You know what - it's not bad.  The site looks roughly as it should, and with a bit of zooming and panning around all the content is accessible. However, on first load the text isn't really legible and it's not making the best usage of the limited screen space on the iPhone.  Also, the large header graphic makes loading a bit strenuous over an EDGE connection when I'm not in 3G coverage.<\/p>\n\n<p>Simon has been blogging recently (<a href=\"http:\/\/pointbeing.net\/weblog\/2008\/06\/mobilising-a-website-part-1-the-problem.html\">here<\/a> and <a href=\"http:\/\/pointbeing.net\/weblog\/2008\/07\/mobilising-a-website-part-2-strategies.html\">here<\/a>), about 'mobilising' websites (and has written a good article on the subject for <a href=\"http:\/\/phparch.com\">php|architect<\/a>) so it's something I've been thinking about lately and I decided to see what it would take to improve the way the page was rendered on iPhone.<\/p>\n\n<p>It's important to realise that this is a very niche pursuit.  What Simon's series of articles is talking about is enabling a site to be viewed from <em>any<\/em> mobile device, which is a very different kettle of fish from just making it work better on a fancy-pants iPhone - this is really just for my own edification.<\/p>\n\n<p>So, the first thing to do was to look through the <a href=\"http:\/\/developer.apple.com\/documentation\/AppleApplications\/Reference\/SafariWebContent\/Introduction\/chapter_1_section_1.html#\/\/apple_ref\/doc\/uid\/TP40002079-SW1\">Apple documentation on iPhone web development<\/a>, which I found was well written and clearly laid out.<\/p>\n\n<p>The first thing I wanted to do was eliminate a lot of the whitespace on the right of the page.  Adding iPhone-only CSS is done using a CSS3 mechanism called <a href=\"http:\/\/www.w3.org\/TR\/css3-mediaqueries\/\">Media Queries<\/a>.  It's not an Apple-specific technology, it's from the <abbr title=\"World Wide Web Consortium\">W3C<\/abbr> and is a generic way of applying complex rules as to which stylesheet(s) a specific device should use.<\/p>\n\n<p>I wrote a phone-specific stylesheet that normalised the column widths to the same as the content area and removed the header image.  The extra markup in the <tt>HEAD<\/tt> of my document looks like this:<\/p>\n\n<p><code class=\"html\">\n&lt;link rel=\"stylesheet\" media=\"only screen and (max-device-width: 480px)\" href=\"\/css\/iphone.css\" \/>\n<\/code><\/p>\n\n<div class=\"figure narrow\">\n    <a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/2709902805\/\" title=\"My site on iPhone (better) by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3013\/2709902805_55a284eab1_m.jpg\" width=\"160\" height=\"240\" alt=\"My site on iPhone (better)\" \/><\/a>\n    <p class=\"caption\">Reduced to 1 column<\/p>\n<\/div>\n\n<p>This says the specified stylesheet should only apply to devices that support Media Queries, consider themselves 'screen' devices, and have a screen width of less than 480 pixels.  This obviously applies to the iPhone, but hopefully more and more user agents will support Media Queries - they're a very powerful mechanism for specifying how a site should display on devices with a hugely varied range of capabilities.<\/p>\n\n<p>With the new CSS applied for iPhone, the site started to take shape.  The content was all in a nice vertical column, but the phone still wasn't displaying the page zoomed-in enough.<\/p>\n\n<p>One solution would be to change all of the page's sizings in CSS so that it fitted into the iPhone's default 980px-wide zoom level, but this seemed a bit messy as the extra CSS was so far fairly small and clean.<\/p>\n\n<p>Apple's solution to this a <tt>META<\/tt> tag to the <tt>HEAD<\/tt> of your document that specifies what zoom level to use on load.  My content was 516px wide so mine looks like this:<\/p>\n\n<p><code class=\"html\">\n&lt;meta name=\"viewport\" content=\"width=516\" \/&gt;\n<\/code><\/p>\n\n<p>You can do a lot with this <tt>META<\/tt> tag, such a disabling user zoom, but frankly I think it's a horrible solution. <\/p>\n\n<p>It lacks the granularity of something like Media Queries, so you're left specifying one common viewport for all 'viewport-aware' devices.  Hopefully there will be some way of specifying viewport dimensions in the stylesheet in future, or that I've missed something.<\/p>\n\n\n<div class=\"figure narrow\">\n    <a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/2710607314\/\" title=\"My site on iPhone (optimised) by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3189\/2710607314_e023043dd5_m.jpg\" width=\"160\" height=\"240\" alt=\"My site on iPhone (optimised)\" \/><\/a>\n    <p class=\"caption\">The final version<\/p>\n<\/div>\n\n<p>With this extra bit of information, Safari is now able to render the site in a much more usable form.  The single-column means only a vertical scroll is needed, with the sidebar items relegated to the bottom of the screen.  The text is legible from the offset, and the loading times are severely reduced.<\/p>\n\n<p>Obviously this is only a simple example, but hopefully it illustrates how a couple of simple steps that you can make fairly harmlessly to your markup, can vastly improve the browsing experience for the iPhone users amongst your audience.<\/p>  \n\n<p>Whether it's worth the effort for your site is a cost\/benefit analysis you'll need to make for yourself, but I strongly believe that technologies like Media Queries will become more and more useful in future, as the current separation between 'computer' and 'mobile' browsers breaks down into a continuous spectrum of PCs, tablets, PDAs and tiny embedded browsers with a massive range of capabilities.<\/p>","created":"2008-07-28 13:41:50","url":"optimising-a-site-for-iphone","tags":["mobile","web","apple"],"comments":[{"name":"kelly","website":"http:\/\/kellybaker.ca","comment":" Great post. I've been looking around for an hour trying to find this info. Thanks for sharing!","created":"2008-09-04 17:16:22"}]},{"title":"Delivering pages as PDF using PHP","content":"<p>HTML is great.  It's the lingua franca of the web, and a fantastic format for exchange of hyperlinked information. However, it has its drawbacks - It typically relies on multiple external files, different browsers interpret it in different ways, and printing it is a bit of a minefield, even with the limited print CSS currently available.<\/p>\n\n<p>So, sometimes it makes sense to present documents as a PDF as well.  I've done so on this very site, with <a href=\"http:\/\/ciaranmcnulty.com\/cv\/\">my CV<\/a>, after finding that most recruitment sites won't except an HTML document, and recruiters just get confused when you attach one to an email (or send them a hyperlink).<\/p>\n\n<p>The component I use is called <a href=\"http:\/\/www.digitaljunkies.ca\/dompdf\/\">dompdf<\/a>.  At its heart it is an HTML->PDF converter written completely in PHP, and is pretty simple to use. The code to convert some HTML to a PDF looks something like this:<\/p>\n\n<div class=\"php\">\n<code><span style=\"color: #000000\">\n<span style=\"color: #0000BB\">&lt;?php\n<br \/>\n<br \/><\/span><span style=\"color: #FF8000\">\/\/&#160;include&#160;in&#160;the&#160;dompdf&#160;library\n\n<br \/><\/span><span style=\"color: #007700\">require_once(<\/span><span style=\"color: #DD0000\">'dompdf_config.inc.php'<\/span><span style=\"color: #007700\">);\n<br \/><\/span><span style=\"color: #0000BB\">spl_autoload_register<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #DD0000\">'DOMPDF_autoload'<\/span><span style=\"color: #007700\">);\n<br \/>\n<br \/><\/span><span style=\"color: #FF8000\">\/\/&#160;instance&#160;dompdf\n<br \/><\/span><span style=\"color: #0000BB\">$dompdf&#160;<\/span><span style=\"color: #007700\">=&#160;new&#160;<\/span><span style=\"color: #0000BB\">DomPDF<\/span><span style=\"color: #007700\">();\n<br \/><\/span><span style=\"color: #0000BB\">$dompdf<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">set_paper<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #DD0000\">'a4'<\/span><span style=\"color: #007700\">);\n\n<br \/>\n<br \/><\/span><span style=\"color: #FF8000\">\/\/&#160;tell&#160;the&#160;user-agent&#160;to&#160;expect&#160;a&#160;PDF\n<br \/><\/span><span style=\"color: #0000BB\">header<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #DD0000\">'Content-type:&#160;application\/pdf'<\/span><span style=\"color: #007700\">);\n<br \/>\n<br \/><\/span><span style=\"color: #FF8000\">\/\/&#160;load&#160;the&#160;HTML,&#160;convert&#160;it&#160;to&#160;PDF&#160;and&#160;output\n\n<br \/><\/span><span style=\"color: #0000BB\">$src&#160;<\/span><span style=\"color: #007700\">=&#160;<\/span><span style=\"color: #0000BB\">file_get_contents<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #DD0000\">'document.html'<\/span><span style=\"color: #007700\">);\n<br \/><\/span><span style=\"color: #0000BB\">$dompdf<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">load_html<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$src<\/span><span style=\"color: #007700\">);\n<br \/><\/span><span style=\"color: #0000BB\">$dompdf<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">render<\/span><span style=\"color: #007700\">();\n<br \/>echo&#160;<\/span><span style=\"color: #0000BB\">$dompdf<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">output<\/span><span style=\"color: #007700\">();\n\n<br \/>\n<br \/><\/span><span style=\"color: #0000BB\">?&gt;<\/span>\n<\/span>\n<\/code><\/div>\n\n<p>Fairly straightforward, but there are some issues with dompdf that complicate the matter a fair bit.<\/p>\n\n<p>In short, dompdf is old.   <a href=\"http:\/\/www.digitaljunkies.ca\/dompdf\/#item_1\">Its last release was two years ago<\/a> and there's not much sign of a new one.  This means that <a href=\"http:\/\/www.digitaljunkies.ca\/dompdf\/css21.php\">its CSS support has a lot of holes<\/a> so just throwing your existing HTML at dompdf isn't going to produce fantastic results.<\/p>\n\n<p>(As an aside, if you have a huge budget it's worth looking at <a href=\"http:\/\/www.princexml.com\/\">Prince<\/a>.  Prince is a similar product that has incredible CSS support, but costs a fortune while dompdf is free.)<\/p>\n\n<p>One option would be to write your HTML pages in a fairly old, table-based style so that they could be rendered properly by dompdf, but my preferred solution is to add a conversion step that takes the nice, semantic XHTML I've written my CV in and convert it into the sort of HTML that dompdf likes on the fly, using XSL.<\/p>\n\n<p>If you're unfamiliar with XSL there's <a href=\"http:\/\/www.w3schools.com\/XSL\/xsl_intro.asp\">a brief introduction here<\/a>, but essentially an XSL template is a template for converting XML documents (such as our XHTML original) into either XML, HTML or string outputs.  It essentially changes the last block of code into something like the following:<\/p>\n\n<div class=\"php\">\n<code><span style=\"color: #000000\">\n<span style=\"color: #0000BB\">&lt;?php\n\n<br \/>\n<br \/><\/span><span style=\"color: #FF8000\">\/\/&#160;load&#160;in&#160;the&#160;HTML&#160;and&#160;the&#160;XSL&#160;into&#160;DOM&#160;objects\n<br \/><\/span><span style=\"color: #0000BB\">$htmlDom&#160;<\/span><span style=\"color: #007700\">=&#160;<\/span><span style=\"color: #0000BB\">DomDocument<\/span><span style=\"color: #007700\">::<\/span><span style=\"color: #0000BB\">load<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #DD0000\">'document.html'<\/span><span style=\"color: #007700\">);\n\n<br \/><\/span><span style=\"color: #0000BB\">$styleDom&#160;<\/span><span style=\"color: #007700\">=&#160;<\/span><span style=\"color: #0000BB\">DomDocument<\/span><span style=\"color: #007700\">::<\/span><span style=\"color: #0000BB\">load<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #DD0000\">'convert.xsl'<\/span><span style=\"color: #007700\">);\n<br \/>\n<br \/><\/span><span style=\"color: #FF8000\">\/\/&#160;instance&#160;an&#160;XSLT&#160;processor&#160;and&#160;give&#160;it&#160;the&#160;stylesheet\n\n<br \/><\/span><span style=\"color: #0000BB\">$xslProc&#160;<\/span><span style=\"color: #007700\">=&#160;new&#160;<\/span><span style=\"color: #0000BB\">XSLTProcessor<\/span><span style=\"color: #007700\">();\n<br \/><\/span><span style=\"color: #0000BB\">$xslProc<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">importStylesheet<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$styleDom<\/span><span style=\"color: #007700\">);\n<br \/>\n<br \/><\/span><span style=\"color: #FF8000\">\/\/&#160;apply&#160;the&#160;XSL&#160;to&#160;the&#160;XHTML&#160;to&#160;get&#160;the&#160;old-style&#160;HTML\n\n<br \/><\/span><span style=\"color: #0000BB\">$src&#160;<\/span><span style=\"color: #007700\">=&#160;<\/span><span style=\"color: #0000BB\">$xslProc<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">transformToXML<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$htmlDom<\/span><span style=\"color: #007700\">);\n<br \/>\n<br \/><\/span><span style=\"color: #FF8000\">\/\/&#160;render&#160;the&#160;old-style&#160;HTML\n<br \/><\/span><span style=\"color: #0000BB\">$dompdf<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">load_html<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$src<\/span><span style=\"color: #007700\">);\n\n<br \/><\/span><span style=\"color: #0000BB\">$dompdf<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">render<\/span><span style=\"color: #007700\">();\n<br \/>echo&#160;<\/span><span style=\"color: #0000BB\">$dompdf<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">output<\/span><span style=\"color: #007700\">();\n<br \/>\n<br \/><\/span><span style=\"color: #0000BB\">?&gt;<\/span>\n<\/span>\n<\/code><\/div>\n\n<p>The task therefore is to write an XSL that converts your 'old' format to your 'new' format.  That's a bit tricker than it sounds so Ill take you through what I've done for my cv.  The starting point, really, is to do nothing.  The XSL for 'do nothing' looks like this:<\/p>\n\n<div class=\"xml\"><pre>&lt;xsl:stylesheet version=&quot;1.0&quot; \n    xmlns:xsl=&quot;http:\/\/www.w3.org\/1999\/XSL\/Transform&quot;&gt;\n\n    &lt;xsl:output method=&quot;html&quot; encoding=&quot;utf-8&quot; \n        omit-xml-declaration=&quot;yes&quot; \/&gt;\n  \n    &lt;xsl:template match=&quot;node()|@*&quot;&gt;\n        &lt;xsl:copy&gt;\n            &lt;xsl:apply-templates select=&quot;@*|node()&quot;\/&gt;\n        &lt;\/xsl:copy&gt;\n    &lt;\/xsl:template&gt;\n  \n&lt;\/xsl:stylesheet&gt;<\/pre><\/div>\n\n<p>The <tt>xsl:stylesheet<\/tt> and <tt>xsl:output<\/tt> nodes just specify that this is an XSL and that we want to output some HTML.  The 'engine' of XSL is the <tt>xsl:template<\/tt> node - an <tt>xsl:template<\/tt> specifies that for a certain node in the source document, a certain output should be produced.<\/p>\n\n<p>This template essentially says that it matches any node in the source document, and that the appropriate behaviour is to copy the node in the output, and then go on to process any of the child nodes in the same way.  The processor will start at the root node of the input (in our case the <tt>html<\/tt> tag) and slavishly copy out the entire DOM tree into the output.<\/p>\n\n<p>Now that we have an XSL that outputs whatever's put into it, we can start specifying exceptions to this rule.  The first thing that I notice from the dompdf output is that dompdf underlines my <tt>A<\/tt> tags and colours them in blue, but doesn't make them clickable.  The solution is to add a template into the document that removes <tt>A<\/tt> tags:<\/p>\n\n<div class=\"xml\"><pre>&lt;xsl:template match=&quot;a&quot;&gt;\n\n      &lt;xsl:apply-templates select=&quot;node()&quot;\/&gt;\n&lt;\/xsl:template&gt;<\/pre><\/div>\n\n<p>This would slot into the previous XSL just underneath the existing <tt>xsl:template<\/tt>, inside the <tt>xsl:stylesheet<\/tt>.  What will now happen is that as the processor traverses the DOM tree of the source document, for most nodes it will copy them into the output because they match the first template.  However, when it gets to an <tt>A<\/tt> node it will match the second template, and just copy the child nodes, ignoring the <tt>A<\/tt>.<\/p>\n\n<p>For example, the following line:<\/p>\n\n<div class=\"xml\"><pre>&lt;p&gt;&lt;a href=&quot;test.html&quot;&gt;Hello &lt;em&gt;world&lt;\/em&gt;&lt;\/a&gt;&lt;\/p&gt;<\/pre><\/div>\n\n<p>Wound be converted into:<\/p>\n\n<div class=\"xml\"><pre>&lt;p&gt;Hello &lt;em&gt;world&lt;\/em&gt;&lt;\/p&gt;<\/pre><\/div>\n\n<p>In the case of my CV, I decided to ditch the existing stylesheet completely and insert my own rules for the PDF version.  The XSL for replacing a node with something else is fairly simple, you just don't tell it to <tt>xsl:apply-templates<\/tt> and all of the children of that node will get ignored, and the node itself replaced with whatever you want:<\/p>\n\n<div class=\"xml\"><pre>&lt;xsl:template match=&quot;style&quot;&gt;\n\n&lt;style type=&quot;text\/css&quot;&gt;\n    body{font-size: 10pt;}\n    \/* rest of the styles here *\/\n&lt;\/style&gt;\n&lt;\/xsl:template&gt;<\/pre><\/div>\n\n<p>Using this technique of specifying exceptions, we can methodically set templates for all of the other elements in the source that aren't being rendered correctly in the output.<\/p>\n\n<p>The process is pretty simple. I tend to do it in an iterative loop of:<\/p>\n\n<ol>\n\n    <li>Render the PDF<\/li>\n    <li>Spot something that doesn't work<\/li>\n    <li>Specify an <tt>xsl:template<\/tt> that makes an exception and fixes it<\/li>\n    <li>Repeat until the output is perfect<\/li>\n<\/ol>\n\n<p>The hardest part is remembering how to lay stuff out using tables, which if you're like me you've been avoiding doing for the last few years.  The good news is, the table-based layout you're designing only has to work for one user-agent, dompdf, and will never be seen in public - there's no 'view source' in a PDF after all.<\/p>\n\n<p>I won't go through the entire XSL for my CV, but as a final example here is the XSL for converting the page header, which in the source uses a UL and a couple of floated elements, and in the PDF ends up relying on a good old 100% width table:<\/p>\n\n<div class=\"xml\"><pre>&lt;xsl:template match=&quot;div[@id='header']&quot;&gt;\n    &lt;table cellspacing=&quot;0&quot; \n           cellpadding=&quot;0&quot; \n           border=&quot;0&quot; \n           width=&quot;100%&quot; \n           style=&quot;border-bottom: solid 0.5pt black; margin: 0;&quot;&gt;\n\n        &lt;tr&gt;\n            &lt;td valign=&quot;bottom&quot; align=&quot;left&quot;&gt;\n                &lt;span style=&quot;font-size: 2em; font-weight: bold&quot;&gt;\n                &lt;xsl:value-of select=&quot;h1&quot; \/&gt;\n\n                &lt;\/span&gt;\n            &lt;\/td&gt;\n        &lt;td valign=&quot;bottom&quot; align=&quot;right&quot;&gt;\n            &lt;xsl:value-of select=&quot;\/\/*[@class='tel']&quot; \/&gt;\n\n            &lt;br \/&gt;\n            &lt;xsl:value-of select=&quot;\/\/*[@class='emai']&quot; \/&gt;\n        &lt;\/td&gt;\n    &lt;\/tr&gt;\n    &lt;\/table&gt;\n\n&lt;\/xsl:template&gt;<\/pre><\/div>\n\n<p>Hopefully this has given you an insight into how powerful XSL can be, and how you can leverage it to give new life to tools like dompdf that otherwise seem a little behind the times.<\/p>","created":"2008-08-07 20:23:25","url":"delivering-pages-as-pdf-using-php","tags":["php","web"],"comments":[{"name":"Russell","website":"http:\/\/www.rdjs.co.uk","comment":"Being a newly qualified Zend Framework Genius I thought you might suggest using Zend_Pdf?","created":"2008-08-12 15:54:20"},{"name":"Ciaran","website":"http:\/\/ciaranmcnulty.com","comment":"Well I've looked at Zend_Pdf a bit, but the problem with it seems to be that, like other programmatic PDF generators, it's actually remarkably hard to format a document in it without writing hundreds of lines of code.\r\n\r\nAlso, when starting off with an HTML document it made sense to me to keep to the HTML->PDF route.  I suppose it would be possible to parse the HTML source and generate a Zend_Pdf object from it, then render the Zend_Pdf but it would be a lot more complicated.\r\n\r\nThat said, if you don't want to touch XSL it may be a good way to go.","created":"2008-08-12 17:34:13"}]},{"title":"How much of your data is available online?","content":"<p>One of the emergent web technologies I'm very interested in is the <a href=\"http:\/\/www.microformats.org\">Microformats<\/a> project, a set of ways of making data embedded in HTML documents machie-readable.<\/p>\n\n<p>Two of the most widely adopted Microformats are <a href=\"http:\/\/microformats\/org\/wiki\/hCard\">hCard<\/a> and <a href=\"http:\/\/www.microformats.org\/wiki\/XFN\">XFN<\/a>.<\/p>\n\n<p>hCard is a standardised method for marking up contact data.  the point of it is that if all sites mark up contact data the same way, it's easier to parse.<\/p>\n\n<p>XFN is all about the relationships between sites, and one of its key features is that it allows you to identify that a set of online profiles all belong to the same person (if they've voluntarily linked them).<\/p>\n\n<p>I thought I'd take a survey of the data about me that's available publically online and exposed via these two formats:<\/p>\n\n<table class=\"data-table\">\n<thead>\n    <tr>\n        <th>hCard Field<\/th>\n        <th>Value<\/th>\n        <th>Source<\/th>\n    <\/tr>\n<\/thead>\n<tbody>\n    <tr>\n        <td rowspan=\"2\">Nickname<\/td>\n        <td>ciaranmcnulty<\/td>\n        <td>LiveJournal, YouTube, Twitter<\/td>\n    <\/tr>\n    <tr>\n        <td>CiaranJMcNulty<\/td>\n        <td>Flickr<\/td>\n    <\/tr>\n    <tr>\n        <td rowspan=\"2\">Full name<\/td>\n        <td>Ciaran McNulty<\/td>\n        <td>CiaranMcNulty.com, Flickr, Last.fm, Facebook, LinkedIn<\/td>\n    <\/tr>\n    <tr>\n        <td>CiaranMcNulty<\/td>\n        <td>YouTube, Twitter<\/td>\n    <\/tr>\n    <tr>\n        <td>Given name<\/td>\n        <td>Ciaran<\/td>\n        <td>CiaranMcNulty.com, Flickr, Last.fm, Facebook, LinkedIn<\/td>\n    <\/tr>\n    <tr>\n        <td>Family name<\/td>\n        <td>McNulty<\/td>\n        <td>CiaranMcNulty.com, Flickr, Last.fm, Facebook, LinkedIn<\/td>\n    <\/tr>\n    <tr>\n        <td rowspan=\"2\">Email<\/td>\n        <td>mail@ciaranmcnulty.com<\/td>\n        <td>CiaranMcNulty.com<\/td>\n    <\/tr>\n    <tr>\n        <td>mail [at] ciaranmcnulty.com<\/td>\n        <td>Flickr<\/td>\n    <\/tr>\n    <tr>\n        <td rowspan=\"2\">Address<\/td>\n        <td>United Kingdom<\/td>\n        <td>Last.fm<\/td>\n    <\/tr>\n    <tr>\n        <td>London, United Kingdom<\/td>\n        <td>LinkedIn<\/td>\n    <\/tr>\n    <tr>\n        <td>Tel<\/td>\n        <td>+447092305237<\/td>\n        <td>CiaranMcNulty.com<\/td>\n    <\/tr>\n    <tr>\n        <td rowspan=\"4\">Photo<\/td>\n        <td><img src=\"http:\/\/p-userpic.livejournal.com\/23103983\/2730323\" \/><\/td>\n        <td>LiveJournal<\/td>\n    <\/tr>\n    <tr>\n        <td><img src=\"http:\/\/userserve-ak.last.fm\/serve\/126\/1300183.jpg\" \/><\/td>\n        <td>Last.fm<\/td>\n    <\/tr>\n    <tr>\n        <td><img src=\"http:\/\/profile.ak.facebook.com\/profile5\/1734\/4\/s600005468_4105.jpg\" \/><\/td>\n        <td>Facebook<\/td>\n    <\/tr>\n    <tr>\n        <td><img src=\"http:\/\/i1.ytimg.com\/i\/L8oa021mTWjabqI2pUHNRA\/1.jpg\" \/><\/td>\n        <td>YouTube<\/td>\n    <\/tr>\n    <tr>\n        <td>Logo<\/td>\n        <td><img src=\"http:\/\/farm3.static.flickr.com\/2244\/buddyicons\/67088004@N00.jpg?1207731389#67088004@N00\" \/><\/td>\n        <td>Flickr<\/td>\n    <\/tr>\n<\/tbody>\n<\/table>\n\n<p>Taken as an aggregated whole, there's a fairly complete set of contact details out there! Personally I don't mind all of this information being out there, but I know a lot of people who would be horrified if they realised how much was already exposed to search engines and other spiders.<\/p>\n\n<p>What interests me is that all this data is already out there in the wild for a lot of us, it's just not previously been machine-readable.  What's also important to realise is that in today's world of web archives and Google caches, once data is public it's pretty much going to be available forever.  A lot of us provide data to websites without really thinking about how that data will be displayed and used in future.<\/p>\n\n<p>As more and more of our lives are lived online, we're all going to leave trails like this and will have to start thinking about how to manage it.<\/p>\n\n<p>One solution is to maintain more than one identity.  XFN allows identities to be consolidated together, but there's no reason they have to be.  If I wanted to, for instance, I could break the XFN links to and from my Flickr account and essentially keep that identity separate in a machine-readable sense.  The use of pseudonyms would come in handy here, for people with less distinctive names.<\/p>\n\n<p>One way or another though, you need to take the time to think about what you're typing into that registration form, and whether you're happy having it online.<\/p>\n","created":"2008-10-01 11:17:05","url":"how-much-of-your-data-is-available-online","tags":["web","microformats"],"comments":[{"name":"Russell","website":"http:\/\/www.rdjs.co.uk","comment":"This reminds me, I need to get a new credit card....\r\n\r\n;)","created":"2008-10-06 14:40:12"}]},{"title":"Keeping your Javascript clean","content":"<p>I've been doing a bit more Javascript recently, specifically using Prototype AJAX stuff with Google Maps ,and I've come up with a few guiding principles that have helped me keep stuff neat and tidy.  I thought I'd share them with you, my handful of readers.<\/p>\n\n<h4>SCRIPT tags should live inside HEAD<\/h4>\n\n<p>There are very few reasons for having SCRIPT tags inside the document body.   The main one, use of <tt>document.write()<\/tt> nearly always leads to ugly code.  It's also not actually allowed in XHTML, despite most browsers accepting it as long as the page is delivered as <tt>text\/html<\/tt>.<\/p>\n\n<p>Furthermore, SCRIPT in the document body is in my opinion always the result of a perceived problem that's actually the result of poor architectural choices.<\/p>\n\n<h4>Data and markup should live in HTML and styles should live in CSS<\/h4>\n\n<p>Somewhat related to the first point, sometimes it's tempting to do something like this on-page or in some server-generated JS to get information into your scripting language:<\/p>\n\n<code><pre>\n&lt;script type=&quot;text\/javascript&quot;&gt;\nlng = &lt;?php echo $lat ?&gt;;\nlat = &lt;?php echo $lng ?&gt;;\ndrawTheMap(lat,lng);\n&lt;\/script&gt;<\/pre><\/code>\n\n<p>What's a little nicer is to put the info somewhere into your HTML with a distinct ID or CLASS, and let your scripting language read it out of the DOM.  That way you can avoid the sticky situations of trying to generate client-side code from your server-side code.<\/p>\n\n<p>For example the data could be stored on the page somewhere sensible using <a href=\"http:\/\/www.microformats.org\/wiki\/geo\">the GEO microformat<\/a>:<\/p>\n\n<code><pre>\nLocation: &lt;abbr id=&quot;location&quot; class=&quot;geo&quot; \n    title=&quot;&lt;?php echo $lat ?&gt;;&lt;?php echo $lng ?&gt;&quot;&gt;\n    6 Example Street\n&lt;\/abbr&gt;<\/pre><\/code>\n\n<p>And then read out from the DOM using something like the following:<\/p>\n\n<code><pre>\n&lt;script type=&quot;text\/javascript&quot;&gt;\nif(locElement = document.getElementById('location')){\n    if(locElement.className='geo'){\n        if((loc = locElement.title.split(';')) &amp;&amp; loc.length==2){\n            lng = loc[0];\n            lat = loc[1];\n            drawTheMap(lat,lng);\n        }\n    }\n}\n&lt;\/script&gt;<\/pre><\/code>\n\n<p>Now, that looks slightly longer than the previous example but consider that it won't change from page to page, so can live in a client-cached JS file.  The first example would need to either lie inside every HTML page, or be in a server-generated .js with nocache headers and be reloaded on every page.<\/p>\n\n<p>As an aside, if you really don't have anywhere sensible in your visible markup to show this data, you could always put it in a HEAD element like META if you really need to - I've toyed with keeping my google API keys in there for instance.<\/p>\n\n<h4>There should only be one SCRIPT tag on the page<\/h4>\n\n<p>Perhaps the rule I'm least sure of, but one I've been trying to stick to as much as possible and I've found it helpful.  Having one central JS that controls everything makes the path of execution of your code a lot cleaner.  When you have multiple SCRIPTs on the page (and when you have them knocking around in the BODY) you can get into situations where different scripts are trying to set window.onload, executing out of order and so forth.<\/p>\n\n<p>To continue the Mapping example above, a lot of my pages used to have:<\/p>\n\n<code><pre>\n&lt;script language=&quot;text\/javascript&quot; src=&quot;myscript.js&quot;&gt;&lt;\/script&gt;\n\n&lt;?php if(thereMightBeAMapOnThisPage()){ ?&gt;\n&lt;script language=&quot;text\/javascript&quot; src=&quot;http:\/\/maps.google.com...&quot;&gt;\n&lt;\/script&gt;\n&lt;?php } ?&gt;<\/pre><\/code>\n\n<p>This relies on the script generating the head knowing whether the mapping API is needed.  Neater in my opinion is to eliminate this and detect inside my own Javascript, whether the API is needed:<\/p>\n\n<code><pre>\n&lt;script language=&quot;text\/javascript&quot;&gt;\n\nif(locElement = document.getElementById('location')){\n  var script = document.createElement(&quot;script&quot;);\n  script.src = &quot;http:\/\/www.google.com\/jsapi?key=asd[...]asd3&amp;\n  script.type = &quot;text\/javascript&quot;;\n  document.getElementsByTagName(&quot;head&quot;)[0].appendChild(script);\n}\n&lt;\/script&gt;<\/pre><\/code>\n\n<p>What this is doing essentially is inserting the SCRIPT into the HEAD via the DOM!  It may well look messy at first glance, but it's worked in all the browsers I've tried it on and is the way Google recommend pulling in their external scripts.<\/p>\n\n<h4>Use the Google AJAX Libraries API<\/h4>\n\n<p>OK so this isn't so much a rule as something I think is fairly handy, and I'm sorry if I keep going on about Google!<\/p>\n\n<p><a href=\"http:\/\/code.google.com\/apis\/ajaxlibs\/\">Google are hosting lots of the common Javascript libraries<\/a>, including Prototype which I use.  Loading your Javascript library via the AJAX loader doesn't make much difference, but it does offer a few advantages:<\/p>\n\n<ul>\n    <li>You get to use the google.load() functionality from within your script, which is quite tidy and helps with my previous point.<\/li>\n    <li>It's served from the Google servers so you don't pay for the bandwidth, and it can download faster in parallel with content from your domain (most browsers won't open more than 2 simultaneous connections to a single server).<\/li>\n    <li>Because it's sitting at one central location, if everyone starts doing this then most clients will have the JS already cached when they hit your site, rather than them redundantly loading it for each server they encounter.<\/li>\n\n    <li>If you do decide in future that Google are too evil to download code from, switching back to a local copy of your library is fairly trivial.<\/li>\n<\/ul>","created":"2008-10-29 12:28:38","url":"keeping-your-javascript-clean","tags":["web","microformats","javascript"],"comments":[{"name":"raj","website":"http:\/\/www.tatainsuranced.com","comment":"please put in proper way","created":"2009-03-12 04:59:17"}]},{"title":"Keeping querystrings clean with Zend Framework","content":"<p>I'm something of a zealot about short, readable URLs.  Most people by now are using server rewrite rules and Front Controllers of some sort to keep the paths in their application sane and legible, but an area that's often overlooked is the querystring, especially after a form submission.<\/p>\n\n<p>A typical example of a situation with a 'messy' querystring might be a search form on site.  When a form is submitted, all the elements in the form are entered into the querystring whether they're relevant or not.<\/p> \n\n<p>That leads to querystrings like <tt>\/search?size=&amp;shape=&amp;colour=red&amp;age=<\/tt>, which would be a lot more legible as <tt>\/search?colour=red<\/tt><\/p>\n\n<p>On some sites I work with, an 'advanced search form' can have up to 20 elements, all of which might get submitted in one go leaving the search results page with a huge URL.<\/p>\n\n<p>Aside from an anally retentive need for neatness, the shorter querystrings provide the following benefits:<\/p>\n\n<ol>\n    <li>They are easier to remember.<\/li>\n    <li>They are less likely to wrap when sent in emails.<\/li>\n    <li>The URL is populated with relevant keywords and not the others, so is better for SEO.<\/li>\n    <li>By shortening the URL in this way we ensure there's one canonical URL for every search, which has SEO benefits and can help with aggregating search statistics.<\/li>\n<\/ol>\n\n<p>So, in the interest of all of the above I've written a Zend Framework Controller Plugin to shorten any GET request that has a querystring.<\/p>\n\n<p>What is important to note about the plugin:<\/p>\n\n<ul>\n    <li>It takes a flag in its constructor to say whether the redirects used should be permanent or temporary.  This is mainly used for testing.<\/li>\n    <li>The plugin takes effect before any routing is applied, so is about as efficient as a Zend Framework application can be.<\/li>\n    <li>The plugin would be initialised in your bootstrap, by doing <tt>$front->registerPlugin(new Plugin_CleanQuery());<\/tt>.<\/li>\n<\/ul>\n\n<p>Here's the source of the plugin, I'm sure the array stuff could be done a bit more efficiently with some combination of <tt>array_filter()<\/tt> and <tt>array_walk_recursive()<\/tt> but I'm not convinced it'll be a bottleneck.<\/p>\n\n<code><span style=\"color: #000000\">\n<span style=\"color: #0000BB\">&lt;?php<br \/><br \/><\/span><span style=\"color: #FF8000\">\/**<br \/>&nbsp;*&nbsp;Plugin&nbsp;that&nbsp;cleans&nbsp;up&nbsp;querystrings&nbsp;in&nbsp;GET&nbsp;submissions<br \/>&nbsp;*\/<br \/><\/span><span style=\"color: #007700\">class&nbsp;<\/span><span style=\"color: #0000BB\">Plugin_CleanQuery&nbsp;<\/span><span style=\"color: #007700\">extends&nbsp;<\/span><span style=\"color: #0000BB\">Zend_Controller_Plugin_Abstract&nbsp;<br \/><\/span><span style=\"color: #007700\">{<br \/><br \/>&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #FF8000\">\/**<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;@var&nbsp;boolean<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*\/<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #007700\">protected&nbsp;<\/span><span style=\"color: #0000BB\">$permanent<\/span><span style=\"color: #007700\">;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #FF8000\">\/**<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;Takes&nbsp;a&nbsp;flag&nbsp;in&nbsp;the&nbsp;constructor&nbsp;to&nbsp;determine&nbsp;whether&nbsp;the&nbsp;redirects&nbsp;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;are&nbsp;permanent&nbsp;or&nbsp;just&nbsp;temporary&nbsp;(default);<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;@param&nbsp;boolean&nbsp;$permanent<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*\/<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #007700\">public&nbsp;function&nbsp;<\/span><span style=\"color: #0000BB\">__construct<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$permanent<\/span><span style=\"color: #007700\">=<\/span><span style=\"color: #0000BB\">false<\/span><span style=\"color: #007700\">)&nbsp;{<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">permanent<\/span><span style=\"color: #007700\">=<\/span><span style=\"color: #0000BB\">$permanent<\/span><span style=\"color: #007700\">;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;}<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #FF8000\">\/**<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;Cleans&nbsp;the&nbsp;GET&nbsp;and&nbsp;if&nbsp;it's&nbsp;changed&nbsp;does&nbsp;a&nbsp;redirect<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*\/<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #007700\">public&nbsp;function&nbsp;<\/span><span style=\"color: #0000BB\">routeStartup<\/span><span style=\"color: #007700\">()<br \/>&nbsp;&nbsp;&nbsp;&nbsp;{<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if(<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">getRequest<\/span><span style=\"color: #007700\">()-&gt;<\/span><span style=\"color: #0000BB\">isGet<\/span><span style=\"color: #007700\">())&nbsp;{<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if(<\/span><span style=\"color: #0000BB\">$params&nbsp;<\/span><span style=\"color: #007700\">=&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">getRequest<\/span><span style=\"color: #007700\">()-&gt;<\/span><span style=\"color: #0000BB\">getParams<\/span><span style=\"color: #007700\">())&nbsp;{<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #0000BB\">$new_params&nbsp;<\/span><span style=\"color: #007700\">=&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">_filterArray<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$params<\/span><span style=\"color: #007700\">);<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if(<\/span><span style=\"color: #0000BB\">count<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$params<\/span><span style=\"color: #007700\">,&nbsp;<\/span><span style=\"color: #0000BB\">COUNT_RECURSIVE<\/span><span style=\"color: #007700\">)<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&gt;<\/span><span style=\"color: #0000BB\">count<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$new_params<\/span><span style=\"color: #007700\">,&nbsp;<\/span><span style=\"color: #0000BB\">COUNT_RECURSIVE<\/span><span style=\"color: #007700\">)){<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #0000BB\">$uri&nbsp;<\/span><span style=\"color: #007700\">=&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">getRequest<\/span><span style=\"color: #007700\">()-&gt;<\/span><span style=\"color: #0000BB\">getRequestUri<\/span><span style=\"color: #007700\">();<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #0000BB\">$qs&nbsp;<\/span><span style=\"color: #007700\">=&nbsp;<\/span><span style=\"color: #0000BB\">substr<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$uri<\/span><span style=\"color: #007700\">,&nbsp;<\/span><span style=\"color: #0000BB\">0<\/span><span style=\"color: #007700\">,&nbsp;<\/span><span style=\"color: #0000BB\">strpos<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$uri<\/span><span style=\"color: #007700\">,&nbsp;<\/span><span style=\"color: #DD0000\">'?'<\/span><span style=\"color: #007700\">)+<\/span><span style=\"color: #0000BB\">1<\/span><span style=\"color: #007700\">)&nbsp;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.&nbsp;<\/span><span style=\"color: #0000BB\">http_build_query<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$new_params<\/span><span style=\"color: #007700\">);<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">getResponse<\/span><span style=\"color: #007700\">()-&gt;<\/span><span style=\"color: #0000BB\">setRedirect<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$qs<\/span><span style=\"color: #007700\">,&nbsp;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">permanent<\/span><span style=\"color: #007700\">?<\/span><span style=\"color: #0000BB\">301<\/span><span style=\"color: #007700\">:<\/span><span style=\"color: #0000BB\">302<\/span><span style=\"color: #007700\">);<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">getResponse<\/span><span style=\"color: #007700\">()-&gt;<\/span><span style=\"color: #0000BB\">sendResponse<\/span><span style=\"color: #007700\">();<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;}<br \/><br \/>&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #FF8000\">\/**<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;Cleans&nbsp;out&nbsp;false&nbsp;values&nbsp;from&nbsp;an&nbsp;array<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;@param&nbsp;array&nbsp;$array<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*\/<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #007700\">private&nbsp;function&nbsp;<\/span><span style=\"color: #0000BB\">_filterArray<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$array<\/span><span style=\"color: #007700\">)<br \/>&nbsp;&nbsp;&nbsp;&nbsp;{<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;foreach(<\/span><span style=\"color: #0000BB\">$array&nbsp;<\/span><span style=\"color: #007700\">as&nbsp;<\/span><span style=\"color: #0000BB\">$key<\/span><span style=\"color: #007700\">=&gt;<\/span><span style=\"color: #0000BB\">$value<\/span><span style=\"color: #007700\">)&nbsp;{<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if(<\/span><span style=\"color: #0000BB\">is_array<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$value<\/span><span style=\"color: #007700\">))&nbsp;{<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #0000BB\">$value&nbsp;<\/span><span style=\"color: #007700\">=&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">_filterArray<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$value<\/span><span style=\"color: #007700\">);<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #0000BB\">$array<\/span><span style=\"color: #007700\">[<\/span><span style=\"color: #0000BB\">$key<\/span><span style=\"color: #007700\">]=<\/span><span style=\"color: #0000BB\">$value<\/span><span style=\"color: #007700\">;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if(<\/span><span style=\"color: #0000BB\">$value<\/span><span style=\"color: #007700\">===<\/span><span style=\"color: #DD0000\">''<\/span><span style=\"color: #007700\">)&nbsp;{<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;unset(<\/span><span style=\"color: #0000BB\">$array<\/span><span style=\"color: #007700\">[<\/span><span style=\"color: #0000BB\">$key<\/span><span style=\"color: #007700\">]);<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;<\/span><span style=\"color: #0000BB\">$array<\/span><span style=\"color: #007700\">;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;}<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<br \/>}<\/span>\n<\/span>\n<\/code>","created":"2008-11-30 12:14:24","url":"keeping-querystrings-clean-with-zend-framework","tags":["php","zend-framework","seo"],"comments":[{"name":"Ciaran McNulty","website":"http:\/\/ciaranmnulty.com","comment":"I forgot to add, I'd consider this code public domain so anyone can use\/modify\/redistribute it.","created":"2008-12-08 12:26:44"},{"name":"Alex","website":"","comment":"I would suggest replacing your code with what i wrote below. It's much more clean and less prone to errors. One could argue that using the routeShutdown instead of the Startup could lead to some overhead (because the route is precessed), but i guess ultimately it depends on the volume of traffic that goes through this, and that may be site dependent. For grid filters in an admin for example, this  would be the better solution.\r\n\r\npublic function routeShutdown( Zend_Controller_Request_Abstract $request )\r\n{\r\n    if( count( $request->getQuery() ) )\r\n    {\r\n        $router = Zend_Controller_Front::getInstance()->getRouter();\r\n        $url = $router->assemble( array_reverse( $request->getQuery(), true ), null, false, true );\r\n\r\n        $this->getResponse()->setRedirect( $url )->sendResponse();\r\n        exit;\r\n    }\r\n}","created":"2009-01-26 22:38:58"},{"name":"Ciaran McNulty","website":"http:\/\/ciaranmcnulty.com","comment":"Interesting stuff, Alex! I wasn't aware you could play with the Router like that, it would be interesting to compare the overheads of doing this pre\/post routing.","created":"2009-01-29 09:20:29"},{"name":"Marc","website":"","comment":"this article and your comments are very helpful to me. thank you!","created":"2010-01-14 22:12:16"},{"name":"Joe Devon","website":"http:\/\/twitter.com\/joedevon","comment":"Nice idea! You didn't mention this, but it would be nice to couple this with some javascript on the front end to remove empty variables before submitting and use this as a backup...","created":"2010-04-02 20:30:08"},{"name":"Ciaran McNulty","website":"http:\/\/ciaranmcnulty.com","comment":"@Joe Thanks for the comment, I did think about doing something with Javascript but never got around to implementing it - let us know if you do!","created":"2010-04-06 13:30:48"},{"name":"Ren\u00e9 Pardon","website":"http:\/\/www.BoonWeb.de\/","comment":"Thank you for sharing code and your awesome comments :)\r\nThey're really helpful to handle query strings on a Zend Form submit.","created":"2010-04-26 16:36:34"},{"name":"Daniel Levitt","website":"http:\/\/www.whatcouldicook.com","comment":"Amazing!! \r\n\r\nYou've really helped me with the biggest headache. Genius.\r\n\r\nOnly using Alex's code worked for me but its really brilliant. Thank you again.","created":"2010-05-11 17:17:29"}]},{"title":"Sharing music between a Mac and Xbox with Connect360","content":"<p>Being a geek, I play Xbox games a lot.  Being a music lover, I often want to listen to my own music while playing. Being the right sort of geek, my music is all lovingly arranged in iTunes on my Mac.<\/p>\n\n<p>Windows people have it easy with Xbox.  They install the Windows Media Sharing service, make sure WMP knows about where their music's kept and it just becomes available to play on the Xbox. I had assumed that us Mac users were excluded from such fun, but then I came across <a href=\"http:\/\/www.nullriver.com\/products\/connect360\">Connect360<\/a>.<\/p>\n\n<p><a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/3096962667\/\" title=\"Connect360 in action by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3049\/3096962667_d78b211057_m.jpg\" width=\"240\" height=\"177\" alt=\"Connect360 in action\" \/><\/a><\/p>\n\n<p>Connect360 is a simple enough application to use.  It installs into your system preferences and lets you share music from iTunes, photos from iPhoto and movies from disk.  The configuration is simple - you can allow\/disallow different Xboxes and it will sort out your Firewall settings for you on the fly.  The first time I tried to play an AAC file the Xbox had to go to MS to get an updated codec, but aside from that no additional setup was needed on the Xbox - the mac appeared as just another source.<\/p>\n\n<p>The overall experience is excellent.  I can drop into the Music menu on the xbox in-game and select which tracks to play, without exiting the game.  The games detect when music is being played and drop out their own in-game music but leave any important sound effects playing (at least, this has worked on all the games I've tried.<\/p>\n\n<p>Less important to me but worth noting is the fact that iPhoto pictures are easy to navigate and come across really well on a big screen.  I experimented a bit with the Movies sharing, it suffers slightly from the fact it shows the video files' filenames rather than reading any metadata like itunes does, but files of formats the Xbox supports played fine across my 100baseT network, even some HD stuff.  It's certainly a viable option for someone who wanted to play videos on their TV and already had an Xbox - my only criticism would be that MKV files are not supported but I expected that's something MS would have to address.<\/p>\n\n<p> There is a trial version available that's limited to sharing 100 songs, which is a good idea to try out if you're worried about your particular network setup and want to check it'll all work. Overall for the $20 licence fee Connect360 does what it claims to and does it well.<\/p>","created":"2008-12-09 14:23:24","url":"sharing-music-between-a-mac-and-xbox-with-connect360","tags":["apple","xbox"]},{"title":"Embedding third-party content in your site using oEmbed","content":"<p>There's a whole class of 'Web 2.0' technologies that have emerged recently which have some common features: They solve a simple problem, they do so in a decentralised way and they stay simple. As examples I'd quote things like <abbr title=\"eXtensible Friends Network\"><a href=\"http:\/\/microformats.org\/wiki\/xfn\">XFN<\/a><\/abbr>, <a href=\"http:\/\/openid.net\">OpenID<\/a>, <a href=\"http:\/\/oauth.net\">oAuth<\/a> and even things like <a href=\"http:\/\/cyber.law.harvard.edu\/rss\/rss.html\">RSS<\/a> and <a href=\"http:\/\/tools.ietf.org\/html\/rfc5023\">Atom feeds<\/a>.  They start off by solving a particular use case, and stay as simple as possible (or at least should - I'm looking at you OpenID).<\/p>\r\n\r\n<p>The latest such technology to interest me is <a href=\"http:\/\/oembed.com\/\">oEmbed<\/a>, via a blog post by <a href=\"http:\/\/ben-ward.co.uk\/blog\/microformat-2009\/\">Ben Ward<\/a>.  The name is a bit cryptic, but the use case it addresses is one of <em>embedding content from one site into another<\/em>.  That may sound like something esoteric, but just looking back over the handful of blog posts I've done on this very site, a large number of them contain images from Flickr.  Looking around the web as a whole people are constantly embedding videos and images from sites all around the web into their forums, blog posts and CMSes.<\/p>\r\n\r\n<div>\r\n<p>There are a couple of ways this is normally done in the wild, neither of which are that satisfactory.<\/p>\r\n<ol>\r\n\t<li><strong>The site the content is hosted on generates a snippet of HTML<\/strong> - From looking at a page with the content on, a couple of clicks will give the user some HTML that they can copy and paste into their HTML editor.  This is ok for people who are happy with HTML and actually have the ability to edit the HTML in their posts rather than using some sort of WYSIWYG, but can be confusing for novice users.  This technique also limits the ability of the receiving site to reformat the content to fit into any existing templating.<\/li>\r\n\t<li><strong>The site the content is hosted on gets screen-scraped<\/strong> - Some blogging platforms and CMSes know how major sites like Flickr or YouTube structure their HTML so are able to extract images and videos from just a URL.  This of course falls down if the HTML changes significantly, and if you're trying to post content from a site your platform doesn't know about, you're out of luck.<\/li>\r\n<\/ol>\r\n\r\n<p>Of the two existing solutions, the second has the best user story.  The user clicks an button, pastes in a URL to the content on another site, and the patform slurps up the content, reformats it to fit in with any house styles and inserts it into the content area.  What's needed is a way to do this in a decentralised way, which is where oEmbed comes in.<\/p>\r\n\r\n<\/div>\r\n\r\n<h4>How oEmbed works<\/h4>\r\n\r\n<p>What happens with a system that supports oEmbed is as follows:<\/p>\r\n\r\n<ol>\r\n\t<li>The user pastes in a URL at which content is hosted.<\/li>\r\n\t<li>The system checks that URL to find the address of its oEmbed API via a LINK element in the document's HEAD.  This step could be cached as the API location is unlikely to change often.<\/li>\r\n\r\n\t<li>The system does a GET to the oEmbed API, essentially asking 'what is the content for this URL'?<\/li>\r\n\t<li>The system gets a JSON or XML response containing structured metadata for the item.<\/li>\r\n\t<li>The system formats the data however it deems appropriate.<\/li>\r\n<\/ol>\r\n\r\n<p>A practical example with a picture from my Flickr would be:<\/p>\r\n\r\n<ol>\r\n\t<li>I give the URL <a href=\"http:\/\/flickr.com\/photos\/ciaranmcnulty\/429868897\/\">http:\/\/flickr.com\/photos\/ciaranmcnulty\/429868897<\/a>, one of my holiday snaps.<\/li>\r\n\r\n\t<li>The system sees from the page that the oEmbed API is at http:\/\/flickr.com\/services\/oembed.<\/li>\r\n\t<li>The system does a GET to <a href=\"http:\/\/flickr.com\/services\/oembed?url=http:\/\/flickr.com\/photos\/ciaranmcnulty\/429868897\/\">http:\/\/flickr.com\/services\/oembed?url=http:\/\/flickr.com\/photos\/ciaranmcnulty\/429868897\/<\/a><\/li>\r\n\t<li>The system gets the following response:\r\n<pre><code>&lt;oembed&gt;\r\n    &lt;version&gt;1.0&lt;\/version&gt;\r\n    &lt;type&gt;photo&lt;\/type&gt;\r\n\r\n    &lt;title&gt;Rosella parrot&lt;\/title&gt;\r\n    &lt;author_name&gt;CiaranJMcNulty&lt;\/author_name&gt;\r\n    &lt;author_url&gt;http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/&lt;\/author_url&gt;\r\n    &lt;cache_age&gt;3600&lt;\/cache_age&gt;\r\n\r\n    &lt;provider_name&gt;Flickr&lt;\/provider_name&gt;\r\n    &lt;provider_url&gt;http:\/\/www.flickr.com\/&lt;\/provider_url&gt;\r\n    &lt;width&gt;375&lt;\/width&gt;\r\n    &lt;height&gt;500&lt;\/height&gt;\r\n\r\n    &lt;url&gt;http:\/\/farm1.static.flickr.com\/185\/429868897_18ea03200a.jpg&lt;\/url&gt;\r\n&lt;\/oembed&gt;\r\n<\/code><\/pre>\r\n\t<\/li>\r\n\t<li>The system reformats this according to some sort of template into:\r\n<pre><code>&lt;div class=&quot;figure&quot;&gt;\r\n    &lt;div id=&quot;caption&quot;&gt;Rosella parrot&lt;\/div&gt;\r\n\r\n    &lt;a href=&quot;http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/&quot;&gt;\r\n    \t&lt;img src=&quot;http:\/\/farm1.static.flickr.com\/185\/429868897_18ea03200a.jpg&quot; width=&quot;375&quot; height=&quot;500&quot; \/&gt;\r\n    &lt;\/a&gt;\r\n\r\n&lt;\/div&gt;\r\n<\/code><\/pre>\t\r\n\t<\/li>\r\n<\/ol>\r\n\r\n<p>The oEmbed format docs specify a few different content types: 'image', 'video', 'rich' (i.e. HTML for embedding) and a whole bunch of different URL parameters you can add into the request, for instance you can ask for the result as JSON instead, specify a maximum size for images, specify that you only accept images and so forth.<\/p>\r\n\r\n<h4>Why oEmbed is awesome, sort of<\/h4>\r\n\r\n<p>On the Internet it's mostly easier to complain than praise, but there are some things oEmbed has done well.<\/p>\r\n\r\n<ul>\r\n\t<li><strong>It addresses the problem.<\/strong> It's easy to underestimate how important this is.  The authors of the oEmbed spec have managed to identify an area that could be improved for users, and have generated a system that does it in a fairly reasonable manner. Frankly even if oEmbed doesn't take off it's got people thinking about the problem.<\/li>\r\n\r\n\t<li><strong>The response formats are really well thought out.<\/strong>  The spec defines a useful transfer format for the domain that covers most scenarios I can think of.  There's obviously a lot of time and effort that's gone into it, and they've been careful to think about how it would be integrated into real-world Javascript code.<\/li>\r\n<\/ul>\r\n\r\n<h4>Why oEmbed sucks, sort of<\/h4>\r\n\r\n<p>All in all oEmbed is a promising technology, and the big appeal for me is the way it simplifies the entire process for the user.  There are however a few bits of the process I think are, well, lame.<\/p>\r\n\r\n<ul>\r\n\t<li><strong>Multiple URLs for a single resource is not very RESTful.<\/strong> The request to the 'API' can contain a parameter saying whether the response should be XML or JSON.  This generates two separate URLs for what is essentially the same resource, a violation of REST principles and a waste of the HTTP Accepts header, which does this in a much nicer way.<\/li>\r\n\r\n\t<li><strong>'Autodiscovery' is long-winded.<\/strong> From knowing a URL of an HTML representation of a resource, I then have to examine that HTML to find out an API location, then construct my own URL based on that and the original URL, from which I can get the oEmbed response... phew! Again, this just duplicates URLs for a resource - I <em>have<\/em> a URL to the resource so why can't I just do a request to the original URL, but ask for an oEmbed content-type?<\/li>\r\n\t<li><strong>The data is already there on the page.<\/strong> OK so this is me with my Microformats head on, but I wouldn't be very surprised if most of the data exposed in a typical oEmbed response is actually present in the HTML anyway.  What would be pretty cool would be a way of embedding oEmbed data inside HTML, either via POSH-type semantic HTML, a Microformat, or even some sort of RDFa vocabulary.  I mentioned Ben Ward earlier and he's expressed a strong intention to work on this so I'll be interested to see how he gets on.<\/li>\r\n\t<li><strong>People aren't using it.<\/strong> A few sites support oEmbed but it's not hit the critical mass needed yet where a CMS or blogging platform could use it for their main embedding solution.<\/li>\r\n\r\n<\/ul>\r\n\r\n<h4>oohEmbed - A third party solution<\/h4>\r\n\r\n<p>My first instincts when pondering the problems of Autodiscovery and the lack of support specified above, were to build a tool that did oEmbed requests in the background, but presented a nic(er) interface, and added in support for sites that didn't yet support oEmbed.<\/p>\r\n\r\n<p>Imagine my annoyance when I found out someone called Deepak Sarda had already done this, months ago at <a href=\"http:\/\/oohembed.com\">oohEmbed<\/a>!<\/p>\r\n\r\n<p>From the developer's point of view, oohEmbed takes out a big step in the oEmbed process - discovery.  Rather than doing oEmbed requests to API endpoints defined by each separate service, oohEmbed exposes an oEmbed API that accepts requests for basically any service, and adds support for those with other APIs the author can tap into.<\/p>\r\n\r\n<p>For example, if I wanted to get an oEmbed response for my Flickr via oohEmbed, rather than the long-winded process described above I'd do a single GET to a URL at oohEmbed - <a href=\"http:\/\/oohembed.com\/oohembed\/?url=http:\/\/flickr.com\/photos\/ciaranmcnulty\/429868897\/\">http:\/\/oohembed.com\/oohembed\/?url=http:\/\/flickr.com\/photos\/ciaranmcnulty\/429868897\/<\/a> - and get essentially the same response I'd have got if I'd gone to Flickr directly.<\/p>\r\n\r\n<p>Furthermore, if I want to get a YouTube video I can do a similar request to <a href=\"http:\/\/oohembed.com\/oohembed\/?url=http:\/\/youtube.com\/watch?v=fWUedF_eTvg\">http:\/\/oohembed.com\/oohembed\/?url=http:\/\/youtube.com\/watch?v=fWUedF_eTvg<\/a> and get the following oEmbed response, despite the fact that YouTube does not yet support oEmbed!  I get an oEmbed JSON response anyway, that I can use right away:<\/p>\r\n\r\n<p><pre><code>{\r\n    &quot;version&quot;: &quot;1.0&quot;,\r\n    &quot;type&quot;: &quot;video&quot;,\r\n    &quot;provider_name&quot;: &quot;YouTube&quot;,\r\n    &quot;width&quot;: 425,\r\n    &quot;height&quot;: 355,\r\n    &quot;html&quot;: &quot;&lt;embed src='http:\/\/www.youtube.com\/v\/fWUedF_eTvg' type='application\/x-shockwave-flash' wmode='transparent' width='425' height='355'&gt;&lt;\/embed&gt;&quot;\r\n\r\n}<\/code><\/pre><\/p>\r\n\r\n<p>Now that's not perfect, but it works pretty well, returns something usable, and is far less complex than a full oEmbed discovery process, so is something that could very simply be used in some Javascript code.<\/p>\r\n\r\n<h4>Where do I go from here?<\/h4>\r\n\r\n<p>I've still got half an idea to implement a front end for oEmbed.  I like the oohEmbed solution, but my qualms about the REST nature of oEmbed aren't really assuaged by it and it'd be an interesting process to go through.<\/p>\r\n\r\n<p>I'll be watching the progress of the Microformats embedding efforts once they start, and attempting to put my 2p's worth into the process via the mailing list and wiki.<\/p>\r\n\r\n<p>Also, I've half an idea to start embedding content into this site via oEmbed, taken from places like my Delicious bookmarks, my flickr and other sites.  I'd just need to make sure that that sort of Tumblr-style content didn't crowd out the sporadic 'real' blog posts I make, I guess!.<\/p>\r\n","created":"2009-01-28 14:11:09","url":"embedding-third-party-content-in-your-site-using-oembed","tags":["web","microformats"],"comments":[{"name":"Tobias","website":"http:\/\/uxzentrisch.de","comment":"Do you know http:\/\/embedit.me\/ and can comment on it?\r\nA friend of mine tells me its like oohembed but even simpler.","created":"2009-10-29 09:14:10"},{"name":"Ciaran McNulty","website":"http:\/\/ciaranmcnulty.com","comment":"To be honest, Tobias, it doesn't look finished - I'd certainly not use it yet","created":"2009-12-07 14:45:08"},{"name":"Jason","website":"http:\/\/autoembed.com","comment":"See AutoEmbed.com too, as it's a good solution for simple video embedding needs.","created":"2010-04-07 20:51:12"}]},{"title":"Combining bordering ranges of data in MySQL","content":"<p>A while back, a friend of mine was working on a database that contained bookings for some equipment, and he needed to separate it out into blocks representing when it was free and busy, regardless of whether the busy times were bookings by the same people or not.<\/p>\r\n\r\n<p>Just today, a different friend who works with mobile phones was dealing with a table that contained IP ranges and which network operator owned them.  He commented that he suspected a lot of the ranges overlapped or adjoined each other, and could be combined together into larger blocks.<\/p>\r\n\r\n<p>Both of these problems are ones of finding <em>contiguous<\/em> (or, bordering) ranges inside data.  <\/p>\r\n\r\n<p>It's tempting to try and approach the problem in an iterative way - find a block, try and find blocks border it, and work outwards from there but it's possible to solve this sort of thing in a non-iterative way with a single SQL query, which is what I'd like to show you how to do using MySQL.<\/p>\r\n\r\n<h4>The example data<\/h4>\r\n\r\n<p>To try and come up with some example data, let's imagine a very simple table with three columns: id (the primary key), and low\/high integer values (which would be indexed ideally).<\/p>\r\n\r\n<code><pre>ranges:\r\n+----+-----+------+\r\n| id | low | high |\r\n+----+-----+------+\r\n|  A |   6 |    8 | \r\n|  B |   7 |    7 | \r\n|  C |   8 |    9 | \r\n|  D |   1 |    2 | \r\n|  E |   3 |    4 | \r\n+----+-----+------+\r\n<\/pre><\/code>\r\n\r\n<p>We can visualise these ranges as follows:<\/p>\r\n\r\n<pre>\r\nA                |-------|\r\nB                   |-|\r\nC                      |----|\r\nD |----|\r\nE       |----|\r\n   1  2  3  4  5  6  7  8  9\r\n<\/pre>\r\n\r\n<p>It should be fairly apparent that some of these ranges overlap, and some border each other.  I'm going to use the term sub-range to mean these starting ranges, and super-range to mean the larger ranges we want to end up with (in this case 1-4 and 6-9).<\/p>\r\n\r\n<p>(I'm also going to ignore for now the fact that in real-world situations ranges might need to be combined separately, e.g. in the IP address example we'd only want to combine ranges that were the same operator).<\/p>\r\n\r\n<h4>Finding the maxima and minima<\/h4>\r\n\r\n<p>I'm going to define a minimum as the number at the bottom end of a super-range.  In our example data the minima would be 1 and 6.<\/p>  \r\n\r\n<p>So what are the properties of a minimum? Looking at the visualisation above, they are are:<\/p>\r\n\r\n<ul>\r\n\t<li>They are the 'low' value of a sub-range<\/li>\r\n\t<li>They do not overlap or border any other sub-ranges at the bottom end.<\/li>\r\n<\/ul>\r\n\r\n<p>We can write a query to find this in MySQL using a subquery as follows:<\/p>\r\n\r\n<code><pre>\r\nSELECT r.low AS low FROM ranges AS r\r\nWHERE NOT EXISTS(\r\n\tSELECT * FROM ranges AS r1\r\n\tWHERE r1.id != r.id\r\n\tAND r1.low <= r.low\r\n\tAND r1.high >= r.low-1\r\n);\r\n<\/pre><\/code>\r\n\r\n<p>This query is selecting low values where there does not exist a range that overlaps them (the <tt>r.low-1<\/tt> is to allow for bordering ranges).  As expected, it returns:<\/p>\r\n\r\n<pre>+-----+\r\n| low |\r\n+-----+\r\n|   6 | \r\n|   1 | \r\n+-----+\r\n<\/pre>\r\n\r\n<p>The efficiency of this query is reasonable when the relevant fields are indexed as (id,low,high), as the WHERE NOT EXISTS formulation allows the engine to bail out of the subquery as soon as one matching row is found.   It's worth noting that it could be rewritten as an OUTER JOIN but in my opinion would be less legible.<\/p>\r\n\r\n<p>Simply inverting this formulation gives us a query to find the maxima:<\/p>\r\n\r\n<code><pre>\r\nSELECT r.high AS high FROM ranges AS r\r\nWHERE NOT EXISTS(\r\n\tSELECT * FROM ranges AS r1\r\n\tWHERE r1.id != r.id\r\n\tAND r1.high >= r.high\r\n\tAND r1.low <= r.high + 1\r\n);\r\n<\/pre><\/code>\r\n\r\n<p>Again, the +1 in this is to allow for bordering ranges.  This would give us the following result:<\/p>\r\n\r\n<pre>+------+\r\n| high |\r\n+------+\r\n|    4 | \r\n|    9 | \r\n+------+\r\n<\/pre>\r\n\r\n<p>It's tempting to stop there, after all the results could now be combined in your application.  However, we can go a step further and combine the two into one bit of SQL.<\/p>\r\n\r\n<h4>Finding the ranges in one query<\/h4>\r\n\r\n<p>Basically we can combine these two together by taking the query that finds the minima, and inserting into its field list the query that finds the maxima, with a slight modification that we only want to find the smallest maximum that's greater than the minimum we're examining.<\/p>\r\n\r\n<pre>\r\nSELECT \r\nr.low AS low,\r\n( \r\n\tSELECT MIN(r2.high)\r\n\tFROM ranges AS r2\r\n\tWHERE NOT EXISTS(\r\n\t\tSELECT * FROM ranges AS r3\r\n\t\tWHERE r3.id != r2.id\r\n\t\tAND r3.high >= r2.high\r\n\t\tAND r3.low <= r2.high + 1\r\n\t)\r\n\tAND r2.high>=r.low\r\n) AS high\r\nFROM ranges AS r\r\nWHERE NOT EXISTS(\r\n\tSELECT * FROM ranges AS r1\r\n\tWHERE r1.id != r.id\r\n\tAND r1.low <= r.low\r\n\tAND r1.high >= r.low-1\r\n);\r\n<\/pre>\r\n\r\n<p>Obviously, the output looks like:<\/p>\r\n\r\n<pre>+-----+------+\r\n| low | high |\r\n+-----+------+\r\n|   6 |    9 | \r\n|   1 |    4 | \r\n+-----+------+\r\n<\/pre>\r\n\r\n<p>It's a big query, but hopefully I've managed to format it legibly. It basically ends up doing four reasonably-indexed SELECTs from the same table, but in general that should scale better than any iterative solution.<\/p>\r\n\r\n<p>It also can be fairly easily modified to only combine sub-ranges that share some common features, with a few additional WHERE clauses, as in our IP address example.<\/p>\r\n\r\n<p>Hopefully this has been of use for some poor googler trying to solve this solution.  If anyone's got any real-world benchmarks for this sort of operation, or suggestions of how it could be improved I'd love to hear from them.<\/p>\r\n\r\n<p><em>Added 13th Feb:<\/em><\/p>\r\n\r\n<h4>Rewriting as a JOIN<\/h4>\r\n\r\n<p>Personally a lot of the time I find that subqueries are the clearest way of thinking about or writing a query.  However, some people are using a version of MySQL that doesn't support them, and sometimes they're not particularly efficient.<\/p>\r\n\r\n<p>To that end, here is essentially the same query redefined as a JOIN:<\/p>\r\n\r\n<code><pre>SELECT r.low AS low, MIN(r2.high) AS high \r\nFROM ranges AS r\r\nLEFT JOIN ranges AS r1\r\n\tON r1.id != r.id\r\n\tAND r1.low <= r.low\r\n\tAND r1.high >= r.low-1\r\nINNER JOIN ranges AS r2\r\n\tON r2.id != r.id\r\n\tAND r2.high >= r.low\r\nLEFT JOIN ranges AS r3\r\n\tON r3.id != r2.id\r\n\tAND r3.high >= r2.high\r\n\tAND r3.low <= r2.high + 1\r\nWHERE ISNULL(r1.id) AND ISNULL(r3.id)\r\nGROUP BY low;\r\n<\/pre><\/code>\r\n\r\n<p>It may well be that this approach ends up being more efficient, I intend to try and do some benchmarks in future.<\/p>","created":"2009-02-12 18:04:45","url":"combining-bordering-ranges-of-data-in-mysql","tags":["mysql"]},{"title":"Rel-canonical should be handled with care","content":"<p>Something we've been telling clients for years is to not publish the same information in more than one place.  There are many reasons for this from the point of view of web semantics, but the one that makes the clients listen is when we say that Google will penalise their site for it.<\/p>\r\n\r\n<p>As of today Google allow duplicate content as long as you <a href=\"http:\/\/googlewebmastercentral.blogspot.com\/2009\/02\/specify-your-canonical.html\">indicate clearly which version is the canonical one<\/a>.  This entails adding something like the following to the HEAD element in your duplicated page, pointing back to the original:<\/p>\r\n\r\n<code><pre>&lt;link rel=\"canonical\" href=\"\/the-other-page\" \/&gt;<\/pre><\/code>\r\n\r\n<p>This approach has been welcomed by many, but I'm fearful that it is duplicating already-existing web semantics as well as encouraging bad habits in web authors.<\/p>\r\n\r\n<h4>Redundancy, or why it's not needed<\/h4>\r\n\r\n<p>HTTP and HTML already have two mechanisms for dealing with URLs that contain duplicate content:<\/p>\r\n\r\n<h5>Permanent redirects<\/h5> \r\n\r\n<p>If URLs are exactly equivalent, the server can send a <tt>301 Permanent Redirect<\/tt> header along with the location of the 'real' content.  This is useful in situations where there's no real reason to present different versions of the same page.<\/p>\r\n\r\n<h5>Content-location headers<\/h5>\r\n\r\n<p>HTTP allows the server to return a content-location header to indicate that the content of the current URL is a duplicate of that at another location.  <a href=\"http:\/\/www.w3.org\/Protocols\/rfc2616\/rfc2616-sec14.html\">RFC2616<\/a> says:<\/p>\r\n\t\r\n<blockquote>\r\n\tThe Content-Location value is not a replacement for the original requested URI; it is only a statement of the location of the resource corresponding to this particular entity at the time of the request. Future requests MAY specify the Content-Location URI as the request- URI if the desire is to identify the source of that particular entity.\r\n<\/blockquote>\r\n\r\n<p>... which would seem to duplicate the functionality of rel-canonical with an existing HTTP mechanism.  If authors didn't have access to the HTTP headers their server sent, they could embed it directly in their HTML using the META element:<\/p>\r\n\r\n<p><pre>&lt;meta http-equiv=\"content-location\" content=\"\/the-other-page\" \/&gt;<\/pre><\/p>\r\n\r\n<p>I'm therefore not sure why Google have chosen to re-invent the wheel in this way, my only guess would be that <a href=\"http:\/\/www.elementary-group-standards.com\/html\/html5-http-equiv-difference\">HTML5 is largely deprecating http-equiv in META tags<\/a>. My main concern is that rel-canonical will start to be used in places where a permanent redirect would be more appropriate.<\/p>\r\n\r\n<p>Google don't follow any public processes for recommendations like this, presumably they have some internal debates but a lot of the time these things hit the web fully-formed and are powered forwards via Google's massive market share until other search engines support them.  It's a shame that they don't publish proposals before implementation though, as I'm sure a lot of interested groups would have had some strong opinions to share.<\/p>\r\n\r\n<h4>Where rel-canonical should not be used<\/h4>\r\n\r\n<h5>To fix badly configured webservers<\/h5>\r\n\r\n<p>Poorly configured webservers, or rather servers configured without much thought towards URL semantics, appear be the major source of duplicated content.  In that there's no reasoned plan behind these duplications, it's far better that the developer reconfigure the server properly than to start adding in markup to their documents.<\/p>\r\n\r\n<p>Some misconfiguration examples include:<\/p>\r\n\r\n<ul>\r\n\t<li><strong>Site available under www.example.com and example.com<\/strong>.  This is rarely a carefully thought out issue, rather it's often just the server's default behaviour.  The best bet is to pick one subdomain and permanently redirect the other to it.  (It's worth having a look at <a href=\"http:\/\/no-www.org\/\">no-www.org<\/a> while you're making the decision).  I can't think of any strong reason for having it available (as in, being served under rather than redirected from) both domains - the site should be served on whatever subdomain you use on your headed notepaper.<\/li>\r\n\t<li><strong>\/foo and \/foo\/ and \/foo\/index.html all point to the same page<\/strong>.  Again this is just default behaviour, based on a hierarchical model of websites as folders full of files.  This is easily fixed with a bit of config to redirect all of them to \/foo, but it's simple enough for even on a simple site to just standardise on 'missing off index.html in hyperlinks so that the duplicates are never referred to'.<\/li>\r\n<\/ul>\r\n\r\n<p>In both of these cases, I'd estimate the amount of effort involved in 'fixing' the config to be less than that of each page detecting what URL it's served on and generating an appropriate rel-canonical link.<\/p>\r\n\r\n<h5>To allow chaff in URLs<\/h5>\r\n\r\n<p>I previously wrote about how when a form is submitted the querystring is full of extraneous information, and <a href=\"http:\/\/ciaranmcnulty.com\/blog\/2008\/11\/keeping-querystrings-clean-with-zend-framework\">how to make the resultant URLs more canonical using redirects<\/a>.<\/p>\r\n\r\n<p>It would be tempting to do something similar with rel-canonical but <strong>a permanent redirect is appropriate when the two URLs represent the same resource<\/strong>.  In an example like <tt>\/search?size=10&colour=&shape=<\/tt>, the <em>meaning<\/em> of both of the requests is 'items that are size 10'.  Therefore it's entirely appropriate to redirect to <tt>\/search?size=10<\/tt>.<\/p>\r\n\r\n<p>Another case worth looking at is when the results of a search are the same as the results of another.  An example might be if the URLs <tt>\/search?size=10<\/tt> and <tt>\/search?colour=red<\/tt> returned the exact same results. This may happen, for instance, if all the red items were only available in size 10.<\/p>\r\n\r\n<p>In this case the two URLs point at clearly different resources ('list of things that are size 10' vs 'list of things that are red'), and the equivalence may change over time.  Therefore it's not something we'd want to do a redirect between - is it an appropriate place for rel-canonical?<\/p>\r\n\r\n<p>Google's definition is a bit quiet on the details of what the exact semantics of rel-canonical are, but more importantly for these kinds of resources it'd be completely impractical to generate a list of which other resources might happen to contain the same list of results at the given time.<\/p>\r\n\r\n<h4>Where rel-canonical should be used<\/h4>\r\n\r\n<p>After all this griping, I can still see some cases where this new semantic might be useful, if we're going to be abandoning the Content-Location HTTP header (or rather, I can think of a few places where content-location would be appropriate that will presumably transfer over).<\/p>\r\n\r\n<p>The commonality between them really is that we don't want to <em>combine<\/em> the resources, either because we want to slightly vary the way they're presented or because we think that even though they're equivalent at the moment that they might stop being so in the future.<\/p>\r\n\r\n<h5>Presenting resources at different points in a site hierarchy<\/h5>\r\n\r\n<p>A common sort of URL online is: <tt>\/red-widgets\/widget2000<\/tt> that contain an identifier for the resource they're looking at as well as some sort of indication of the hierarchy of the site they're in.<\/p>\r\n\r\n<p>Really this sort of slash-separated construction doesn't contain any special meaning it's largely the same as <tt>?category=red-widgets&product=widget2000<\/tt> except that it contains an implicit hierarchy that hints that you can't have a product identifier without specifying a category.<\/p>\r\n\r\n<p>In a typical application, of course, the page served would contain lots of different contextual stuff such as links to other items in the same category, and maybe some breadcrumbs.  A product may exist in a number of different categories, so we would want to hint that the different URLs were somehow equivalent, without redirecting between them.<\/p>\r\n\r\n<p>Enter rel-canonical, this seems like an entirely appropriate usage to me.  From a resource point of view the page is something like 'widget2000's details in the red-widgets category', which is distinct from 'widget2000's details in the big-widgets category', but their contents are the same and we can hint that using rel-canonical.  Which version is the canonical one I would leave as an exercise to the reader.<\/p>\r\n\r\n<h5>Keeping temporarily-equivalent URLs separate<\/h5>\r\n\r\n<p>This example is from Google's own pages, but is quite a good one.  They quote Wiki type pages, where one wiki entry 'redirects' to another.  The way this is normally handled in Wikis is to not actually do a redirect, but present the same content with a note saying it's a redirect.<\/p>\r\n\r\n<p>Why do this?  Well, the reasoning seems to be that the resources might at some point stop being equivalent, so it's a good idea to keep them separated out.  This would seem to be a reasonable case for a temporary redirect or even a permanent redirect with a short(er) cache header, but in practical terms if the user bookmarks the URL or sends it to a friend, you want them to still have the 'original' URL in their address bar.<\/p>\r\n\r\n<p>This again does seem a reasonable use of rel-canonical, though one I'm less comfortable with.<\/p>\r\n\r\n<h4>Future progress<\/h4>\r\n\r\n<p>I have a few ideas I'd like to see considered for moving this technology forwards:<\/p>\r\n\r\n<ol>\r\n\t<li>Adoption of rel-canonical on A elements as well as just HEAD.  A lot of the time (i.e. in the Wiki example) a valid link to the alternate will already exist on the page.  If the @rel could be added on to this rather than having to exist in the head, it would save a bit of effort and keep the markup local to the link.<\/li>\r\n\t<li>Use of this in Microformats, specifically in the field of finding canonical hCards and so on.  There are <a href=\"http:\/\/microformats.org\/wiki\/hcard-brainstorming-autodiscovery\">already efforts to do similar things<\/a>, but if this semantic becomes widespread it's worth adopting.<\/li>\r\n\t<li>Really, a bit more definition of what this @rel value is trying to indicate in terms of REST semantics.  The wording from Google has so far been fairly focussed on what it means practically for search indexing, but it'd be good to see them look at it from a more academic point of view.<\/li>\r\n<\/ol>\r\n","created":"2009-02-16 14:19:26","url":"rel-canonical-should-be-handled-with-care","tags":["web","microformats","html","seo"],"comments":[{"name":"Simon Harris","website":"http:\/\/pointbeing.net\/","comment":"I'd have to point out that Google weren't acting unilaterally (not this time around at least), rather this initiative was announced by Google, Yahoo and Microsoft on the same day. See also:\r\n\r\nhttp:\/\/ysearchblog.com\/2009\/02\/12\/fighting-duplication-adding-more-arrows-to-your-quiver\/\r\nhttp:\/\/blogs.msdn.com\/webmaster\/archive\/2009\/02\/12\/partnering-to-help-solve-duplicate-content-issues.aspx\r\n\r\nThe idea of (for example) search engine companies adapting HTML for their own purposes does leave me feeling uneasy, all the same.\r\n\r\nThat said, I can't say I prefer either of your methods. A 301 means \"moved permanently\", and in the case of so-called canonical URLs, nothing has moved. The Content-Location header also seems inappropriate, but then my reading of the paragraph from RFC2616 seems to be the complete opposite of yours! I interpret the semantic as being \"here's this other location, I got the relevant stuff from there just now, but it might move\" which is far from what canonical URLs are trying to achieve.\r\n\r\nThe Content-Location header seems to be more approriate for implementation of content-negotation, as in this paper:\r\n\r\nhttp:\/\/www.w3.org\/TR\/cooluris\/#conneg\r\n\r\nI realise that I'm not offering any constructive alternatives, but then I tend also to subscribe to the philosophy that if you need this device in the first place, you're probably doing it wrong. \r\n","created":"2009-02-16 15:39:50"},{"name":"Ciaran McNulty","website":"http:\/\/ciaranmcnulty.com","comment":"Thanks for the comments, Simon.\r\n\r\nI indeed hadn't realised Yahoo! and MS had both implemented the same thing, and the Google announcement I linked to didn't seem to mention it either!  I do wonder how they agree these things.\r\n\r\nI'm also quite interested in your interpretation of content-location.  It's one of those little-used headers so maybe I need to re-read and do some more research on what exactly it means, it's entirely possible you're right.\r\n\r\nHowever, I disagree on a couple of points:\r\n\r\n1. The 301 status may be defined as 'Moved Permanently' but there's some wiggle room in that. \r\n\r\nIn the RFC it says the resource has been moved. I would argue that clearly there was a resource there, because somebody has been able to construct a URL for it.  I don't think that the existence of a past specific representation of that resource is 100% necessary, though clearly this is a bit pedantic.\r\n\r\nThe other argument I'd make is that it's very common to set up a newly-registered domain to 301 redirect to another domain, without first taking time to establish a site there, so common usage of the 301 semantic might have evolved since the RFC was written.\r\n\r\n2. I certainly don't think this counts as 'adapting HTML'.  HTML4 specifically allows any values you like for @rel, and even encourages you to develop your own semantics.  However, if you start defining your own semantics HTML4 says you SHOULD add a @profile to your <HTML>, which this proposal doesn't suggest.  It's a slap-on-the-wrists rather than an error though.\r\n\r\nCertainly defining new @rel\/@rev values to mean specific things is not new, so even if you disagree you may have missed the boat! \r\n","created":"2009-02-16 15:53:22"},{"name":"Ciaron Dunne","website":"http:\/\/www.broadbandgenie.co.uk","comment":"Where this will be useful (unless I'm misunderstanding it) is for shops where you inevitably get a large number of pages with extremely similar content. For example, if you've sorted by price or filtered by colour using text links then the URL might change and the new page would be accessible by Google. You really don't want to confuse Google, so it's a nice way of reminding it which is the master page. Previously this has been handled by nofollow and noindex, but this way seems more elegant - rather than excluding the pages, just communicate the hierarchy to Google.","created":"2009-02-20 11:22:12"}]},{"title":"Simplifying file operations using PHP stream wrappers","content":"<p>When I took the <a href=\"http:\/\/ciaranmcnulty.com\/blog\/2008\/07\/some-thoughts-on-zend-php5-certification\">Zend certification exam<\/a>, one of the areas I really wasn't very clear on was PHP's stream wrappers.  Since reading up on them for the exam, I've been kicking myself for not using them before, the amount of simplification they allow for common code is ridiculous.<\/p>\r\n\r\n<p>As an example, a colleague recently showed me some code he'd written that downloaded a .dat.gz file from a remote server, saved it to disk, unzipped it and save the expanded contents into a file. The original code he showed me was similar to the following (with a lot more error checking and comments):<\/p>\r\n\r\n<p><code><span style=\"color: #000000\">\r\n<span style=\"color: #0000BB\">&lt;?php&nbsp;<br \/><br \/>$tempfile&nbsp;<\/span><span style=\"color: #007700\">=&nbsp;<\/span><span style=\"color: #0000BB\">tempnam<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">sys_get_temp_dir<\/span><span style=\"color: #007700\">());<br \/><br \/><\/span><span style=\"color: #FF8000\">\/\/&nbsp;get&nbsp;the&nbsp;file&nbsp;from&nbsp;FTP&nbsp;to&nbsp;local&nbsp;disk<br \/><\/span><span style=\"color: #0000BB\">$fh&nbsp;<\/span><span style=\"color: #007700\">=&nbsp;<\/span><span style=\"color: #0000BB\">ftp_connect<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #DD0000\">'ftphost.com'<\/span><span style=\"color: #007700\">,&nbsp;<\/span><span style=\"color: #0000BB\">21<\/span><span style=\"color: #007700\">);<br \/><\/span><span style=\"color: #0000BB\">ftp_login<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$fh<\/span><span style=\"color: #007700\">,&nbsp;<\/span><span style=\"color: #DD0000\">'username'<\/span><span style=\"color: #007700\">,&nbsp;<\/span><span style=\"color: #DD0000\">'password'<\/span><span style=\"color: #007700\">);<br \/><\/span><span style=\"color: #0000BB\">ftp_get<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$fh<\/span><span style=\"color: #007700\">,<\/span><span style=\"color: #0000BB\">$tempfile<\/span><span style=\"color: #007700\">,&nbsp;<\/span><span style=\"color: #DD0000\">'\/path\/to\/file.dat.gz'<\/span><span style=\"color: #007700\">);<br \/><\/span><span style=\"color: #0000BB\">ftp_close<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$fh<\/span><span style=\"color: #007700\">);<br \/><br \/><\/span><span style=\"color: #FF8000\">\/\/&nbsp;read&nbsp;data&nbsp;from&nbsp;local&nbsp;.gz&nbsp;into&nbsp;var<br \/><\/span><span style=\"color: #0000BB\">$gh&nbsp;<\/span><span style=\"color: #007700\">=&nbsp;<\/span><span style=\"color: #0000BB\">gzopen<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$tempfile<\/span><span style=\"color: #007700\">,&nbsp;<\/span><span style=\"color: #DD0000\">'r'<\/span><span style=\"color: #007700\">);<br \/><\/span><span style=\"color: #0000BB\">$data&nbsp;<\/span><span style=\"color: #007700\">=&nbsp;<\/span><span style=\"color: #0000BB\">gzread<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$gh<\/span><span style=\"color: #007700\">,&nbsp;<\/span><span style=\"color: #0000BB\">1000000<\/span><span style=\"color: #007700\">);<br \/><\/span><span style=\"color: #0000BB\">gzclose<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$gh<\/span><span style=\"color: #007700\">);<br \/><\/span><span style=\"color: #0000BB\">unlink<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$tempfile<\/span><span style=\"color: #007700\">);<br \/><br \/><\/span><span style=\"color: #FF8000\">\/\/&nbsp;write&nbsp;data&nbsp;to&nbsp;local&nbsp;.dat<br \/><\/span><span style=\"color: #0000BB\">file_put_contents<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #DD0000\">'\/local\/copy\/of\/file.dat'<\/span><span style=\"color: #007700\">,&nbsp;<\/span><span style=\"color: #0000BB\">$data<\/span><span style=\"color: #007700\">);<\/span>\r\n\r\n<\/span>\r\n<\/code><\/p>\r\n\r\n<p>The first thing to note is that the ftp functions have an underscore in, while the gz functions don't.  To me at least, this makes it almost impossible to remember without constantly referring to the reference. The second thing to note is that by downloading the file to disk first, then reading it into memory, then writing it to disk, we're doing a three-step process.<\/p>\r\n\r\n<p>It might be possible to make this code more efficient using the ftp_* and gz* functions by keeping the data in memory more, and writing some sort of pipeline, but frankly stream wrappers are the way to go.  In fact, the whole thing can be rewritten using stream wrappers into a single line:<\/p>\r\n\r\n<p><code><span style=\"color: #000000\">\r\n<span style=\"color: #0000BB\">&lt;?php&nbsp;<br \/><br \/>copy<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #DD0000\">'compress.zlib:\/\/ftp:\/\/username:password@ftphost.com:21\/path\/to\/file.dat.gz'<\/span><span style=\"color: #007700\">,&nbsp;<\/span><span style=\"color: #DD0000\">'\/local\/copy\/of\/file.dat'<\/span><span style=\"color: #007700\">);<\/span>\r\n\r\n<\/span>\r\n<\/code><\/p>\r\n\r\n<p>This has the following benefits:<\/p>\r\n\r\n<ul>\r\n    <li>The original complex operation is rephrased as a 'copy', so it's easier to see at a glance what's going on.<\/li>\r\n    <li>Data is pipelined straight to disk as soon as enough has been downloaded from the FTP to start being decoded.<\/li>\r\n    <li>It's far more compact.<\/li>\r\n<\/ul>\r\n\r\n \r\n<p>This is only really the tip of the iceberg when it comes to the power of stream wrappers, but hopefully enough to pique your interest enough that you <a href=\"http:\/\/uk2.php.net\/manual\/en\/wrappers.php\">go and see for yourself<\/a> how much more they can do for you.<\/p>","created":"2009-04-02 10:59:18","url":"simplifying-file-operations-using-php-stream-wrappers","tags":["php","web"],"comments":[{"name":"Russell","website":"http:\/\/rdjs.co.uk","comment":"I have not used stream wrappers before but will certainly give them a try next time. It is quite amazing what you can accomplish with such a concise code.\r\n\r\nReading this made me think about what a small fraction of PHP I actually use on a day to day basis.\r\n\r\nJust having a quick look through the manual I would estimate that I use about 5% to 10% of the available functionality regularly.\r\n\r\nThe really interesting question would be, how much of the bits that I don't use are actually useful? I think that stream wrappers are a great example of little used functionality that would actually make a developers life easier.\r\n\r\nI suppose that although you only ever use a small percentage of of what PHP is capable of the key is to be aware of more unusual functionality.","created":"2009-04-02 11:38:39"}]},{"title":"Converting HTML to PDF using wkhtmltopdf","content":"<p>I blogged a while back about <a href=\"http:\/\/ciaranmcnulty.com\/blog\/2008\/08\/delivering-pages-as-pdf-using-php\">delivering pages as PDF using PHP<\/a>, and at the time DOMPDF seemed to be the best-of-breed package for converting HTML into PDF for the purposes of delivering PDF versions of web content.<\/p>\r\n\r\n<p>However, I noted at the time that DOMPDF's last release was in July 2007, and it still doesn't look like being updated any time soon. The fundamental problem with packages like DOMPDF is that they tend to implement their own rendering engine.  The thing is, HTML and CSS are both pretty huge now - writing a rendering engine that can cope with all the different combinations is a huge task, so projects like DOMPDF end up missing out important bits of functionality.<\/p>\r\n\r\n<p>A better approach would be to use an existing rendering engine from a browser, and then build a binary around it that can take a website as input and produce a PDF as output.  That way you can get results consistent with how browsers would print a page and if you pick the right engine you'll not have to keep up with any changes to HTML standards, the engine developers will do that for you.<\/p> \r\n\r\n<p>This is essentially the approach <a href=\"http:\/\/code.google.com\/p\/wkhtmltopdf\/\">wkhtmltopdf<\/a> takes: it extracts the open-sourced Webkit renderer used inside browsers like Safari and Chrome and bundles it up into a Linux CLI application which produces some pretty impressive results.<\/p>\r\n\r\n<p>I thought I'd jump right in and start by compiling it on my Debian webserver.  The wkhtmltopdf site has some instructions for building it on Ubuntu, which I thought were worth a try.  The basic procedure was as follows:<\/p>\r\n\r\n<p><code><pre>#apt-get update\r\n#apt-get install libqt4-dev qt4-dev-tools build-essential cmake\r\n\r\n#svn checkout http:\/\/wkhtmltopdf.googlecode.com\/svn\/trunk\/ wkhtmltopdf\r\n#cd wkhtmltopdf\r\n#cmake -D CMAKE_INSTALL_PREFIX=\/usr .\r\n#make\r\n#sudo make install<\/pre><\/code><\/p>\r\n\r\n<p>In my case, this installed a terrifying amount of new packages to my server, but everything went very smoothly.  I was left with a binary in \/usr\/bin and ploughed right in!<\/p>\r\n\r\n<p><code><pre>#wkhtmltopdf http:\/\/ciaranmcnulty.com \/tmp\/ciaranmcnulty.pdf\r\nwkhtmltopdf: cannot connect to X server<\/pre><\/code><\/p>\r\n\r\n<p>Argh.  The rendering engine depends on there being a GUI running on the machine so it can do cool things like generate graphics, render fonts and so forth.  A typical webserver won't be running X, but luckily there are ways around it.  <\/p>\r\n\r\n<p>One such way is <a href=\"http:\/\/www.x.org\/archive\/X11R6.8.1\/doc\/Xvfb.1.html\">xvfb<\/a>, or the X Virtual Frame Buffer.  This is a handy bit of code that basically runs an X instance but without a lot of the overheads.  You can create a temporary X buffer and run a command in it using the xvfb-run binary, the benefit of which is that the x instance gets thrown away afterwards.  I installed xvfb and then invoked it as follows:<\/p>\r\n\r\n<p><code><pre>#apt-get install vfb\r\n#xvfb-run -a -s \"-screen 0 640x480x16\" wkhtmltopdf --dpi 200 \r\n  --page-size A4 http:\/\/ciaranmcnulty.com \/tmp\/ciaranmcnulty.pdf<\/pre><\/code><\/p>\r\n\r\n<p>The options should be fairly self-explanatory, the key things to note are that -a makes xvfb pick an unused display number (to avoid collisions) and -screen starts up the virtual framebuffer with a display with the correct bit depth and dimensions.<\/p>\r\n\r\n<p>The results are fairly good, certainly better than PHPDOM would generate given the same input.  My site layout uses a fair bit of floating and absolute positioning, and the PDF came out exactly as I'd expect:<\/p>\r\n\r\n<p><a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/3426661909\/\" title=\"Website PDF by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3375\/3426661909_46aa0e293d.jpg\" width=\"500\" height=\"500\" alt=\"Website PDF\" \/><\/a><\/p>\r\n\r\n<p>It's important to note that this isn't a bitmap, the text in the PDF is still 'text'.<\/p>\r\n\r\n<p>A quick dig around showed that to print the backgrounds I'd need to have Qt4.5 installed, something I wasn't really prepared to risk my server for.  However, I thought I'd quickly try doing what I should have in the first place.  The wkhtml project provides a linux binary that's statically compiled against Qt.<\/p>\r\n\r\n<p>I downloaded this binary and gave it a whirl.  The results were much better:<\/p>\r\n\r\n<p><a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/3426662113\/\" title=\"Website PDF with backgrounds by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3339\/3426662113_f5de7809fe.jpg\" width=\"500\" height=\"500\" alt=\"Website PDF with backgrounds\" \/><\/a><\/p>\r\n\r\n<p>Frankly I think this is a great rendition of the page, and certainly good enough for an autogenerated PDF on a website.  A bit of further investigation and experimentation has left me pretty impressed with the breadth of CSS print functionality webkit can support.<\/p>\r\n\r\n<p>The next step for me is going to be to try and replace some of the DOMPDF installations in some of my smaller sites, and see how it performs under load. The time taken to generate a PDF is pretty high, and I've not really checked out how xvfb is with concurrency so I'd hesitate to throw it onto a production site straight away, but it'll be my first port of call next time I want to do something with a PDF.<\/p>\r\n","created":"2009-04-09 21:26:58","url":"converting-html-to-pdf-using-wkhtmltopdf","tags":["web","linux"],"comments":[{"name":"Russell","website":"http:\/\/rdjs.co.uk","comment":"Creating a PDF from a web page is not that common an occurrence for me. However this looks great and I am racking my brains to think of somewhere cool to implement this!","created":"2009-04-09 21:45:38"},{"name":"Simon Harris","website":"http:\/\/pointbeing.net\/","comment":"I think that creating a PDF from an existing Web page is only one use case for this. You could use it in *any* situation where you want to generate a PDF in some dynamic, automated way such as via PHP. Rather than try to figure out the PDF format, or the workings of some arcane library, you can generate a page of HTML (which you already know, and is well documented) and then convert that.\r\n\r\nIt'll be interesting to see how well this plays with concurrency and load etc. I'll look forward to a follow-up post somewhere down the line!","created":"2009-04-09 22:14:23"},{"name":"Ciaran McNulty","website":"http:\/\/ciaranmcnulty.com","comment":"Yeah as Simon says, there are really two use cases - one is PDF versions of existing pages, but the other is generating PDFs for different uses using HTML as your templating system.\r\n\r\nThe idea that your PDF templates can be in HTML and sit in your application alongside page templates, and basically be edited by the same people, is pretty attractive.","created":"2009-04-09 23:05:35"},{"name":"Kowalikus","website":"http:\/\/kowalikus.pl","comment":"thanks for help","created":"2010-02-17 12:56:01"},{"name":"John","website":"","comment":"Any chance you could elaborate on installing the static binary?  What commands did you use to get this to work?\r\n\r\nThanks for the article!  Very helpful, I just gotta get it to work now lol.","created":"2010-03-22 20:48:03"},{"name":"nc3b","website":"","comment":"http:\/\/wkhtmltopdf.googlecode.com\/files\/wkhtmltopdf-0.9.5-static-i386.tar.bz2\r\nThat is a statically compiled binary for i386. Just download it, untar it and run it.\r\n\r\nCatalin","created":"2010-03-23 06:05:46"},{"name":"Ciaran McNulty","website":"http:\/\/ciaranmcnulty.com","comment":"@John - It's a case of unarchiving the distributed binary that Catalin has linked to and executing the 'wkhtmltopdf' binary iniside it, adding it to the path if necessary.\r\n\r\n@Catalin - Thanks for the link!","created":"2010-03-24 20:48:37"},{"name":"eva","website":"http:\/\/no tengo ","comment":"muchas gracias co","created":"2010-05-17 12:37:37"},{"name":"Stormy","website":"","comment":"A few notes about the installation:\r\nX package is called xvfb but not vfb.\r\nTherefore the correct command is:\r\n#apt-get install xvfb\r\n\r\nAlso, you will need libxrender1 package for the static build:\r\n#apt-get install libxrender1\r\nSince you don't need a separate directory (static version is a single executable) I suggest you put it in \/usr\/local\/bin or somewhere with an existing path line.","created":"2010-06-14 11:35:20"},{"name":"Stormy","website":"","comment":"More notes about the options:\r\nFirst of all you don't need -s \"-screen 0 640x480x16\" since it's the default mode for xvfb and it seems screen resolution\/mode does not affect wkhtmltopdf output.\r\n\r\nWhat the author forgot to mention is that by default, xvfb does NOT come with any standard (web) fonts so your output PDF will be with a single font.\r\nTo rectify this - you need to install:\r\n#apt-get install msttcorefonts\r\nThen point the path in xvfb-run server options, e.g.:\r\n#xvfb-run -a -s \"-fp \/usr\/share\/fonts\/truetype\/msttcorefonts\" wkhtmltopdf http:\/\/www.angelfire.com\/fl5\/html-tutorial\/fontlist.htm test.pdf\r\n\r\nAnother issue is the default page size for wkhtmltopdf. In my case it was somewhere around 30\" which was not exactly a standard A4.\r\nIf you run onto this, set the page size (in mm) manually with (i.e. for A4 portrait):\r\n--page-width 210 --page-height 297\r\nI suggest you do the same in the html code  just in case.\r\n\r\nOn the side note - althou wkhtmltopdf does give you the option to switch to print media style, the behavour is not a 100% compatible: e.g. in case you span huge html tables over several pages it will not repeat THEAD and TFOOT as by HTML 4 Standart.\r\n\r\nThankfully, it has a powerfull support for headers and footers via HTML\/JS code which should satisfy all your needs (if you're able to code them)...","created":"2010-06-14 17:42:43"},{"name":"Ciaran McNulty","website":"http:\/\/ciaranmcnulty.com","comment":"Thanks for the comments, Stormy. \r\n\r\nInteresting note about the fonts - I didn't have that issue but maybe my distro had the package installed already for some reason.","created":"2010-06-21 11:03:19"},{"name":"Steepe","website":"","comment":"Cool, I'm kinda new to all of this. I really would like to know how do i start.\r\nI have an in-house server with an app on it that is supposed to generate reports. Can u gimme a step by step approach?\r\nThank u so much in advance.\r\nmy email is oluwamayowa@steepe.org","created":"2010-06-26 01:41:27"},{"name":"Pradeep Pant","website":"http:\/\/ppant.wordpress.com","comment":"I m facing a issue with generated PDF size. There is a huge difference between size of the PDF generated in Windows and Linux platforms. \r\nI think this is because of embedding wrong fonts. \r\nThe detailed problem statement can be found in http:\/\/stackoverflow.com\/questions\/3193805\/wkhtmltopdf-generated-pdf-size-issues-in-cent-os-4-6\r\n\r\nWill appreciate if anybody can provide some help.\r\n\r\nThanks,\r\nPradeep\r\n","created":"2010-07-12 09:16:47"},{"name":"Anonymous","website":"","comment":"Last time I looked at xvfb-run it was a shell script that paused for 3 seconds waiting for the X server to start.  You might find that this three second pause is what takes the majority of the time you are seeing for the PDF to be generated.  I'd recommend not using the xvfb-run shell script and instead rapidly polling for the socket to be created in the \/tmp\/.X11 directory.  When this appears the X server is ready to accept client connections and you can invoke wkhtmltopdf.  \r\n\r\nActually, you have probably realized by now that the X server is not even required if you use the static binary (unless you are using web pages with certain plugins like flash).  Try skipping the xvfb-run wrapper entirely.\r\n\r\n","created":"2010-09-16 17:11:19"},{"name":"Eric","website":"","comment":"THANK YOU!!!!!\r\n\r\nYour install procedure was the ONLY one that worked for me for the Amazon Ubuntu AMIs for EC2 by Canonical (http:\/\/alestic.com\/2010\/08\/ec2-ami-canonical).\r\n\r\nYours worked perfectly out of the box. I was pulling my freakin hair out for 6 hrs pior!!","created":"2010-11-21 16:41:57"},{"name":"Brennan","website":"http:\/\/docraptor.com\/","comment":"Another tool for converting html to pdf (or html to excel) that's worth checking out is DocRaptor. http:\/\/docraptor.com\/","created":"2011-04-21 19:04:33"},{"name":"S.B","website":"","comment":"Did anyone get over the font-spacing issue when using QT rather than X?","created":"2011-07-12 11:55:52"},{"name":"Jeremy","website":"http:\/\/jscolton.com","comment":"Hi,\r\n\r\nI am using this tool to create a PDF.\r\n\r\nMy web page has dimensions of: 972px X 687px (29.7cm\/13.5\" at 72dpi, 21.0cm\/9.55\" at 72dpi).\r\n\r\nI put a border on my centralized div to check the edges.\r\n\r\nI used the following syntax to call the PDF tool:\r\n\r\nwkhtmltopdf runme.html runmeA4L.pdf --page-size A4 --orientation landscape --dpi 300\r\n\r\nThe resulting PDF says its properties are: 11.69\" x 8.26\" which is NOT A4!\r\n\r\nWhat is going on?\r\n\r\nI am viewing the PDF in Foxit Reader 3.3\r\n\r\nMany thanks for your help\r\nJeremy C.\r\n","created":"2011-09-20 14:34:52"},{"name":"Jeremy","website":"http:\/\/jscolton.com","comment":"...my mistake, is 2.5cm = 1\" :)\r\nDimensions are correct in the PDF to be 8.26\" x 11.69\" :)","created":"2011-09-20 14:44:20"},{"name":"Jeremy","website":"http:\/\/jscolton.com","comment":"...ok, having fixed my silly mistake I now have a web page size of 841px (11.69\"@72dpi) by 594px (8.26\"@72dpi).\r\n\r\nAnd still the resulting PDF has a border in it covering roughly half the page...It looks like the conversion has squashed the page...\r\n\r\nAny ideas?\r\n\r\nMany thanks again\r\nJeremy C.","created":"2011-09-20 14:51:55"}]},{"title":"Rev-canonical should be handled with care","content":"<p>A short while back, Google and a bunch of other search engines launched @rel=\"canonical\", a standard for specifying that the current page is a copy of another, more canonical, version hosted elsewhere. <a href=\"http:\/\/ciaranmcnulty.com\/blog\/2009\/02\/rel-canonical-should-be-handled-with-care\">I blogged about it at the time<\/a> , and generally approved of the idea but warned against overuse when an HTTP redirect might be more sensible.<\/p>\r\n  \r\n<p>Recently there's been a large amount of discussion about <a href=\"http:\/\/simonwillison.net\/2009\/Apr\/11\/revcanonical\/\">@rev=\"canonical\"<\/a> , a proposal that seems to have been floated with the intention of providing <a href=http:\/\/revcanonical.appspot.com\/ id=zueh title=\"URL shortening services\">URL shortening services<\/a>. The idea is that my page can 'advertise' some other URLs that it can be found at so that clients can pick a different one to use when referring to it.<\/p>\r\n\r\n<p>In this particular use case I could publish a page at <strong><tt>http:\/\/ciaranmcnulty.com\/blog\/2009-04-14\/a-long-blog-post-with-a-complex-url<\/tt><\/strong> that had a @rel=\"canonical\" link to <strong><tt>http:\/\/ciaran.ws\/complex<\/tt><\/strong> (I don't really have that domain, don't bother trying it). Applications that wanted a shorter URL for the content (e.g. Twitter clients, SMS gateways) could then use my shorter URL rather than having to get a more obfuscated one from <a href=\"http:\/\/tinyurl.com\">TinyURL<\/a> or somewhere similar.<\/p>\r\n\r\n<p>The number of sites that have already included the markup is staggering in such a short time, and a testament to how a simple markup idea like this can really take off (if only Microformats could gain this kind of uptake!). I've been reading a lot of the commentary that's bouncing around the HTML blogosphere, and thought I'd put my &pound;0.02 in. Frankly, I fail to see the point of all the hooh-hah, for the following reasons:<\/p>\r\n\r\n<h4>@rev is deprecated.<\/h4>\r\n\r\n\r\n<p>@rev has been taken out of the proposed HTML5 specification because it's confusing and under-used, so this is probably the worst possible time to start a wide-ranging deployment of a new @rev value. The widespread use will have one of two results, either it'll be completely invalidated when HTML5 is finalised, or the deployment will cause @rev to be put back into the HTML5 spec. Either of these are bad results in my opinion.<\/p>\r\n\r\n<p>The reasons @rev was taken out of the HTML5 proposal are that basically:<\/p>\r\n\r\n<ol>\r\n  <li>Most uses of @rev turned out to be typos of @rel.<\/li>\r\n  <li>It was pointed that every @rev value could be turned into a @rel just by changing the keyword to indicate a reverse relation, e.g. @rev=\"parent\" and @rel=\"child\" are equivalent.<\/li>\r\n<\/ol>\r\n\r\n<p>On this basis, a better alternative to @rel=\"canonical\" could be @rel=\"non-canonical\" or something equally trivial - this could also be combined with @rel=\"alternate\".<\/p>\r\n\r\n<h4>Using @rev=\"canonical\" for redirect URLs is wrong<\/h4>\r\n\r\n<p>The idea of @rel=\"canonical\" is to let search engines know that you have duplicate content at other URLs, and which version is the 'correct' one that they should be concentrating on including in their indexes. By that logic, @rev=\"canonical\" should be a list of other URLs at which the same content as the current page exists, but would indicate to a search engine that the current URL is the one that should be used canonically. As an interesting use-case, a search engine could make indexing those URLs low-priority, or just ignore them completely.<\/p>\r\n\r\n<p>However, redirect URLs don't fit in with this usage. They're resources that will redirect to the current one, not resources that contain the same information. The distinction might seem like hair-splitting but I feel it's important that @rel=\"canonical\" is seen as for situations where there are concrete individual pages at differenet URLs.<\/p>\r\n\r\n<p>On a related note, my friend Simon also has some strident opinions about 301 MOVED redirects from URLs that never initially hosted any content that I wish he'd blog about (hint hint!).<\/p>\r\n\r\n<h4>There are better semantics for URL shortening than @rev=\"canonical\"<\/h4>\r\n\r\n<p>OK, so there's probably a use case for saying 'these other URLs have the same content as this page', but nearly all of the discussion has been concentrated on URL shortening.&nbsp; If we're going to use a head LINK to advertise a shorter URL for our content, there has to be a better way than saying 'these other URLs contain the same content' and letting the client check the length of each.<\/p>\r\n\r\n<p>I don't really know what to propose, but something like @rel=\"shorter-url\" or @rel=\"short-url\" or similar would seem to be sensible.&nbsp; Anything's fine as long as it's widespread and gets registered.&nbsp; It'd be nice if someone could knock up an HTML profile for us to use too, but they seem to be on the way out.<\/p>\r\n\r\n<p>Overall, the rev-canonical thing seems to be a fairly simple idea, with a few flaws, that's been overhyped and suddenly implemented everywhere with not much thought going into it.&nbsp; It may well achieve a few things though:<\/p>\r\n\r\n<ol>\r\n  <li>It's got people talking and thinking about @rel values, which is a good thing and might lead to more uptake of technologies like <a href=\"http:\/\/microformats.org\/wiki\/XFN\">XFN<\/a>.<\/li>\r\n  <li>It's prompted a lot of discussion about HTML semantics, which is a good thing and could help promote <a href=\"http:\/\/microformats.org\/wiki\/posh\">POSH<\/a> and <a href=\"http:\/\/microformats.org\">Microformats in general<\/a>.<\/li>\r\n  <li>It's shown people how easy it can be to roll out a simple semantic HTML change on a large site, which has to be a good thing.<\/li>\r\n<\/ol>\r\n\r\n<p>I can only hope that that outweighs all the niggles I have with how rev-canonical is used, and frankly it's currently being used in such a narrow use-case that it doesn't really have a huge impact on the way we use the web.<\/p>\r\n\r\n<p>[EDIT: Just as I posted this, <a href=http:\/\/annevankesteren.nl\/2009\/04\/rev-canonical id=ry8m title=\"Anne van Kesteren made the same points as me\">Anne van Kesteren made the same points as me<\/a> , but in about 10% of the words and with none of the waffle.]<\/p>","created":"2009-04-14 12:31:56","url":"rev-canonical-should-be-handled-with-care","tags":["web","microformats","html","seo"],"comments":[{"name":"Russell","website":"http:\/\/rdjs.co.uk","comment":"I have been loosely following the rev=\"canonical\" debate over the last few days. \r\nIt will be interesting to see if this idea matures into something truly usable but for now there are too many hurdles in the way.\r\nAlthough the whole thing is very interesting I can't help feeling that if some of the fundamental issues cannot be solved then this will all turn out to be a lot of hot air.\r\nThe most important of these, as you correctly point out is the semantics of rev=\"canonical\" and the depreciation of rev in HTML5. \r\n","created":"2009-04-14 15:40:58"},{"name":"Sam Johnston","website":"http:\/\/samj.net","comment":"I am more concerned about this even if only for the reason that getting it wrong (e.g. rel instead of rev) can destroy your site\/business... it's like having the ejector seat button next to the ignition. Save that it's like saying \"I am the canonical URL and that URL over there points at me\" so it must only ever be deployed on the canonical url itself.\r\n\r\nOf all the \/short[_- ]?ur[il]\/ permutations, rel=shortlink is the only one that is safe and unambiguous.\r\n\r\nSam\r\n ","created":"2009-04-21 09:38:37"},{"name":"Ciaran McNulty","website":"http:\/\/ciaranmcnulty.com","comment":"Sam, that's a very good point - a lot of @rev=\"canonical\" deployments do seem to be present on multiple URLs, which sort of defeats the point.\r\n\r\nIt's also massively open to cross-domain abuse, so I doubt any search engines will start paying attention to the @rev version.","created":"2009-04-21 10:33:09"}]},{"title":"Changing an image's aspect ratio without distortion, using Liquid Rescale","content":"<p>Sometimes it's useful to be able to change the shape of a photo - on our website PropertyMall, we like the <a href=\"http:\/\/www.propertymall.com\/property\/search?submit=Submit\">thumbnails on our property search results<\/a> to be a nice uniform size.  Rather than stretch the images, we've chosen on that site to crop them down to the correct size, however this approach can sometimes have odd results.<\/p>\r\n\r\n<p>I've just been looking at the <a href=\"http:\/\/liquidrescale.wikidot.com\/\">Liquid Rescale plugin for GIMP<\/a>, which attempts to let you rescale images to different aspect ratios without having to distort or crop out the important details.  The technology used is Seam Carving, which you can read about in this <a href=\"http:\/\/www.faculty.idc.ac.il\/arik\/imret.pdf\">paper by Shai Avidan and Ariel Shamir<\/a>, or watch <a href=\"http:\/\/www.youtube.com\/watch?v=6NcIJXTlugc\">a video about it on Youtube<\/a>. <\/p>\r\n\r\n<p>As an example, imagine I had a system that only accepted square images. Here is a picture I took a while back of some elephants:<\/p>\r\n\r\n<p><a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/430148669\/\" title=\"Elephants crossing by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm1.static.flickr.com\/166\/430148669_f2364b452a_m.jpg\" width=\"180\" height=\"240\" alt=\"Elephants crossing\" \/><\/a><\/p>\r\n\r\n<p>Using traditional tools, I have two choices for making it square: I can stretch it or crop it.<\/p>\r\n\r\n<div class=\"figure\">\r\n<a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/3446656645\/\" title=\"Elephants pic, with comparison of stretched and cropped versions by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3338\/3446656645_a671dd5a10.jpg\" width=\"500\" height=\"182\" alt=\"Elephants pic, with comparison of stretched and cropped versions\" \/><\/a>\r\n<p class=\"caption\">The original, scaled and cropped versions<\/p>\r\n<\/div>\r\n\r\n<p>In the scaled version, the elephants look far too fat, while in the cropped version some of the interesting foreground and background are missing (ok, you may disagree that they're interesting but let's assume a more talented photographer took it).  What Liquid Rescale offers is a way of preserving the dimensions on the Elephants, which are quite easy to spot when they're wrong, while allowing the water, riverbank and trees to be scaled because that scaling will be much harder to spot.<\/p>\r\n\r\n<p>Just running the image through the plugin gives a slightly better result than the scaled version, but the elephants still look stretched a bit.  The reason for this is presumably that the river isn't uniform enough for the algorithm to detect that it's scaleable.  The plugin allows you to specify certain areas of the image as inviolable, by scribbling over them with a mask - the whole process is quite simple and gives a very acceptable result:<\/p>\r\n\r\n<div class=\"figure\">\r\n<a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/3446656647\/\" title=\"Elephants pic, with example mask and Liquid Rescale by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3585\/3446656647_50b494039f.jpg\" width=\"500\" height=\"201\" alt=\"Elephants pic, with example mask and Liquid Rescale\" \/><\/a>\r\n<p class=\"caption\">The original, original with a mask, and the liquid rescaled version<\/p>\r\n<\/div>\r\n\r\n<p>As you can see, knowing that the elephants should be preserved, the algorithm has picked parts of the river and bank to stretch, and the final result is pretty good! I don't think I'd know at first glance that anything had been moved around.  Designers have been doing this sort of thing for years, of course, but normally with a bit more Photoshop effort, and some gruelling use of the clone tool.<\/p>\r\n\r\n<p><a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/3447514412\/\" title=\"Elephants crossing, Liquid Rescaled by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3311\/3447514412_b48614b49b_m.jpg\" width=\"240\" height=\"240\" alt=\"Elephants crossing, Liquid Rescaled\" \/><\/a><\/p>\r\n\r\n<p>Of course, my main interest was in doing this automatically for website-building purposes, and I have to say the results without adding the hint mask were very disappointing.  However, it seems a useful tool for meddling with my photos in future, so my time wasn't completely wasted.  If I were to pursue this in future for our property thumbnails, I'd have to take a look 'under the hood' at the algorithm and see if there was a way of optimising it for 'building' colours and not for 'sky' colours, but that's not really something I'm likely to find the time for!<\/p>\r\n\r\n<p>If you want to give it a go yourself, Linux people can <a href=\"http:\/\/liquidrescale.wikidot.com\/en:download-page\">get the GIMP plugin<\/a>, or Photoshop users can upgrade to CS4 where the same technology is used and called 'Content Aware Scaling'.<\/p>","created":"2009-04-16 13:23:01","url":"changing-an-images-aspect-ratio-without-distortion-using-liquid-rescale","tags":["photography"]},{"title":"Make all your sites work in IE8 with one fell swoop","content":"<p>At work we have around 100 sites hosted for clients, some of which might not have been updated in a few years (I should point out these are sites we develop, so there's no chance a client's going to edit the site themselves).  <a href=\"http:\/\/blogs.msdn.com\/ie\/archive\/2009\/04\/10\/prepare-for-automatic-update-distribution-of-ie8.aspx\">IE8 is going to be rolled out to Windows users with Automatic Updates enabled<\/a> as of next week, so there's a small worry about auditing these sites in time.<\/p>\r\n\r\n<p>When IE7 came out we had to spend the time going through each of them manually and checking everything was fine.  This time around,<a href=\"http:\/\/msdn.microsoft.com\/en-us\/library\/cc288325(VS.85).aspx\"> although IE8 has a new rendering model, it's possible for the browser to render pages as if it was IE7<\/a>.  In general this has been hugely controversial, but for people in our situation it's pretty handy.<\/p>\r\n\r\n<p>The easiest solution to having sites that may not work in the IE8 renderer is 'do nothing'.  IE8 has a compatibility button that a user can press that renders the page as if it's IE7.  If enough users press this button, a scary centralised Microsoft database marks you as a naughty site and from then on, IE8 users get to see you in 'compatibility mode' until some time in the future when you fix your site and manage to persuade Microsoft that you should be let back in to the halls of the worthy.<\/p>\r\n\r\n<p>However that sounds like a mess, relies on users jumping through some hoops, and might be a bit tricky to get off the list at a later date.  The strategy we've decided to go for is to explicitly mark all our sites as needing to be rendered in compatibility view, then turn this off for each site in turn as they're audited, at our leisure.<\/p>\r\n\r\n<p>The solution that Microsoft have provided is a new HTTP header, <tt>X-UA-Compatible<\/tt>.  The semantics of the header have been defined in a way that allows browsers aside from IE to use it but, frankly, I'll be quite upset if they do.<\/p>\r\n\r\n<p>To mark an HTML page as needing to be rendered in IE7 mode, you'd include the following META tag as the first element in its HEAD, telling it to behave as IE7 would.  I've seen some advice online saying the value should be <tt>IE=IE7<\/tt>, but that will instruct the browser to use IE7 Standards Mode which  isn't ideal. The value I've used here, <tt>IE=EmulateIE7<\/tt> will tell IE8 to use either IE7 Standards Mode or IE7 Quirks Mode based on the page's <tt>&lt;!DOCTYPE&gt;<\/tt> using the same algorithm as IE7.<\/p>\r\n\r\n<p><code><pre>&lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=EmulateIE7\" \/&gt;<\/pre><\/code><\/pre>\r\n\r\n<p>So there's one solution - go through all the sites and add that tag to the pages. I don't like it though, for a few reasons:<\/p>\r\n\r\n<ol>\r\n<li>It's still fairly labour-intensive to open a load of old sites, work out their templating system and add in the markup.<\/li>\r\n<li>This tag would be invalid in HTML5 and I don't want to get into bad habits.<\/li>\r\n<li>It feels like the HTML is being cluttered up.<\/li>\r\n<\/ol>\r\n\r\n<p>What we've gone with in our setup is to include this instruction as a real HTTP header in our Apache httpd.conf for all sites:<\/p>\r\n\r\n<p><code><pre>Header set X-UA-Compatible: IE=EmulateIE7<\/pre><\/code><\/p>\r\n\r\n<p>Now, all of our sites in one go should use the compatibility view.  Then, as we audit them we can add the following to the VirtualHost for each site:<\/p>\r\n\r\n<p><code><pre>Header unset X-UA-Compatible\r\nHeader set X-UA-Compatible: IE=IE8 ; optional<\/pre><\/code><\/p>\r\n\r\n<p>Once we've tested each site, this will then tell IE8 to render using IE8's engine no matter what the compatibility database says.  You could leave off the header completely for sites, of course, but then you'll end up mired in the compatibility database. You would save the slight overhead of having an IE-specific header, though.<\/p>","created":"2009-04-17 11:22:27","url":"make-all-your-sites-work-in-ie8-with-one-fell-swoop","tags":["web","html","apache"]},{"title":"Webmasters: opt out of Phorm now!","content":"<p>I just got the following email:<\/p>\r\n\r\n<blockquote>\"Thank you for your submission to the Phorm website exclusion list. If there are no obvious grounds to doubt the legitimacy of the request the URL will be blocked as soon as possible, usually within 48 hours.\"<\/blockquote>\r\n\r\n<p>You can get one too by writing an email to <a href=\"mailto:website-exclusion@webwise.com\" class=\"vcard\">the <span class=\"fn org\">Phorm<\/span> opt-out address (<span class=\"email\">website-exclusion@webwise.com<\/span>)<\/a> asking them to remove their service from any and all domains you have control over.  I could explain why, but it's best if you just do it first.  What you'll be doing is placing a vote against a fairly insidious new marketing system that most of your users won't know how to opt out of, or even know is happening. Go on, do it before you read the next paragraph.<\/p>\r\n\r\n<p>For years marketing companies have been offering consumers the following deal: <em>\"Give us a completely history of every website you visit, and in exchange we'll give you slightly more targeted adverts\"<\/em>.  Most people on hearing this proposition don't really see what's in it for them, and decline.  Basically, the price in privacy is worth far less to most people than some idea of amazingly personalised advertising.<\/p>\r\n\r\n<p>It's been tried time and time again - <a href=\"http:\/\/www.doubleclick.com\/\">DoubleClick<\/a> are probably the most successful attempt to push this model, they essentially operate by providing ads to different sites from their one domain, and getting each ad to set a cookie in the user browser so the browsing behaviour across sites can be tracked.  This is so unappealing that a whole ecosystem of third-party browser extensions and cookie blockers sprang up.  You could interpret that as a comprehensive rejection of the model by 'the industry'.<\/p>\r\n\r\n<p>Phorm is a technology that tries to apply this model again, but at the ISP level.  The idea is that someone like BT can run all their user traffic through a logging proxy and then use that data to feed into what ads people see (it's <a href=\"http:\/\/en.wikipedia.org\/wiki\/File:Phorm_cookie_diagram.png\">actually more complex than that<\/a>, but that's the gist of the idea).  Unlike Doubleclick, the data on the users preferences therefore comes from all sites they visit, not just ones that are part of the advertising network.  This won't be anything users notice, and its legality is being debated in different territories, but here in the UK <a href=\"http:\/\/www2.bt.com\/static\/i\/btretail\/webwise\/\">BT<\/a>, <a href=\"http:\/\/www.virginmedia.com\/customers\/webwise.php\">Virgin Media<\/a> and <a href=\"http:\/\/www.techwatch.co.uk\/2008\/03\/12\/talk-talk-offer-phorm\/\">TalkTalk<\/a> are already trialling it under the name Webwise.<\/p>\r\n\r\n<p>In theory this is an 'opt in' system for users, but it's being sneaked into the terms of service for these ISPs, as part of the big pack you get when you sign up that nobody ever reads or as one of those 'updates' you sometimes get in the post.  They'll also have an 'opt out' form buried somewhere in their support website, but for most users the whole thing will go on without their noticing.<\/p>\r\n\r\n<p>As a website owner, the only way of opting out is to write to the email address I mention above.  The Phorm docs say the only way of stopping them using traffic information from visits to your site is to add the following to robots.txt:<\/p>\r\n\r\n<p><pre>User-agent: *\r\nDisallow: \/ <\/pre><\/p>\r\n\r\n<p>That's right - their official solution is for you to ban <em>all<\/em> robots from visiting, so you have to sacrifice your search engine rankings if you want to opt out.  Perhaps a more convenient fix would be for Phorm to let us know what their user-agent's name is, but it's of course not in their interest to make it easy.<\/p>\r\n\r\n<p>Phorm is currently being challenged in the courts, but while that's going on I'd urge all website owners to opt out. You'll be doing your users a favour, and you'll be adding your voice to the many who are telling ISPs that this is something we Do Not Want.<\/p>\r\n\r\n","created":"2009-04-20 11:30:22","url":"webmasters-opt-out-of-phorm-now","tags":["web","privacy"],"comments":[{"name":"Russell","website":"http:\/\/rdjs.co.uk","comment":"I feel somewhat conflicted here. My daily income is 90% dependant on websites earning revenue based on a advertising supported business model. I also cannot stand advertising which is *not* targeted. \r\n\r\nHowever it is perfectly clear that the way that phorm have been going about implementing their technology is totally reprehensible. It should categorically be opt-in and not opt-out - both for users and content creators.\r\n\r\nThe fact that big player such as Wikipedia & Amazon have openly opted-out shows that there is significant resistance. Of course there is no way of telling which other sites have opted out without anyone knowing. \r\n\r\nAdditionally, news that European Commission will be starting legal action against the UK's data protection laws on this matter doesn't bode well for the future of the scheme.","created":"2009-04-20 12:17:51"}]},{"title":"Working out the speed of light using a fish pie","content":"<p>Today I brought in some leftover fish pie for my lunch.  I heated it up in our office microwave, but didn't notice that the turntable had slipped off its axis, so the whole thing didn't turn.  When I came to eat the pie, there were hot and cold patches on the top, in a classic <a href=\"http:\/\/en.wikipedia.org\/wiki\/Interference_Pattern\">interference pattern<\/a>.  Microwaves always have these hot and cold areas, which is why the turntable is important.<\/p>\r\n\r\n<div class=\"figure\">\r\n<a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/3459410000\/\" title=\"No more pie by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3580\/3459410000_9f5737f0ec_m.jpg\" width=\"240\" height=\"180\" alt=\"No more pie\" \/><\/a>\r\n<p class=\"caption\">Sadly the pie disappeared before I could take a picture<\/p>\r\n<\/div>\r\n\r\n<p>My tupperware box is about 20cm across, and the hot patches were about half its width across, so I estimated the distance as 10cm.  The label on the microwave gave the frequency of the magnetron as 2.45GHz. The relationship between wavelength and frequency of a wave is as follows:<\/p>\r\n\r\n<blockquote>\r\n\t<p>wavelength = speed of wave &times; frequency<\/p>\r\n\t\r\n\t<p>or:<\/p>\r\n\t\r\n\t<p>speed of wave = wavelength &divide; frequency<\/p>\r\n<\/blockquote>\r\n\r\n<p>So using my observed measurements of 10cm and 2.45GHz, this would give the speed of light as:<\/p>\r\n\r\n<blockquote>\r\n\t<p>speed of wave = wavelength &divide; frequency<\/p>\r\n\t<p><span style=\"visibility:hidden\">speed of wave<\/span> = 10cm &divide; 2.45GHz<\/p>\r\n\t<p><span style=\"visibility:hidden\">speed of wave<\/span> = 1 &times; 10<sup>-1<\/sup>m &divide; 2.45 * 10<sup>-9<\/sup> \/s<\/p>\r\n\t<p><span style=\"visibility:hidden\">speed of wave<\/span> = 1 &times; 10<sup>-1<\/sup>m &divide; 1\/(2.45 * 10<sup>9<\/sup>) \/s<\/p>\r\n\t<p><span style=\"visibility:hidden\">speed of wave<\/span> = 2.45 &times; 10<sup>8<\/sup>m\/s<\/p>\r\n\t<p><span style=\"visibility:hidden\">speed of wave<\/span> = 245,000 km\/s<\/p>\r\n<\/blockquote>\r\n\r\n<p>The actual speed of light is more like 299,792 km\/s, so I'm in the right ball park but about 18% out.  The source of that error will be my 10cm estimate - working backwards it looks like the actual distance should be more like 12cm. <\/p>\r\n\r\n<p>Anyway, I hope that's piqued your interest, I may try and blog a few more experiments you can do around the office, as they occur to me!<\/p>","created":"2009-04-20 14:01:21","url":"working-out-the-speed-of-light-using-a-fish-pie","tags":["science"],"comments":[{"name":"Paul","website":"http:\/\/www.paulgoodwin.com","comment":"Interesting method, but I'd have probably used some kind of Cornish pasty rather than a fish pie on not making the office stink grounds.","created":"2009-04-20 14:10:44"},{"name":"RJ","website":"","comment":"How entertaining. Particularly since I ate my slice warm, while Sarah had hers cold with salad. Such options!","created":"2009-04-20 14:16:41"}]},{"title":"Article in php|architect (maybe)","content":"<p>Sorry for the lack of recent posts - I've been distracted recently working on an article I've written for <a href=\"http:\/\/www.phparch.com\/\">php|architect<\/a>.<\/p>\r\n\r\n<p>In theory it'll be in the August issue but these things are subject to change and frankly they could probably still reject it if they wanted to.<\/p>\r\n\r\n<p>Anyway there's still time to subscribe if you want to get a copy!<\/p>","created":"2009-05-26 10:37:03","url":"article-in-php-architect-maybe","tags":["php","writing"]},{"title":"Simplify pagination logic using a custom Zend_Paginator_Adapter","content":"<p>Pagination logic is something that I've found myself redoing a number of times over the years, and each time it's been a relatively fiddly and painful process.<\/p>\r\n\r\n<p>This time around I decided to check out the <a href=\"http:\/\/framework.zend.com\/manual\/en\/zend.paginator.html\">Zend_Paginator<\/a> component from the Zend Framework, and found the process useful enough to share!  In my case I was using Doctrine to retrieve data from the database.  I'll skip most of the Doctrine-specific stuff, however, as hopefully this will end up as a decent example of how to integrate Paginator with other non-Zend libraries.<\/p>\r\n\r\n<p>When the Paginator is instanced, it's given an instance of an appropriate Adapter and told what the current page is:<\/p>\r\n\r\n<div class=\"php\">\r\n<p><code><span style=\"color: #000000\">\r\n<span style=\"color: #0000BB\">&lt;?php<br \/>$paginator&nbsp;<\/span><span style=\"color: #007700\">=&nbsp;&nbsp;new&nbsp;<\/span><span style=\"color: #0000BB\">Zend_Paginator<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$adapter<\/span><span style=\"color: #007700\">);<br \/><\/span><span style=\"color: #0000BB\">$paginator<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">setItemCountPerPage<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">20<\/span><span style=\"color: #007700\">);<br \/><\/span><span style=\"color: #0000BB\">$paginator<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">setCurrentPageNumber<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">2<\/span><span style=\"color: #007700\">);<br \/><\/span>\r\n<\/span>\r\n<\/code><\/p>\r\n<\/div>\r\n\r\n<p>It can then be used in a View using the <a href=\"http:\/\/framework.zend.com\/manual\/en\/zend.paginator.usage.html#zend.paginator.rendering\">Paginator View Helper<\/a>:<\/p>\r\n\r\n<div class=\"php\">\r\n<p><code><span style=\"color: #000000\">\r\n<span style=\"color: #0000BB\">&lt;?php<br \/><\/span><span style=\"color: #007700\">echo&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">paginationControl<\/span><span style=\"color: #007700\">(<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #0000BB\">$paginator<\/span><span style=\"color: #007700\">,&nbsp;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #DD0000\">'All'<\/span><span style=\"color: #007700\">,&nbsp;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #DD0000\">'my_pagination_control.phtml'<br \/><\/span><span style=\"color: #007700\">);<br \/><\/span>\r\n<\/span>\r\n<\/code><\/p>\r\n<\/div>\r\n\r\n<p>The view helper is given an instance of the paginator, a pagination style, and a view script to use to render the pagination.  Zend give a few <a href=\"http:\/\/framework.zend.com\/manual\/en\/zend.paginator.usage.html#zend.paginator.usage.rendering.example-controls\">example view scripts<\/a> in their documentation.  They're fairly simple in that they access a straightforward API to see which page would be next, previous, and which pages are in the current range.<\/p>\r\n\r\n<p>So, what I needed to do was write an Adapter to work with Doctrine queries. I wanted it to take a query as a parameter and then paginate across the set of results.  This turned out to be pretty simple - the Zend_Paginator_Adapter_Interface that I needed to implement only had 2 methods, count() and getItems().  The finished Adapter looks like this:<\/p>\r\n\r\n<div class=\"php\">\r\n<p><code><span style=\"color: #000000\">\r\n<span style=\"color: #0000BB\">&lt;?php<br \/><\/span><span style=\"color: #007700\">class&nbsp;<\/span><span style=\"color: #0000BB\">My_Paginator_Adapter_DoctrineQuery&nbsp;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #007700\">implements&nbsp;<\/span><span style=\"color: #0000BB\">Zend_Paginator_Adapter_Interface<br \/><\/span><span style=\"color: #007700\">{<br \/><br \/>&nbsp;&nbsp;&nbsp;&nbsp;protected&nbsp;<\/span><span style=\"color: #0000BB\">$_query<\/span><span style=\"color: #007700\">;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;protected&nbsp;<\/span><span style=\"color: #0000BB\">$_count_query<\/span><span style=\"color: #007700\">;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;public&nbsp;function&nbsp;<\/span><span style=\"color: #0000BB\">__construct<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$query<\/span><span style=\"color: #007700\">)<br \/>&nbsp;&nbsp;&nbsp;&nbsp;{<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">_query&nbsp;<\/span><span style=\"color: #007700\">=&nbsp;<\/span><span style=\"color: #0000BB\">$query<\/span><span style=\"color: #007700\">;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">_count_query&nbsp;<\/span><span style=\"color: #007700\">=&nbsp;clone&nbsp;<\/span><span style=\"color: #0000BB\">$query<\/span><span style=\"color: #007700\">;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;}<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;public&nbsp;function&nbsp;<\/span><span style=\"color: #0000BB\">getItems<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$offset<\/span><span style=\"color: #007700\">,&nbsp;<\/span><span style=\"color: #0000BB\">$itemsPerPage<\/span><span style=\"color: #007700\">)<br \/>&nbsp;&nbsp;&nbsp;&nbsp;{&nbsp;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">_query<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">limit<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$itemsPerPage<\/span><span style=\"color: #007700\">)<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&gt;<\/span><span style=\"color: #0000BB\">offset<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$offset<\/span><span style=\"color: #007700\">)<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&gt;<\/span><span style=\"color: #0000BB\">execute<\/span><span style=\"color: #007700\">();<br \/>&nbsp;&nbsp;&nbsp;&nbsp;}<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;public&nbsp;function&nbsp;<\/span><span style=\"color: #0000BB\">count<\/span><span style=\"color: #007700\">()<br \/>&nbsp;&nbsp;&nbsp;&nbsp;{&nbsp;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">_count_query<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">count<\/span><span style=\"color: #007700\">();<br \/>&nbsp;&nbsp;&nbsp;&nbsp;}<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<br \/>}<br \/><\/span>\r\n<\/span>\r\n<\/code><\/p>\r\n<\/div>\r\n\r\n<p>The count() method of course just returns the total results the query would return if run without constraints, while the getItems() method returns the items on the specified page.<\/p>\r\n\r\n<p>Putting it all together, the code in my Action looks like this:<\/p>\r\n\r\n\r\n<div class=\"php\">\r\n<p><code><span style=\"color: #000000\">\r\n<span style=\"color: #0000BB\">&lt;?php<br \/>$query&nbsp;<\/span><span style=\"color: #007700\">=&nbsp;<\/span><span style=\"color: #0000BB\">Doctrine_Query<\/span><span style=\"color: #007700\">::<\/span><span style=\"color: #0000BB\">create<\/span><span style=\"color: #007700\">()<br \/>&nbsp;&nbsp;&nbsp;&nbsp;-&gt;<\/span><span style=\"color: #0000BB\">from<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #DD0000\">'SomeTable'<\/span><span style=\"color: #007700\">)<br \/>&nbsp;&nbsp;&nbsp;&nbsp;-&gt;<\/span><span style=\"color: #0000BB\">where<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #DD0000\">'someField&nbsp;=&nbsp;?'<\/span><span style=\"color: #007700\">,&nbsp;<\/span><span style=\"color: #0000BB\">12<\/span><span style=\"color: #007700\">);<br \/><\/span><span style=\"color: #0000BB\">$adapter&nbsp;<\/span><span style=\"color: #007700\">=&nbsp;new&nbsp;<\/span><span style=\"color: #0000BB\">My_Paginator_Adapter_DoctrineQuery<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$query<\/span><span style=\"color: #007700\">);<br \/><br \/><\/span><span style=\"color: #0000BB\">$paginator&nbsp;<\/span><span style=\"color: #007700\">=&nbsp;&nbsp;new&nbsp;<\/span><span style=\"color: #0000BB\">Zend_Paginator<\/span><span style=\"color: #007700\">(<br \/>&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;<\/span><span style=\"color: #0000BB\">My_Paginator_Adapter_DoctrineQuery<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$query<\/span><span style=\"color: #007700\">));<br \/><\/span><span style=\"color: #0000BB\">$paginator<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">setItemCountPerPage<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">20<\/span><span style=\"color: #007700\">);<br \/><\/span><span style=\"color: #0000BB\">$paginator<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">setCurrentPage<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">_request<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">getParam<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #DD0000\">'page'<\/span><span style=\"color: #007700\">));<br \/><br \/><\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">view<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">paginator&nbsp;<\/span><span style=\"color: #007700\">=&nbsp;<\/span><span style=\"color: #0000BB\">$paginator<\/span><span style=\"color: #007700\">;<br \/><\/span>\r\n<\/span>\r\n<\/code><\/p>\r\n<\/div>\r\n\r\n<p>In the view I use the paginator to render out the pagination widget, but also for the view to obtain the objects it wants:<\/p>\r\n\r\n<div class=\"php\">\r\n<p><code><span style=\"color: #000000\">\r\n<span style=\"color: #0000BB\">&lt;?php<br \/><\/span><span style=\"color: #007700\">echo&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">paginationControl<\/span><span style=\"color: #007700\">(<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">paginator<\/span><span style=\"color: #007700\">,&nbsp;<\/span><span style=\"color: #DD0000\">'All'<\/span><span style=\"color: #007700\">,&nbsp;<\/span><span style=\"color: #DD0000\">'my_pagination.phtml'<\/span><span style=\"color: #007700\">);<br \/><\/span><span style=\"color: #0000BB\">$items&nbsp;<\/span><span style=\"color: #007700\">=&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">paginator<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">getCurrentPageItems<\/span><span style=\"color: #007700\">();<br \/>foreach(<\/span><span style=\"color: #0000BB\">$items&nbsp;<\/span><span style=\"color: #007700\">as&nbsp;<\/span><span style=\"color: #0000BB\">$item<\/span><span style=\"color: #007700\">)&nbsp;{<br \/>&nbsp;&nbsp;&nbsp;&nbsp;<\/span><span style=\"color: #FF8000\">\/\/&nbsp;...<br \/><\/span><span style=\"color: #007700\">}<br \/><\/span>\r\n<\/span>\r\n<\/code><\/p>\r\n<\/div>\r\n\r\n<p>And a very simplified pagination partial would look like this:<\/p>\r\n\r\n<div class=\"php\">\r\n<p><code><span style=\"color: #000000\">\r\n<br \/><span style=\"color: #0000BB\">&lt;?php&nbsp;<\/span><span style=\"color: #007700\">if&nbsp;(isset(<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">previous<\/span><span style=\"color: #007700\">)){&nbsp;<\/span><span style=\"color: #0000BB\">?&gt;<br \/><\/span>&nbsp;&nbsp;&lt;a&nbsp;href=\"<span style=\"color: #0000BB\">&lt;?php&nbsp;<\/span><span style=\"color: #007700\">echo&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">url<\/span><span style=\"color: #007700\">(array(<\/span><span style=\"color: #DD0000\">'page'&nbsp;<\/span><span style=\"color: #007700\">=&gt;&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">previous<\/span><span style=\"color: #007700\">));&nbsp;<\/span><span style=\"color: #0000BB\">?&gt;<\/span>\"&gt;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;prev<br \/>&nbsp;&nbsp;&lt;\/a&gt;<br \/><span style=\"color: #0000BB\">&lt;?php&nbsp;<\/span><span style=\"color: #007700\">}&nbsp;<\/span><span style=\"color: #0000BB\">?&gt;<br \/>&lt;?php&nbsp;<\/span><span style=\"color: #007700\">foreach&nbsp;(<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">pagesInRange&nbsp;<\/span><span style=\"color: #007700\">as&nbsp;<\/span><span style=\"color: #0000BB\">$page<\/span><span style=\"color: #007700\">){&nbsp;<\/span><span style=\"color: #0000BB\">?&gt;<br \/><\/span>&nbsp;&nbsp;&nbsp;&nbsp;&lt;a&nbsp;href=\"<span style=\"color: #0000BB\">&lt;?php&nbsp;<\/span><span style=\"color: #007700\">echo&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">url<\/span><span style=\"color: #007700\">(array(<\/span><span style=\"color: #DD0000\">'page'&nbsp;<\/span><span style=\"color: #007700\">=&gt;&nbsp;<\/span><span style=\"color: #0000BB\">$page<\/span><span style=\"color: #007700\">));&nbsp;<\/span><span style=\"color: #0000BB\">?&gt;<\/span>\"&gt;<br \/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #0000BB\">&lt;?php&nbsp;<\/span><span style=\"color: #007700\">echo&nbsp;<\/span><span style=\"color: #0000BB\">$page<\/span><span style=\"color: #007700\">;&nbsp;<\/span><span style=\"color: #0000BB\">?&gt;<br \/><\/span>&nbsp;&nbsp;&nbsp;&nbsp;&lt;\/a&gt;&nbsp;<br \/><span style=\"color: #0000BB\">&lt;?php&nbsp;<\/span><span style=\"color: #007700\">}&nbsp;<\/span><span style=\"color: #0000BB\">?&gt;<br \/>&lt;?php&nbsp;<\/span><span style=\"color: #007700\">if&nbsp;(isset(<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">next<\/span><span style=\"color: #007700\">)){&nbsp;<\/span><span style=\"color: #0000BB\">?&gt;<br \/><\/span>&nbsp;&nbsp;&lt;a&nbsp;href=\"<span style=\"color: #0000BB\">&lt;?php&nbsp;<\/span><span style=\"color: #007700\">echo&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">url<\/span><span style=\"color: #007700\">(array(<\/span><span style=\"color: #DD0000\">'page'&nbsp;<\/span><span style=\"color: #007700\">=&gt;&nbsp;<\/span><span style=\"color: #0000BB\">$this<\/span><span style=\"color: #007700\">-&gt;<\/span><span style=\"color: #0000BB\">next<\/span><span style=\"color: #007700\">));&nbsp;<\/span><span style=\"color: #0000BB\">?&gt;<\/span>\"&gt;<br \/>&nbsp;&nbsp;next<br \/>&nbsp;&nbsp;&lt;\/a&gt;<br \/><span style=\"color: #0000BB\">&lt;?php&nbsp;<\/span><span style=\"color: #007700\">}&nbsp;<\/span><span style=\"color: #0000BB\">?&gt;<br \/><\/span>\r\n<\/span>\r\n<\/code><\/p>\r\n<\/div>\r\n\r\n<p>Overall I like this way of working, and certainly it was easier to make a new Adapter than I'd feared.  One future possibility is of making individual adaptors for specific queries, as a way of removing the query logic from my contoller.<\/p>","created":"2009-06-13 18:18:16","url":"Simplify-pagination-logic-using-a-custom-zend-paginator-adapter","tags":["php","zend-framework","doctrine"],"comments":[{"name":"DavidZB","website":"","comment":"Awsome!. This may come very helpfull, now that Doctrine is a excelent tool to access database.","created":"2010-03-10 01:47:39"}]},{"title":"Using Twitter as a voting platform","content":"<div class=\"figure narrow\">\r\n<a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/3627788423\/\" title=\"Cast of Star Trek by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3406\/3627788423_c757c36050_m.jpg\" width=\"240\" height=\"160\" alt=\"Cast of Star Trek\" \/><\/a>\r\n<\/div>\r\n\r\n<p>Like a lot of other people, I've had a love\/hate relationship with <a href=\"http:\/\/twitter.com\">Twitter<\/a>.  At first I didn't see the point - it was just <a href=\"http:\/\/facebook.com\">Facebook<\/a> without the features, then I drank the kool-aid, and fell in love with its simplicity and openness.  Nowadays I've backed off a bit and see it as an interesting social phenomenon that I enjoy being a part of. I'd been meaning to check out the <a href=\"http:\/\/framework.zend.com\/manual\/en\/zend.service.twitter.html\">Zend_Service_Twitter<\/a> PHP library for a while, but hadn't really thought of an excuse.<\/p>\r\n\r\n<p>  A few weeks back I was unlucky enough to watch Star Trek V and <a href=\"http:\/\/twitter.com\/CiaranMcNulty\/status\/1981914567\">tweeted about how crap it was<\/a>, despite my friend Nick thinking it's the best of the lot. There was a bit of back and forth, so I posted an order for the films, from best to worst.  A few of my friends then did the same, with the hashtag of #startrekrank as a way of identifying the posts.<\/p>\r\n\r\n<p>It struck me that I could somehow aggregate these results using the Twitter API, so I present to you, <a href=\"http:\/\/startrekrank.com\/\">StarTrekRank.com<\/a>!<\/p>\r\n\r\n<p>Actually building the site was pretty straightforward.  The Twitter API combined with the Zend library make it pretty simple to perform searches.  I'm generating the rankings using the <a href=\"http:\/\/en.wikipedia.org\/wiki\/Condorcet_method#Kemeny-Young_method\">Kemeny-Young method<\/a>, which is fairly processor-intensive - I suspect it's O(n!) for the number of movies - but to my mind produces very fair results.<\/p>\r\n\r\n<p>The way the site operates is to periodically search for #startrekrank via the API, and index any new tweets.  Then if there are some new tweets, the overall ranking is re-calculated automatically.  Finally, the new tweeters get a message sent @them from <a href=\"http:\/\/twitter.com\/startrekrank\">the 'startrekrank' twitter account<\/a> thanking them and directing them back to the main site to view the results.<\/p>\r\n\r\n<p>As a voting platform, Twitter is pretty efficient - voters are authenticated via their Twitter account so you know who the votes have come from.  It's only real downside is that a secret ballot isn't very practical. Now clearly this is all just a bit of fluff, but to me it's an interesting illustration of how Twitter's openness and simplicity allow more complex applications to be built on top of it. <\/p>","created":"2009-06-15 10:30:04","url":"using-twitter-as-a-voting-platform","tags":["php","web","zend-framework","startrekrank"],"comments":[{"name":"Russell","website":"http:\/\/rdjs.co.uk","comment":"10\/10 on the geek scale. ;)","created":"2009-06-15 11:09:36"}]},{"title":"XHTML not dead, despite reports ","content":"<p>With the W3C's recent <a href=\"http:\/\/www.w3.org\/News\/2009#item119\">announcement that work on XHTML 2.0 is not being continued<\/a>, it would be tempting to think that the HTML vs XHTML war has been 'won', and not by the side a lot of people wanted.<\/p>\r\n\r\n<p>However, that's a misconception.  XHTML is alive and well as part of <a href=\"http:\/\/www.w3.org\/TR\/html5\/\">HTML5<\/a>, on more or less equal terms with 'plain' HTML.  It's just not going to be replacing 'tag soup' any time soon unless people start using it!<\/p>\r\n\r\n<p>I'll be taking a look at the options authors have for producing XHTML markup, but lets first look at why someone might want to use XML.<\/p>\r\n\r\n<h4>Pros and cons of XHTML<\/h4>\r\n\r\n<p>Pros:<\/p>\r\n\r\n<ul>\r\n<li>Parsing - XHTML pages can be parsed using standard XML toolkits.<\/li>\r\n<li>Transforms - pages can have XSL transforms applied to them.<\/li>\r\n<li>Embedded content - pages can have other XML namespaces embedded into them.<\/li>\r\n<li>Unambiguous - the author doesn't have to remember whether a tag needs closing or not, or whether the tag should be upper or lowercase.  This also taps into the general developer's 'coolness' gene.<\/li>\r\n<li>XML is 'cool'.<\/li>\r\n<\/ul>\r\n\r\n<p>Cons:<\/p>\r\n\r\n<ul>\r\n<li>Brittleness - it's a lot easier to make a mistake that renders the page invalid XHTML.<\/li>\r\n<li>Deprecated JS - you can't use some constructs like document.write().<\/li>\r\n<li>No iFrames - these aren't supported in XHTML strict.<\/li>\r\n<li>MIME type - there is confusion about which type XHTML should be served as (see next section).<\/li>\r\n<\/ul>\r\n\r\n<p>To be honest, it is worth considering whether those pros are worth it for you.  There are plenty of people who think you should just use HTML 4.01 and not worry about XML.<\/p>\r\n\r\n<h4>Option 1: Use XHTML 1.1 and serve it as text\/html<\/h4>\r\n\r\n<p>Just because XHTML 2.0 has gone away, it doesn't mean you have to jump on board XHTML 5 - browsers will continue supporting XHTML 1.1 for decades to come.<\/p>\r\n\r\n<p>There are a few caveats to consider when using XHTML but serving it as HTML. The <a href=\"http:\/\/www.w3.org\/TR\/xhtml-media-types\/#text-html\">W3C XHTML Media Types recommendation<\/a> states:<\/p>\r\n\r\n<blockquote>\r\n\"In general, this media type is NOT suitable for XHTML except when the XHTML is conforms to the guidelines in Appendix A. In particular, 'text\/html' is NOT suitable for XHTML Family document types that add elements and attributes from foreign namespaces, such as XHTML+MathML [...] XHTML documents served as 'text\/html' will not be processed as XML\"\r\n<\/blockquote>\r\n\r\n<p>In short, even if your DOCTYPE says your document is XHTML 1.1 Strict, your browser will not believe you and will basically parse it as HTML.  There is good reason for this -however: surveys suggest that less than 40% of documents online validate against the doctype they declare.<\/p>\r\n \r\n<p>Anecdotally, the Microformats community has developed a number of proxy services that take HTML pages as input and transform them to other document types, and nearly all of them have run into the problem of supposedly-XHTML documents causing errors when fed into XSL engines.  Most now run content through Tidy before processing.<\/p>\r\n\r\n<p>This option means:<\/p>\r\n\r\n<ul>\r\n<li>Your pages have to be valid HTML 4.01 anyway, by using the Appendix A compatibility guidelines.<\/li>\r\n<li>You can't use any of the XML features like namespaces.<\/li>\r\n<li>Consumers are advised not to trust that it's XML anyway, so browser will render it the same as HTML 4.01.<\/li>\r\n<li>Consequently, this option is best thought of as a subset of HTML 4.01 where the document just happens to also be valid XML.<\/li>\r\n<\/ul>\r\n\r\n<h4>Option 2: Use XHTML 1.1 served as application\/xhtml+xml<\/h4>\r\n\r\n<p>The <a href=\"http:\/\/www.w3.org\/TR\/xhtml-media-types\/#text-html\">same W3C document quoted above<\/a> says:<\/p>\r\n\r\n<blockquote>\r\n\"Family documents. 'application\/xhtml+xml' should be used for serving XHTML documents to XHTML user agents (agents that explicitly indicate they support this media type).\"\r\n<\/blockquote>\r\n\r\n<p>In short, even if you're serving documents as text\/html to some clients, you should use application\/xhtml+xml for those that say they can support it, like most modern browsers except IE.  Very few sites actually do this.<\/p>\r\n\r\n<p>The reason is that when served as application\/xhtml+xml, browsers actually trust that your document is going to be XML and throw valiation errors or break when it's not.  Why is that bad? Well, it turns out it's actually pretty hard to guarantee this, even at the server side.<\/p>\r\n\r\n<p>Developers are reasonably conversant in XML syntax, but does that apply to everyone that gets to generate content on your site?  Maybe there's a junior front-end developer who knows how to bash HTML in Dreamweaver, maybe users can post content onto the site themselves, or maybe your super-genius senior developers will occasionally make a typo.<\/p>\r\n\r\n<p>Essentially the upshot of this option is:<\/p>\r\n<ul>\r\n<li>If you do this for some clients, you still have to do Option 1 for other users, which means you either have to do everything twice, or you have to duplicate your work.<\/li>\r\n<li>You have to do a lot more work ensuring that your markup is valid XML at the server side.<\/li>\r\n<li>You do get to use XML-specific features, as long as you don't mind not serving your content to some users.<\/li>\r\n<\/ul>\r\n\r\n<h4>Option 3: Use XHTML5<\/h4>\r\n\r\n<p>At this point in the post, you're probably thinking that XHTML is a bit of a mess, and might be hoping that I'm going to say that HTML5 solves all the problems.  Sadly, that's not the case.<\/p>\r\n\r\n<p>HTML5 does however clean the issues up somewhat. <\/p> \r\n\r\n<p>For a start, unlike HTML 4.01 vs XHTML 1.1, the XML element of HTML5 is in the core of the specification.  The HTML5 spec (or proposed spec, I should say) defines the elements and attributes in terms of a parsed DOM, and then explains how they should be serialised into XML and 'HTML' forms.\r\n\r\n<p>The spec also goes to great lengths to specify a parsing and error-handling model for the HTML serialisations, so that browsers can know the 'right' way to parse seemingly-malformed content like &lt;p&gt;&lt;b&gt;&lt;\/p&gt;&lt;\/b&gt;> and get a consistent result.  This may seem like a waste of time in a world where XML exists, but in reality with so many hand-coded sites out there, it's a good idea to have a consistent set of rules about how to handle bad markup.<\/p>\r\n\r\n<p>One other way that HTML5 clarifies the split between HTML and XHTML is that the two document types share a consistent DOCTYPE:<\/p>\r\n\r\n<p>&lt;!DOCTYPE html&gt;<\/p>\r\n\r\n<p>Think about the current generation's situation:<\/p>\r\n<ul>\r\n<li>Documents served as text\/html with the HTML 4 doctype are HTML<\/li>\r\n<li>Documents served as text\/html with the XHTML 1.1 doctype are HTML and valid XHTML<\/li>\r\n<li>Documents served as application\/xhtml+xml and the XHTML 1.1 doctype are XHTML<\/li>\r\n<\/ul>\r\n\r\n<p>By having a single DOCTYPE, HTML5 avoids the awkward middle situation:<\/p>\r\n<ul>\r\n<li>Documents served as text\/html with the HTML5 doctype are HTML<\/li>\r\n<li>Documents served as application\/xhtml+xml with the HTML docytpe are XHTML<\/li>\r\n<\/ul>\r\n\r\n<p>This option seems like a good one going forwards, as HTML5 elements become more and more supported by browsers:<\/p>\r\n<ul>\r\n<li>Authors who can guarantee their pages are valid XML can serve them as XHTML to supporting browsers.<\/li>\r\n<li>Authors who think their pages are probably XML can serve them as text\/html and if any mistakes sneak in, it won't matter too much.  The HTML parsing engine in HTML5 should render their documents as intended anyway.<\/li>\r\n<li>Authors who don't want to worry about XML can write their pages as HTML and continue not to care about whether they're parsable by XML toolkits, as they know that the content-type and DOCTYPE they're using offer no such guarantees to consumers.<\/li>\r\n<\/ul>\r\n\r\n<h4>The future<\/h4>\r\n\r\n<p>My own feeling is that the XHTML 1.1 specification didn't bring much to the table for browser manufacturers.  It defined a new MIME type for them to recognise, and started asking them to validate pages as XML in some instances, but didn't actually add much in terms of useful features - browsers already had an HTML rendering engine after all, so it's not as if XHTML made anything easier for them.<\/p>\r\n\r\n<p>Also from the development side, XHTML was implemented on sites for a few different motivations: a sense of neatness, the wish to keep up with the latest thing, but there was rarely a business case for its implementation - very few sites rely on their output being parsable as XML.<\/p>\r\n\r\n<p>Hopefully by having XML at the core of the new specification, XHTML will be more and more embraced.  When user-agents are upgraded to parse the new markup, programming teams will also feel the need to implement the XML parser as well as the HTML parser.  Similarly, when sites are redesigned to be HTML5-compatible, hopefully in a lot of cases XML-compatibility will be included in that work.<\/p>\r\n\r\n<p>However, in another sense hopefully HTML5's strong specification of how HTML should be parsed will enable browser manufacturers to further standardise how they treat 'tag soup', and maybe those amateur hand-coders out there will find that their non-validating badly-written code is at least achieving the goal of working roughly the same no matter what browser looks at it.<\/p>\r\n","created":"2009-07-20 18:33:46","url":"xhtml-not-dead-despite-reports","tags":["web","html"]},{"title":"A quick update on my life","content":"<p>Seeing as I'm updating, here's what's going on with me lately:<\/p>\r\n\r\n<ul>\r\n<li>I've written an article for <a href=\"http:\/\/phparch.com\/\">php|Architect<\/a> - not sure if I'm meant to say what it's about, but it should be in the August issue.<\/li>\r\n<li>I left <a href=\"http:\/\/www.propertymall.com\">PropertyMall<\/a> after four years, to move on to pastures new as a freelancer.<\/li>\r\n<li>After 6 weeks of contracting, and enjoying the freedom, I had a couple of interviews at <a href=\"http:\/\/www.beam.tv\">Beam.tv<\/a>.<\/li>\r\n<li>The upshot of which is, I'll be starting at Beam on Monday! I'm very much looking forward to it.<\/li> \r\n<\/ul>","created":"2009-07-20 19:11:34","url":"a-quick-update-on-my-life"},{"title":"Doctrine article in php|architect","content":"<p>Ah, fame at last!<\/p>\r\n<div>\r\n <div class=\"figure narrow\">\r\n    <a href=\"http:\/\/phparch.com\/c\/phpa\/magazine\/index\"><img src=\"http:\/\/static.phparch.com\/common\/issues\/small\/0104.jpg\" width=\"200\" height=\"258\" alt=\"Cover of php|architect\"\/><\/a>\r\n    <p class=\"caption\">The latest issue<\/p>\r\n<\/div>\r\n\r\n<p>It looks like <a href=\"http:\/\/phparch.com\/c\/phpa\/magazine\/index\">the new issue of php|architect<\/a> is out, and contains my article about <a href=\"http:\/\/www.doctrine-project.org\/documentation\">Doctrine<\/a>, the PHP-based Object Relational Mapper.<\/p>\r\n\r\n<p>It feels like ages since I wrote it (I'm no longer a 'freelance PHP developer' for a start) so re-reading it was actually a slightly weird experience.<\/p>\r\n<\/div>\r\n<p>It's my first published work, and I'm fairly happy with it.  Hopefully I'll get another chance to write for php|architect, I just need to think of another subject that I have something to say about.<\/p>\r\n\r\n<p>The bad news for most of you cheapskates is that php|architect is a subscription-only publication so you can't read my article for free!  However, I would genuinely recommend the magazine, especially as it's only effectively $2.50\/issue.  Obviously I wouldn't recommend it for people who aren't interested in PHP, however!<\/p>","created":"2009-08-27 07:56:25","url":"doctrine-article-in-php-architect","tags":["php","writing","doctrine"]},{"title":"FoWA London 2009 Round-up","content":"   <div class=\"figure narrow\">\r\n\r\n<a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/3986858821\/\" title=\"FoWA London by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm4.static.flickr.com\/3438\/3986858821_73ba3fae6c_m.jpg\" width=\"240\" height=\"180\" alt=\"FoWA London\" \/><\/a>\r\n\r\n<\/div>\r\n\r\n\r\n\r\n<p>I was lucky enough to go along to <a href=\"http:\/\/events.carsonified.com\/fowa\/2009\/london\/content\"><abbr title=\"The Future of Web Applications\">FoWA<\/abbr><\/a> this week with a couple of my colleagues, so I thought I'd do a quick round-up of the two days.<\/p>\r\n\r\n<p>I really enjoyed the conference overall - Kensington Town Hall was pretty adequate for the size of conference, the afterparty at Orchid on the Thursday was fairly epic, and the talks left me really energised about the state of web applications in general.  The only slight blot on the whole thing was the terrible state of the WiFi, which was unusable on the first day and pretty flakey the second.<\/p>\r\n\r\n<p>Rather than going through it in strict chronological order I've grouped the talks into broad themes. When the videos turn up online I'll try and link them through.<\/p>\r\n\r\n<h4>Product Demos<\/h4>\r\n\r\n<p>OK so FoWA talks tend to ostensibly be on some abstract theme, but really a hell of a lot are an excuse to show off some tech the speaker is involved in. There were a few that were really impressive.<\/p>\r\n\r\n<h5>280 North<\/h5>\r\n\r\n<img src=\"http:\/\/280north.com\/i\/280NorthLogoSmall.png\" width=\"160\" style=\"float: right; padding: 0 0 1em 1em; border: 0;\" \/>\r\n\r\n<p>This was a prime example.  <a href=\"http:\/\/tolmasky.com\/\">Francisco Tolmasky<\/a> from <a href=\"http:\/\/280north.com\/\">280 North<\/a> ran through their system for creating online apps, and it's safe to say that it blew the audience's socks off.  <a href=\"http:\/\/objective-j.org\/\">Cappuccino<\/a> is a Javascript application framework while <a href=\"http:\/\/280north.com\/blog\/2009\/02\/announcing-atlas\/\">Atlas<\/a> offers drag-and-drop interface and behaviour design for that framework.  The framework seems incredibly advanced, with pre-built interface elements for windowing and some amazing drag\/drop functionality that makes you forget you're in a web environment.<\/p>\r\n\r\n<p>In short, you can pretty much build a whole web application graphically and just write some JS to control how it talks to your server, then export that as a JS\/HTML interface.  It's all certainly jaw-dropping, and is already being used to create some real apps like 280 Slides.  Francisco was pretty clear that they've aimed Atlas squarely at the 'online app' end of the market - it's not for generating 'websites' - and from what I've seen the JS it produces degrades gracefully and interfaces with a server back-end really cleanly (essentially via any RESTful interface). <\/p>\r\n\r\n<p>The kicker came when Francisco showed how Atlas now allows you to export your application as a native application for your users to run on their desktops without any significant code changes, allowing them to save to native files instead of remote servers.  Taking it a step further, he showed how a native Mac interface designed in Interface Builder could go the other way, and be imported into Cappuccino as a web interface.  I think that was the point at which my brain switched off and assumed I was dreaming.<\/p>\r\n\r\n<p>I'd strongly recommend a look at <a href=\"http:\/\/280north.com\/blog\/2009\/02\/announcing-atlas\/\">their demo video<\/a> for a glimpse of the future in that end of the market.  I can certainly see web apps like ours becoming more and more like desktop applications in their interfaces, and the idea that we could write our site and then offer a desktop version with a unified codebase was pretty exciting.<\/p>\r\n\r\n<h5>Ubuntu Enterprise Cloud<\/h5>\r\n\r\n<img src=\"http:\/\/www.ubuntu.com\/sites\/all\/themes\/ubuntu09\/logo.png\" width=\"160\" style=\"float: right; padding: 0 0 1em 1em; border: 0;\" \/>\r\n\r\n<p><a href=\"http:\/\/blog.gardeviance.org\/\">Simon Wardley<\/a>, billed as a freelancer, gave a great talk about the future of cloud computing.  He talked about the different types of cloud networks (private vs public) and about how dependencies between service providers can lead to a bit of a domino effect when a cloud vendor goes down.<\/p>\r\n\r\n<p>For example, if someone builds an service on <a href=\"http:\/\/aws.amazon.com\/ec2\/\">EC2<\/a>, then sells that service to another party who builds an app, who then has end customers, when Amazon has server issues the whole chain fails. His main thrust was that we were in a very early transitional phase from traditional to cloud computing and that to progress we need to have more compatibility between the different cloud platform vendors to allow portability, for instance in the example above maybe some of the webservers were on Amazon and the rest on another service.<\/p>\r\n\r\n<p>To that end he talked about <a href=\"http:\/\/www.ubuntu.com\/products\/whatisubuntu\/serveredition\/cloud\/UEC\">Ubuntu Enterprise Cloud<\/a> - this is an open source server implementation that's EC2 compatible.  The cool thing there is that you can run your web app on your own server hardware the way you normally do, just with this extra virtualisation layer in place.  Then when your app goes viral and gets digg'd, slashdotted and blogged to death you can quickly duplicate it across EC2 or any other compatible hosted solutions.<\/p>\r\n\r\n<p>It would be good if the existence of this open-source reference implementation helped push the EC2 VM format and APIs towards becoming a de facto standard.  We currently sometimes use some Amazon services at peak load times. It would be interesting to be able to have a mix of local and remote servers and datastores, but treat them all with the same API.<\/p>\r\n\r\n<h5>Facebook and Six Apart<\/h5>\r\n\r\n<img src=\"http:\/\/blogs.ft.com\/techblog\/files\/2009\/08\/facebook-logo.jpg\" width=\"160\" style=\"float: right; padding: 0 0 1em 1em; border: 0;\" \/>\r\n<img src=\"http:\/\/upload.wikimedia.org\/wikipedia\/en\/thumb\/9\/95\/Sixapart_logo.svg\/295px-Sixapart_logo.svg.png\" width=\"160\" style=\"clear: right; float: right; padding: 0 0 1em 1em; border: 0;\" \/>\r\n\r\n<p>Everyone nowadays seems to want to be the gatekeeper for social media, but <a href=\"http:\/\/www.facebook.com\">Facebook<\/a> and <a href=\"http:\/\/sixapart.com\">Six Apart<\/a> both showed their solutions, which are pretty different.<\/p>\r\n\r\n<p><a href=\"http:\/\/www.facebook.com\/cat\">Cat Lee<\/a> from Facebook appeared to have been brainwashed as part of her induction.  Her talk was a bit over-corporate and was about on how you can add social functionality to your sites using <a href=\"http:\/\/developers.facebook.com\/connect.php\">Facebook Connect<\/a>.  It seems like a decent solution if you're a big site who don't mind 'partnering' with Facebook and accepting lots of their branding, but for a seamless solution it's a complete no-go without your app becoming part of some sort of Facebook ecosystem.<\/p>\r\n\r\n<p>In contrast, the talk from Six Apart showed a similar sort of proposition, but one that's a totally open and free platform.  The <a href=\"\"http:\/\/developer.typepad.com\/documentation\/>TypePad development API<\/a> they're exposing now can let you accept login from multiple points (including OpenID and even Facebook Connect!), can keep your user's social graphs on their servers, and even store items of content that the users want to share. <\/p>\r\n\r\n<p>This seems ideal for plugging in 'social' functionality to sites without much backend - a good example is <a href=\"http:\/\/www.zacharyquinto.com\/\">Zachary Quinto's site<\/a> which is basically a brochure site with some TypePad API stuff dropped in, but it's actually pretty feature-rich for users.  I think the Quinto site, for instance, won't need a database as all the assets, logins, friendships and so forth are kept in TypePad.<\/p>\r\n\r\n<h5>Vodafone Mobile Widgets<\/h5>\r\n\r\n<img src=\"http:\/\/online.vodafone.co.uk\/dispatch\/Portal\/SimpleGetFileServlet?dDocName=VF010304&revisionSelectionMethod=latestReleased&inline=false\" width=\"160\" style=\"clear: right; float: right; padding: 0 0 1em 1em; border: 0;\"  \/>\r\n\r\n<p><a href=\"http:\/\/twitter.com\/sanjmatharu\">Sanj Matharu<\/a> from <a href=\"http:\/\/vodafone.co.uk\">Vodafone<\/a> was there to show their new mobile applications platform, <a href=\"http:\/\/www.vodafone360.com\/en\/web\/home\/index\">Vodafone 360<\/a>, and a guy called Joel Moss from <a href=\"http:\/\/codaset.com\/\">Codaset<\/a> went through some of his own experiences developing for it.<\/p>\r\n\r\n<p>The idea for their platform was interesting - apps are basically ZIP files containing HTML, CSS and Javascript that runs the app along with some XML manifests.  The Javascript then gets a lot of the phone's infrastructure exposed to it via a standardised API that presumably irons over all the differences in phone capabilities.  The example app they showed us was a fairly simple battery level monitor, but it's interesting to see that sort of data accessed via Javascript.<\/p>\r\n\r\n<p>The idea is solid, but I have doubts about Vodafone's ability as an operator to push this further.  It's very 'branded' at the moment so maybe other operators would be slow to take it up, but it looks like all the technology involved is portable at least (the application uses the Opera engine to render the apps).<\/p>\r\n\r\n<h5>The Guardian<\/h5>\r\n\r\n<img src=\"http:\/\/i.thisis.co.uk\/274079\/promoBoxModule\/images\/655645\/657461.jpg\" width=\"160\" style=\"clear: right; float: right; padding: 0 0 1em 1em; border: 0;\"  \/>\r\n\r\n<p><a href=\"http:\/\/guardian.co.uk\">The Guardian<\/a> seem to be really committed to joining the online community rather than fighting against it like King Canute or, for instance, Ruper Murdoch.  Chris Thorpe took us through their new initiatives including <a href=\"http:\/\/www.guardian.co.uk\/open-platform\">open APIs<\/a> for finding and sharing Guardian content, open datasets of public information the paper has gathered and curated.<\/p>\r\n\r\n<p>He also took us through their recent project for extracting MPs claim expenses from the PDFs they were published in and constructing a system for members of the public to audit and annotate them, flagging up interesting expense claims for review by the journos.  The interesting bit about this project was that it took remarkably few developer days (I think it was about 3 man days in total) and is hosted on EC2 rather than traditional servers.  Apparently it's so far cost only about &#8356;50.<\/p>\r\n\r\n<h4>Building the future<\/h4>\r\n\r\n<p>Aside from (and overlapping with) product demos, at FoWA you get a certain type of talk that's concerned with predicting how the web application industry will go in the future, and talking about coming technologies that will enable that.<\/p>\r\n\r\n<h5>HTML 5<\/h5>\r\n\r\n<img src=\"http:\/\/komplettie.files.wordpress.com\/2009\/08\/opera-logo.jpg?w=300&h=262\" width=\"160\" style=\"clear: right; float: right; padding: 0 0 1em 1em; border: 0;\"  \/>\r\n\r\n<p><a href=\"http:\/\/www.brucelawson.co.uk\/\">Bruce Lawson<\/a> from <a href=\"http:\/\/www.opera.co.uk\">Opera<\/a> took the stage to demo <a href=\"http:\/\/dev.w3.org\/html5\/spec\/Overview.html\">HTML5<\/a>.  To be honest he didn't go into much that anyone following HTML5's development wouldn't be familiar with but managed to do it in an incredibly engaging and enthusiastic style.  I think most people leaving the talk would have immediately gone and started building stuff in HTML5.\r\n\r\n<h5>Javascript frameworks<\/h5>\r\n\r\n<img src=\"http:\/\/sharkenergy.ca\/magazine\/wp-content\/uploads\/2009\/05\/twitter-logo-001.jpg\" width=\"160\" style=\"clear: right; float: right; padding: 0 0 1em 1em; border: 0;\"  \/>\r\n\r\n<p><a href=\"http:\/\/www.dustindiaz.com\/\">Dustin Diaz<\/a> from <a href=\"http:\/\/twitter.com\">Twitter<\/a> gave a slightly frazzled but fast-paced talk about how awesome Javascript was.  Twitter use jQuery extensively, and he had some great things to say about frameworks in general that I think applied outside of the JS world. <\/p>\r\n\r\n<p>He compared <a href=\"http:\/\/jquery.com\">jQuery<\/a> to cocaine in a fairly longstanding and contrived metaphor, but basically doing a few lines every so often seem great, but if you have a friend who's doing line after line all day long you should take him aside and get him to seek help.<\/p>\r\n\r\n<p>What interested me about Diaz was that he had come into this jQuery organisation but actually had a great pragmatic view of things.  Basically he said that you should use frameworks as the tools they are, for the things they're good at, but keep an eye on the bigger picture and not be afraid to stray outside of the constraints your framework imposes on you.<\/p>\r\n\r\n<h5>Accessiblity<\/h5>\r\n\r\n<img src=\"http:\/\/www.abilitynet.org.uk\/images\/ab_logo.gif\" width=\"160\" style=\"clear: right; float: right; padding: 0 0 1em 1em; border: 0;\"  \/>\r\n\r\n<p><a href=\"http:\/\/twitter.com\/usa2day\">Robin Christopherson<\/a> from <a href=\"http:\/\/www.abilitynet.org.uk\">AbilityNet<\/a> spoke to us about accessibility, and to be honest I was ready for a yawnfest.  Accessibility is something that devs in particular can treat as something of a chore.  Quite to the contrary though, he was really interesting!  He took us through some popular sites via a screen reader, and it was evident that some (e.g. Facebook) were not doing a great job for their disabled users.\r\n\r\n<p>Robin seemed to have plenty of stats to back up the fact that disabled users are a huge market online who are traditionally sidelined even though they tend to be more active online than 'able-bodied' users.<\/p>\r\n\r\n<p>One thing that was food for thought was his anti-CAPTCHA stance - <a href=\"http:\/\/www.zurb.com\/article\/285\/its-official-captchas-are-bad-for-business\">they seem to exclude disabled users while only offering moderate spam catching<\/a>.  It's certainly worth thinking about whether the cost of looking through spam is less than the cost of the users you exclude!  <\/p>\r\n\r\n<p>Something else I found pretty interesting, being in the industry I am, was he showed us a demo of <a href=\"http:\/\/www.annodex.net\/~silvia\/itext\/elephant_no_skin.html\">HTML5 accessible video<\/a>, with subtitles and audio description kept in sync with the video.<\/p>\r\n\r\n<h5>Ruby on Rails<\/h5>\r\n\r\n<img src=\"http:\/\/blog.eukhost.com\/images\/rails_logo.jpg\" width=\"160\" style=\"clear: right; float: right; padding: 0 0 1em 1em; border: 0;\"  \/>\r\n\r\n<p>As a PHP guy this wasn't of massive interest, but <a href=\"http:\/\/yehudakatz.com\/\">Yehuda Katz<\/a> gave a great talk about what to expect in Rails 3, which seems to be the highly successful rival Merb MVC system integrating with Ruby.  What I found most interesting about the talk was the fact he and his partner are doing Pair Programming on Rails, which is very rare in the OSS world.  He seemed to find it pretty valuable and while I'm still suspicious of true pair stuff, it was food for thought.<\/p>\r\n\r\n<h4>Business tips<\/h4>\r\n\r\n<p>Another sort of talk you get at FoWA is of the 'how to build a startup' type.  As a developer these were less relevant, but some still contained some interest.<\/p>\r\n\r\n<h5>Virb<\/h5>\r\n\r\n<img src=\"http:\/\/www.littlepaperplanes.com\/virb.jpg\" width=\"160\" style=\"clear: right; float: right; padding: 0 0 1em 1em; border: 0;\"  \/>\r\n\r\n<p>The talk from <a href=\"http:\/\/chrislea.com\/\">Chris Lea<\/a> from <a href=\"http:\/\/virb.com\">Virb<\/a> was probably the one I got the most from.  Ostensibly about scaling, he was very keen on the idea that developers need to recognise that they're part of real-life businesses, and be more pragmatic.  The most interesting point he made was that a scalable web application isn't one that's had man-hours thrown at it to squeeze out 10% less CPU usage, it's one where the costs of buying more CPU are known, the plan is in place, and the business already knows that the costs will be covered by the increased revenue when expansion happens.<\/p>\r\n\r\n<h5>Digg \/ Freshbooks<\/h5>\r\n\r\n<img src=\"http:\/\/www.citystyleandliving.com\/socialnetworking\/digg-logo.png\" width=\"160\" style=\"clear: right; float: right; padding: 0 0 1em 1em; border: 0;\"  \/>\r\n<img src=\"http:\/\/www.freshbooks.com\/images\/freshbooks2.gif\" width=\"160\" style=\"clear: right; float: right; padding: 0 0 1em 1em; border: 0;\"  \/>\r\n\r\n\r\n<p><a href=\"http:\/\/kevinrose.com\/\">Kevin Rose<\/a> from <a href=\"http:\/\/digg.com\">Digg<\/a>  and <a href=\"http:\/\/www.michaelmcderment.com\/\">Mike McDerment<\/a> from <a href=\"http:\/\/freshbooks.com\">Freshbooks<\/a> started things off with separate talks about growing your audience.  Rose's message was one of engagement with the audience, and that's something that Digg do incredibly well. McDerment hammered home the idea that to do that you need to have some really solid metrics and reporting in place to be able to achieve this.  It's easy to leave reporting as low-priority, then spend the next few years of your product cycle eating up the man days producing ad hoc reports.<\/p>\r\n\r\n<h5>Spymaster<\/h5>\r\n\r\n<img src=\"http:\/\/cache0.techcrunch.com\/wp-content\/uploads\/2009\/05\/picture-77.png\" width=\"160\" style=\"clear: right; float: right; padding: 0 0 1em 1em; border: 0;\"  \/>\r\n\r\n<p><a href=\"http:\/\/www.chrisabad.com\/\">Chris Abad<\/a> from <a href=\"http:\/\/playspymaster.com\/\">Spymaster<\/a> had something like an alternate universe version of the same message, where getting users involved equates to spamifying their friends via Twitter.  I didn't have much time for him but he did have an interesting point about how after a big explosion like they had, you need to take stock of what you've got when the dust settles and think carefully about how to serve your core audience and make the model sustainable (and wow, people still seem to be playing Spymaster - who knew?).<\/p>\r\n\r\n<h5>Revision3<\/h5>\r\n\r\n<img src=\"http:\/\/cybernetnews.com\/wp-content\/uploads\/2008\/05\/revision-3-logo.jpg\" width=\"160\" style=\"clear: right; float: right; padding: 0 0 1em 1em; border: 0;\"  \/>\r\n\r\n<p><a href=\"http:\/\/twitter.com\/dlprager\">David Prager<\/a> from <a href=\"http:\/\/revision3.com\/\">Revision3<\/a>'s theme was essentially that of the Long Tail where even very specialist interest products can gain an audience but with the twist that once you've succeeded in focussing on a small niche, you can then build on that success in a broader sense. I found this pretty convincing - the paradigmatic examples he used were Facebook (originally a University system) and Digg (originally tech news but now general interest stuff).  Coming from a company that concentrates on some mildly niche industries it was interesting stuff, it got me wondering about what we could do next, once we dominate our space!<\/p>\r\n\r\n<h4>Overall<\/h4>\r\n\r\n<p>Well, that's most of what I can remember from FoWA!  A lot of the rest of the time was spent either playing Xbox or wandering round the few other exhibitors - I was impressed with <a href=\"http:\/\/yahoo.co.uk\">Yahoo!<\/a>'s presence and will certainly consider going along to one of their YDN evenings, <a href=\"https:\/\/www.x.com\/blog\/\">PayPal's new, better API<\/a> looked pretty neat, and a few of the smaller companies like <a href=\"http:\/\/go-test.it\/\">Go Test It<\/a> impressed with the things they were creating.<\/p>\r\n\r\n<p>See you next year!<\/p>\r\n","created":"2009-10-06 16:41:35","url":"fowa-2009-london-round-up","tags":["web","fowa"],"comments":[{"name":"Paul","website":"","comment":"All I really took away is that the web app community has suddenly come to the conclusion that awkwardly shoehorning swear words into every sentence shows that you mean what you're saying.","created":"2009-10-06 17:25:04"},{"name":"Ciaran McNulty","website":"http:\/\/ciaranmcnulty.com","comment":"Paul, I know what you mean - there were quite a few potty mouths out there and generally they were the ones with the least to say!","created":"2009-10-06 17:27:10"},{"name":"Tomboa","website":"http:\/\/www.tomboa.net","comment":"Lots of interesting stuff!","created":"2009-10-06 18:01:48"},{"name":"bruce","website":"http:\/\/brucelawson.co.uk","comment":"Glad you liked the talk! ","created":"2009-10-06 20:02:36"},{"name":"DavidM","website":"http:\/\/www.openseo.co.uk","comment":"Thanks for the roundup, Ciaran. Very interesting. ","created":"2009-10-06 20:25:08"},{"name":"Carl","website":"http:\/\/sweetnr.com","comment":"@Paul I blame 37signals... http:\/\/37signals.com\/svn\/posts\/1214-profanity-works","created":"2009-10-07 10:45:00"}]},{"title":"Why you should close PHP sessions as soon as you can","content":"<p>When serving files with PHP, you may notice a curious effect where only one request gets served at a time per user.<\/p>\r\n\r\n<p>You can see it if you're the kind of retro throwback who uses framesets served via PHP - the panels will load in one at a time.  You'll see the same thing if you generate a load of images via PHP - they'll pop up sequentially - and if you serve large video files via PHP like we do at work you may see a curious effect of the downloads queueing up.  Those of you with AJAX applications may be victim to this without realising, but if you're serving JSON\/XML responses from PHP scripts you'll find that your parallel AJAX requests will only get served one at a time.<\/p>\r\n\r\n<p>I've seen this effect a few times and always ended up working around it.  The odd thing is this isn't a setting in Apache or a global slowdown of your server. PHP just refuses to serve more than one request per user at a time.  Luckily <a href=\"http:\/\/twitter.com\/kevindmorgan\" rel=\"friend\">Kevin<\/a> managed to spot the reason, and it was a new one on me even after 9+ years of using PHP (it's possible everyone else knows about it, mind you).<\/p>\r\n\r\n<p>The answer is pretty simple: <strong>PHP can only handle one response at a time if you have an open session<\/strong>.<\/p>\r\n\r\n<p>This makes perfect sense when you think about it - when you <tt>session_start()<\/tt> PHP has to read the data out of the session, then at the end of your script it has to write the data back - if this was happening in parallel then you'd have classic race conditions.  To handle this PHP locks the session on <tt>session_start()<\/tt> and other pending requests will block until the lock is released.<\/p>\r\n\r\n<p>This leads to some guidelines:<\/p>\r\n\r\n<ol>\r\n<li>Don't start sessions with <tt>session_start()<\/tt> until you need them (but remember you have to start them before your script output begins).   This would also imply not using session.autostart if you can avoid it.<\/li>\r\n<li>When serving files via PHP, consider serving them from a different domain so the sessions don't overlap.<\/li>\r\n<li>End your sessions as soon as you can.  By calling <tt>session_write_close()<\/tt> you can release your session lock, so as soon as you know your script won't need to write any more to the session, call it.<\/li>\r\n<\/ol>\r\n\r\n<p>Hopefully this will help out somebody in a similar situation in future!<\/p>\r\n","created":"2009-12-23 10:54:49","url":"why-you-should-close-php-sessions-as-soon-as-you-can","tags":["php"]},{"title":"Wag.gd - short URLs with a point","content":"<p>Short URLs are a bit of a hot-button topic amongst devs - some think they're useful (like <a href=\"http:\/\/rdjs.co.uk\/web\/Implement-revcanonical-and-become-supercool\/4\" rel=\"friend\">Russell<\/a>), some are wary of them (like <a href=\"http:\/\/ciaranmcnulty.com\/blog\/2009\/04\/rev-canonical-should-be-handled-with-care\" rel=\"me\">me<\/a>) and some, like my friend <a href=\"http:\/\/pointbeing.net\/\" rel=\"friend\">Simon<\/a>, rail against them as a waste of time and resource.<\/p>\r\n\r\n<p>Simon, however, is a sensible sort so rather than just making lots of noise about how they suck, he's gone away and tried to think of a sensible use case, then implemented it.<\/p>\r\n\r\n<p>So take a look over at <a href=\"http:\/\/wag.gd\">Wag.gd<\/a> if you're interested in mobile development.  <a href=\"http:\/\/pointbeing.net\/weblog\/2009\/12\/mobile-friendly-short-urls-with-waggd.html\">Simon's written about it<\/a> far better than I could and it's certainly an interesting idea.<\/p>  ","created":"2009-12-29 10:21:32","url":"wag-gd-short-urls-with-a-point","tags":["mobile","web"],"comments":[{"name":"Simon Harris","website":"http:\/\/pointbeing.net\/","comment":"Cheers for the plug, old chap. Slightly chagrined that your blog post created more traffic than mine did, though!\r\n\r\nI'd argue that you've misquoted me somewhat on the subject of short URLs in general, but I can't really back that up. Regardless, I'll try to cobble together a post with my thoughts, now that I'm part of the URL shortening, uh, community.","created":"2009-12-29 22:45:43"},{"name":"Ciaran McNulty","website":"http:\/\/ciaranmnulty.com","comment":"Simon, it's because you refuse to use Twitter and I don't!\r\n\r\nI may have misrepresented you a little - IIRC you were getting quite annoyed at how much attention these services were getting a while back though. \r\n\r\nIt's good to see one with a point, rather than yet another clone of TinyURL!","created":"2009-12-30 08:03:10"}]},{"title":"Clarifying Javascript-PHP communication using JSON-RPC","content":"<p>I think of myself first and foremost as a PHP developer but serious sites are getting more and more JS-heavy as time goes on so it gets harder (and less pragmatic) to try and avoid dealing with JS<->PHP communication of some sort.<\/p>\r\n\r\n<p>I'm a big advocate of RESTful design so tend to end up attempting to write scripts that do lots of GETs and POSTs (as appropriate) and parsing out whatever custom response format I've decided JSON requests will return.  It feels good - like I'm sticking to my principles and 'doing it right' but it's a long painful slog that can feel like self-flagellation at times.<\/p>\r\n\r\n<p>It's also slow and hard to prototype - it's hard to argue in favour of some abstract design idea when it's making you take forever to generate simple tasks .  Sometimes when I feel lazy what I really want is a way of calling my PHP objects directly from the JS and not worrying about what's happening in the underlying HTTP, and that's what <a href=\"http:\/\/json-rpc.org\">JSON-RPC<\/a> provides.<\/p>\r\n\r\n<p>In this blog I'll be showing some simple examples of JSON-RPC in action but first let's look at the pros and cons.<\/p>\r\n\r\n<h4>Why JSON-RPC is awesome:<\/h4>\r\n\r\n<ul>\r\n<li>It includes basic error handling as part of the protocol<\/li>\r\n<li>It hides away all the client-server communications from me the developer<\/li>\r\n<li>It looks a bit like SOAP so is fairly familiar<\/li>\r\n<li>I don't have to spend time writing RESTful response formats and pondering URLs to get working code<\/li>\r\n<\/ul>\r\n\r\n<h4>Why JSON-RPC sucks:<\/h4>\r\n\r\n<ul>\r\n<li>It's not <a href=\"http:\/\/en.wikipedia.org\/wiki\/Rest\">REST<\/a>ful - requests from the client come in as POSTs to on URL without a clear semantic 'resource' behind it<\/li>\r\n<li>There may be specifics to the HTTP that aren't covered by the abstraction<\/li>\r\n<\/ul>\r\n\r\n<p>I suspect a lot of developers reading the lists above will be thinking \"hell yeah, sounds good, how can I have it?\"<\/p>\r\n\r\n<h4>The protocol<\/h4>\r\n\r\n<p>I won't go into all the ins and outs of the protocol but it's worth taking a quick look.  The basic paradigm is that the server has a bunch of methods that can be called by the client, that take different parameters.<\/p>\r\n\r\n<p>An example request is a POST to the server that looks like this:<\/p>\r\n\r\n<p><tt>{ \"method\": \"greet\", \"params\": [\"Ciaran\"], \"id\": 1234 }<\/tt><\/p>\r\n\r\n<p>This is the PHP equivalent of $server->greet(\"Ciaran\").  The ID parameter is used to match up requests and responses.  The response would look like this:<\/p>\r\n\r\n<p><tt>{ \"result\": \"Hello Ciaran\", \"error\": null, \"id\": 1234 }<\/tt><\/p>\r\n\r\n<p>So the result is a string literal with no error conditions - there's not much more to it than that to be honest, aside from error handling.<\/p>\r\n\r\n<p>It would be fairly simple to implement either side of the protocol yourself on a project, but the real strength is of course that once something is a standard, the rest of the world goes to work on it and starts writing up libraries that lazy programmers like us can use! Let's take a look at two libraries, a Zend Framework one on the PHP end and a jQuery one on the Javascript end.<\/p>\r\n\r\n<h4>JSON-RPC in PHP: Zend_Json_Server<\/h4>\r\n\r\n<p><a href=\"http:\/\/framework.zend.com\/manual\/en\/zend.json.server.html\">Zend_Json_Server<\/a> is pretty simple to use, you will need a class that exposes and handles the methods you're going to be using that's properly docblock commented (this is used by the component to see the parameter and return types):<\/p>\r\n\r\n<code><pre>class My_Service_Handler\r\n{\r\n    \/**\r\n    * @param string $name\r\n    * @return string\r\n    *\/\r\n    public function greet($name)\r\n    {\r\n        return \"Hello $name\";\r\n    }\r\n}\r\n<\/code><\/pre>\r\n\r\n<p>You can then proxy JSON-RPC requests along into this object using the Zend Framework component, Zend_Json_Server:<\/p>\r\n\r\n<code><pre>\r\n$server = new Zend_Json_Server();\r\n$server->setClass('My_Service_Handler');\r\n$server->handle();\r\n<\/pre><\/code>\r\n\r\n<p>Now any requests like our examples above will get an appropriate response.  Again fairly straightforward stuff I think, and should be familiar to anyone who's used a SOAP server in PHP.  All of the complexity of decoding the response and encoding the request is handled by the component.<\/p>\r\n\r\n<h4>JSON-RPC in JQuery: zendjsonrpc<\/h4>\r\n\r\n<p>There are a huge number of jQuery plugins to do JSON-RPC, but <a href=\"http:\/\/plugins.jquery.com\/project\/zendjsonrpc\">this one is specifically written to work with the Zend_Json_Server<\/a> so I figured it's as good an example as any.  If you look at the source code of the plugin it's fairly straightforward and I'm sure it'd be easy to write your own if you preferred.  The basic usage is:<\/p>\r\n\r\n<code><pre>\r\nvar client = jQuery.Zend.jsonrpc({url: '\/path\/to\/service\/handler.php'});\r\nvar message = client.greet(\"Ciaran\");\r\nalert(message);\r\n<\/pre><\/code>\r\n\r\n<p>As you can see, once the client object is constructed with the service URL you as a developer have a local JS object that exposes the exact same methods the My_Service_Handler has.<\/p>\r\n\r\n<h4>Overall<\/h4>\r\n\r\n<p>What I really find attractive about the JSON-RPC protocol is that, well, someone else has implemented it for me in the two components above.  That means that I can stop worrying about AJAX and start pretending that my PHP object is somehow present locally in my JS and that I can just call its methods at will.<\/p>\r\n\r\n<p>That's a really powerful abstraction. No doubt like most abstractions there are places where it leaks around the edges but the simplicity of the idea and the clarity it brings to JS<->PHP communication make it an approach I'll be certainly investigating for my next JS-heavy project.<\/p>\r\n","created":"2010-03-15 11:44:02","url":"clarifying-javascript-php-communication-using-json-rpc","tags":["php","web","javascript","zend-framework","jquery"],"comments":[{"name":"Nick","website":"http:\/\/dev.nuclearrooster.com","comment":"Hey, I'm looking at JSON RPC 2.0 instead of REST as well.  It seems like it is a little more defined (error handling, etc) than REST and faster to get up and running.  Any more thoughts after using it for a while?  Thanks","created":"2011-01-10 17:55:52"}]},{"title":"Tether to iPhone with Ubuntu 9.10 Karmic Koala","content":"<p>I just did a fresh Ubuntu Karmic reinstall after an ill-conceived upgrade to a Lucid Alpha, so I had to try and retrace my fairly muddled steps in configuring iPhone tethering.   \r\n\r\n<p>Because I had a fair idea what I was doing this time it was pretty easy, so I figured I'd best document the steps for the next unfortunate soul trying to do the same.  I'd also be interested to hear if the same steps apply to Lucid once it's out of Beta.\r\n\r\n<div style=\"float: right; margin: 0 0 1em 1em; clear: right\"><a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/4460108683\/\" title=\"iPhone tethering by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm5.static.flickr.com\/4041\/4460108683_bf732c6c7e_m.jpg\" width=\"160\" height=\"240\" alt=\"iPhone tethering\" \/><\/a><\/div>\r\n\r\n<p>The first thing to do is get tethering enabled by your operator.  For some reason O2 can only enable it overnight so make sure you get it well before you'll need it.  Once it's enabled, you'll find your phone has a new option under Settings-&gt;General-&gt;Network-&gt;Internet Tethering.  Make sure you turn it on in here and then forget about it - it's only enabled for devices that are paired over Bluetooth or USB so there's not much of a security worry.\r\n\r\n<p>The next step is to get the Ubuntu side sorted.  The best bet is to install the Bluetooth Manager widget Blueman, which will replace your existing Bluetooth widget.  Blueman is much better than the default simple widget, but unfortunately either the way the iPhone exposes its network access point is non-standard or it's a bit advanced because the older version of Blueman in the Ubuntu Karmic sources is not capable of connecting - you'll need to install a newer version from Blueman directly.\r\n\r\n<p>The best way of doing this is to add the Blueman PPA and install it from them via apt:\r\n\r\n<code><pre>\r\n$ sudo add-apt-repository ppa:blueman\/ppa\r\n$ sudo apt-get upgrade\r\n$ sudo apt-get install blueman\r\n<\/pre><\/code>\r\n\r\n<p>I found after doing this the old bluetooth widget was hanging around, but restarting X fixed that.\r\n\r\n<p>To make the iPhone discoverable, go to Settings-&gt;Network-&gt;Bluetooth and just leave the page open.  Most phones require you to somehow make your handset discoverable, but Apple decided that it's discoverable just for as long as you're on this page.\r\n\r\n<p>Next, pop open Blueman and click search, and you'll see a list similar to this one:\r\n\r\n<div><a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/4460136087\/\" title=\"Blueman by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm5.static.flickr.com\/4041\/4460136087_5fdd62d92a_o.png\" width=\"407\" height=\"245\" alt=\"Blueman\" \/><\/a><\/div>\r\n\r\n<p>Right-click on the iPhone and select Pair, both the phone and the PC will pop up a confirmation code and you should confirm on both that they're the same.  After pairing happens you should be able to right-click on the iPhone in Blueman and select 'Network access point' to connect via it (even if the phone is not on the Bluetooth screen).\r\n\r\n<p>As an added bonus, you should find after your next reboot there'll be a new entry in Network Manager next to the available wireless networks called something like 'Network Access Point on <name of phone>' so you can initiate a bluetooth\/tethering connection with one click in future without having to run Blueman.\r\n","created":"2010-03-24 20:40:23","url":"tether-to-iphone-with-ubuntu-9-10-karmic-koala","tags":["apple","linux","ubuntu"],"comments":[{"name":"Andre Lucas","website":"","comment":"FWIW the lucid beta2 version of Blueman worked just fine. Ta for your article. -A","created":"2010-04-20 13:27:28"},{"name":"Ciaran McNulty","website":"http:\/\/ciaranmcnulty.com","comment":"Andre, That's interesting because I had a brief try on the Lucid alpha and it didn't work - I'll try and follow this up once Lucid gets a proper release.","created":"2010-04-21 15:51:53"},{"name":"Dave","website":"","comment":"Thanks for the tutorial. This worked fine with Lucid Linux release candidate","created":"2010-04-27 00:20:32"}]},{"title":"Frontal - a new approach to triggering Javascript behaviour ","content":"<p>My friend <a href=\"http:\/\/sweetnr.com\">Carl<\/a> has just released <a href=\"http:\/\/sweetnr.com\/70\">a really interesting Javascript library called Frontal<\/a>.  I've had a night to sleep on it and thought I'd share my thoughts.<\/p>\r\n\r\n<p>The key problem Frontal addresses is <em>'some Javascript needs to be run only on some pages'<\/em>.  There are a few different approaches to this:<\/p>\r\n\r\n<h4>Per-page scripts<\/h4>\r\n\r\n<p>The first approach is to have lots of Javascripts that only apply for the current page, and insert them in the HEAD of the document:<\/p>\r\n\r\n<code><pre>\r\n&lt;head&gt;\r\n  &lt;script src=\"base.js\"&gt;&lt;\/script&gt;\r\n  &lt;script src=\"something-page-specific.js\"&gt;&lt;\/script&gt;\r\n&lt;\/head&gt;\r\n<\/pre><\/code>\r\n\r\n<p>Pros:<\/p>\r\n<ul>\r\n<li>You can attach your scripts modularly<\/li>\r\n<li>No inline scripts<\/li>\r\n<\/ul>\r\n\r\n<p>Cons:<\/p>\r\n<ul>\r\n<li>Lots of JS files to keep track of<\/li>\r\n<li>Lots of HTTP requests to your server<\/li>\r\n<li>Each page's JS isn't precached<\/li>\r\n<li>No way of passing parameters to the script, everything has to be hard-coded<\/li>\r\n<\/ul>\r\n\r\n<h4>Inline triggers<\/h4>\r\n\r\n<p>A second approach is to have some base library but then activate with some inline script in your page:<\/p>\r\n\r\n<code><pre>\r\n&lt;head&gt;\r\n  &lt;script src=\"base.js\"&gt;&lt;\/script&gt;\r\n  [...]\r\n&lt;\/head&gt;\r\n&lt;body&gt;\r\n  [...]\r\n  &lt;script&gt;\r\n    doSomeBehaviour('foo', 'bar');\r\n  &lt;\/script&gt;\r\n&lt;\/body&gt;\r\n<\/pre><\/code>\r\n\r\n<p>Pros:<\/p>\r\n<ul>\r\n<li>One JS that's easily cached<\/li>\r\n<li>Triggered functionality per-page<\/li>\r\n<\/ul>\r\n\r\n<p>Cons:<\/p>\r\n<ul>\r\n<li>Mixes JS with HTML<\/li>\r\n<\/ul>\r\n\r\n<h4>POSH triggering<\/h4>\r\n\r\n<p>This third approach is one I've preferred to use in the past is to have the Javascript pick up elements that exist in the markup in some sort of <a href=\"http:\/\/microformats.org\/wiki\/posh\">POSH<\/a> form.<\/p>\r\n\r\n<code><pre>\r\n&lt;head&gt;\r\n  &lt;script src=\"base.js\"&gt;&lt;\/script&gt;\r\n  [...]\r\n&lt;\/head&gt;\r\n&lt;body&gt;\r\n  [...]\r\n  &lt;div id=\"foo\"&gt;\r\n    &lt;span class=\"bar\"&gt;An element&lt;\/span&gt;\r\n  &lt;\/div&gt;\r\n&lt;\/body&gt;\r\n<\/pre><\/code>\r\n\r\nIn this instance the base.js would pick up that there's an element with @id=\"foo\" and do some action based on it (or rather, attach some behaviour).\r\n\r\n<p>Pros:<\/p>\r\n<ul>\r\n<li>One JS that's easily cached<\/li>\r\n<li>JS only applies when needed<\/li>\r\n<\/ul>\r\n\r\n<p>Cons:<\/p>\r\n<ul>\r\n<li>Lots of findById() to check every possible element that might trigger a behaviour<\/li>\r\n<li>Can only apply after DOM is ready<\/li>\r\n<\/ul>\r\n\r\n<h4>The Frontal approach - path-based actions<\/h4>\r\n\r\n<p>What frontal does quite simply and brilliantly is allow you to specify Javascript that gets run based on the URL of the current script:<\/p>\r\n\r\n<code><pre>\r\n$frn('\/blog', function(){\r\n   \/\/ some blog-specific action\r\n});\r\n\r\n$frn('\/news\/latest', function(){\r\n   \/\/ e.g. script that refreshes the list of news items\r\n});\r\n\r\n$frn(\/blog\\\/.*zend.*\/, function(){\r\n   \/\/ action for blog items with Zend in the URL\r\n});\r\n<\/pre><\/code>\r\n\r\nI find this approach really interesting, and would be pretty keen to see how it can be integrated with your average framework's routing mechanism (specifically ZF and the URL view helper).\r\n\r\n<p>Pros:<\/p>\r\n<ul>\r\n<li>One big JS<\/li>\r\n<li>JS only applied on pages where it's needed<\/li>\r\n<\/ul>\r\n\r\n<p>Cons:<\/p>\r\n<ul>\r\n<li>Page-specific JS might not be fine-grained enough<\/li>\r\n<li>Need to link to Frontal as a library to use (unless you replicate the pattern)<\/li>\r\n<\/ul>\r\n\r\n<h4>Looking forward<\/h4>\r\n\r\n<p>At first glance I tend to think that a mixed strategy of the Frontal and POSH approaches - I still tend to think that JS should get as much of the 'stuff' it needs to understand from POSH-esque structures within the page (e.g. a Google Map probably shouldn't have it's coordinates hardcoded in the JS). However it does get costly to keep traversing the DOM, and you can't always wait for the DOM to be available, so there's a strong argument for combining that with Frontal and nesting the POSH checking inside Frontal clauses.<\/p>\r\n\r\n<p>I'm going to keep nagging Carl about getting this integrated into a Zend project, and would like to see it bundled into a jQuery plugin.<\/p>\r\n\r\n","created":"2010-03-25 10:14:17","url":"frontal-a-new-approach-to-triggering-javascript-behaviour","tags":["javascript","frontal"],"comments":[{"name":"Russell","website":"http:\/\/rdjs.co.uk","comment":"In nearly all sites, except for the very biggest and the very smallest, I much prefer to have several seperate js files containing code for a specific part of the website or to perform a specific task. The same preference applies to css files too.\r\nFor cacheing and http requests this is not ideal but for simplicity, and ease of maintenance I much prefer it. \r\nIn situations where a single js file is prefered I could see the value in frontal. \r\n\r\nJquery plugin would be a massive win.","created":"2010-03-25 11:25:32"},{"name":"Jani Hartikainen","website":"http:\/\/codeutopia.net","comment":"This is an interesting approach indeed, but I can see some issues..\r\n\r\nFirstly, if you have a lot of page specific scripts, do you really want to load all of them on all pages? Not only will this increase the size of the script, it'll make parsing it slower due to size.\r\n\r\nSecondly, when developing JS code it's a good idea to separate it into multiple files - you don't put all of your PHP into one file either.\r\n\r\nPersonally I'm in favor of using a script to automatically concatenate and cache all scripts a specific page needs into a single file.","created":"2010-03-25 12:19:55"},{"name":"Ciaran McNulty","website":"http:\/\/ciaranmcnulty.com","comment":"@Russell - is that for performance, or is it for ease of use at your end?\r\n\r\nWhat I've been thinking about this morning is that somehow you could specify the which JS applies to which page somewhere within your MVC app, and then the MVC framework could compile it into one big JS with Frontal rules giving the best of both worlds.","created":"2010-03-25 12:21:43"},{"name":"Ciaran McNulty","website":"http:\/\/ciaranmcnulty.com","comment":"@Jani Organisationally in my codebase sure, the same applies to things like CSS, but if you're concatenating and caching before serving to the user, something like Frontal makes big sense.","created":"2010-03-25 12:23:30"},{"name":"Russell","website":"http:\/\/rdjs.co.uk","comment":"Yeah, for ease of use rather than performance. Then combat any performance issues caused by multiple http requests with the concatenating and caching Jani recommends. ","created":"2010-03-25 14:00:18"},{"name":"Carl","website":"http:\/\/sweetnr.com","comment":"Glad to see i've inspired some debate.\r\n\r\nWhen i was first thrashing out this idea my first thought was to write a jQuery plugin. But wasn't convinced that my approach followed the jQuery paradigm of finding elements and then doing stuff to them.\r\n\r\nThat said it would only take a few lines to layer on the jQuery sugar.\r\n\r\nWe've just started a fresh ZF project at work and i plan to try writing our JavaScript on top of frontal; i'll be sure to write up my findings.","created":"2010-03-25 19:45:07"}]},{"title":"Zend Framework bindings for Frontal","content":"<p>Having thought further about <a href=\"\/blog\/2010\/03\/frontal-a-new-approach-to-triggering-javascript-behaviour\">Frontal, Carl's JS library<\/a>, I wrote a quick View Helper to make it easier to use it in Zend Framework projects.<\/p>\r\n\r\n<p>It's <a href=\"http:\/\/dl.dropbox.com\/u\/1845336\/Frontal-ZF.tar.gz\">available to download<\/a> on Dropbox, it's available under the MIT licence.  I'll bung it up on somewhere like GitHub once I work out how Git works.<\/p>\r\n\r\n<h4>Basic usage<\/h4>\r\n\r\n<p>Before you do anything you'll need to register the helpers in your <tt>application.ini<\/tt>:<\/p>\r\n\r\n<code><pre>\r\nresources.view.helperPath.Frn_View_Helper = \/path\/to\/Frn\/View\/Helper\r\n<\/pre><\/code>\r\n\r\n<p>to get it to output anything you'll need to echo the frontal helper at the bottom of the page:<\/p>\r\n\r\n<code><pre>\r\n...\r\n&lt;?= $this->frontal() ?&gt;\r\n&lt;\/body&gt;\r\n<\/pre><\/code>\r\n\r\n<p>By default this will echo nothing! Don't panic, it'll start doing things once you've loaded some stuff into it.  The main use-case here is that you're echoing the helper out in some sort of template (Zend_Layout particularly) but pushing configuration into it from your individual views.<\/p>\r\n\r\n<p>Firstly, you can override the path Frontal will use, for instance if there's a page appears under lots of different URLs but you just want one rule that matches it against '\/foo':<\/p>\r\n\r\n<code><pre>\r\n&lt;? $this->frontal->location('\/foo'); ?&gt;\r\n\r\nwill output:\r\n\r\n&lt;script&gt;\r\n$frn.location('\/foo');\r\n&lt;\/script&gt;\r\n<\/pre><\/code>\r\n\r\n<p>Secondly, you can provide some data that frontal might find useful (rather than dump it in global scope).  The data is auto-converted to JSON so it's a fairly nice way of feeding data from PHP to JS:<\/p>\r\n\r\n<code><pre>\r\n&lt;? $this->frontal->data(array('foo', 'bar')); ?&gt;\r\n\r\nwill output:\r\n\r\n&lt;script&gt;\r\n$frn.data([\"foo\",\"bar\"]);\r\n&lt;\/script&gt;\r\n<\/pre><\/code>\r\n\r\n<p>That's pretty much it for now, but it works pretty well and I'm going to be building it into a work project.<\/p>","created":"2010-04-06 13:27:18","url":"zend-framework-bindings-for-frontal","tags":["php","javascript","zend-framework","frontal"]},{"title":"Always declare a media type in your CSS links","content":"<p>An odd one today at work, a site had the following:<\/p>\r\n\r\n<code><pre>\r\n&lt;link rel=\"stylesheet\" href=\"styles.css\" \/&gt;\r\n&lt;link rel=\"stylesheet\" href=\"print.css\" media=\"print\" \/&gt;\r\n<\/pre><\/code>\r\n\r\n<p>What was puzzling was that when you printed the page from Firefox, none of the styles from <tt>styles.css<\/tt> were being applied. I for one had assumed that it would be inherited.<\/p>\r\n\r\n<p>It turns out that it's not clear what the default media value for the <tt>link<\/tt> element is.  <a href=\"http:\/\/www.w3.org\/TR\/REC-html40\/present\/styles.html#adef-media\">The HTML4 spec<\/a> says:<\/p>\r\n\r\n<blockquote>\r\nThis attribute specifies the intended destination medium for style information. It may be a single media descriptor or a comma-separated list. The default value for this attribute is \"screen\".\r\n<\/blockquote>\r\n\r\n<p>Pretty clear-cut, although maybe not what I expected - looks like if the <tt>media<\/tt> attribute is missing the styles only apply to screens. But hang on, look what <a href=\"http:\/\/dev.w3.org\/html5\/spec\/Overview.html#attr-link-media\">the HTML5 spec<\/a> says:<\/p>\r\n\r\n<blockquote>\r\nThe default, if the media attribute is omitted, is \"all\", meaning that by default links apply to all media.\r\n<\/blockquote>\r\n\r\n<p>That's a more sensible default of course, but it's unusual to see the HTML5 spec completely change behaviour like this. The fact it has changed indicates that browsers are (currently) being inconsistent about which value to default to.<\/p>\r\n\r\n<p>For now, it seems sensible to <em>always<\/em> declare a media value in your <tt>link<\/tt>s, and not make assumptions like we did!<\/p>\r\n\r\n","created":"2010-07-08 10:16:28","url":"always-declare-a-media-type-in-your-css-links","tags":["web","html","css"],"comments":[{"name":"ajbis","website":"http:\/\/www.ajbis.co.uk","comment":"funky","created":"2010-07-08 11:14:54"}]},{"title":"Context switching in the 18th Century","content":"<p>Something we've been trying to cut down on at work is the amount of context switching that the development team have to do. Rather than working on multiple projects at once, we've been trying to get them onto one project that they can concentrate on all day.<\/p>\r\n\r\n<p>The reason we do this is we think there's a cognitive cost of changing what you're doing. It's obvious, and it's not a new observation:<\/p>\r\n\r\n<blockquote>\r\n<p>A man commonly saunters a little in turning his hand from one sort of employment to another. When he first begins the new work, he is seldom very keen and hearty; his mind, as they say, does not go to it, and for some time he rather trifles than applies to good purpose. The habit of sauntering, and of indolent careless application, which is naturally, or rather necessarily, acquired by every country workman who is obliged to change his work and his tools every half hour, and to apply his hand in twenty different ways almost every day of his life, renders him almost always slothful and lazy, and incapable of any vigorous application, even on the most pressing occasions. Independent, therefore, of his deficiency in point of dexterity, this cause alone must always reduce considerably the quantity of work which he is capable of performing.<\/p>\r\n<p><cite>Adam Smith - The Wealth of Nations (1776)<\/cite><\/p>\r\n<\/blockquote>\r\n\r\n<p>It amazes me when people say \"Can't you just work on both things at once?\" but it's very common in some workplaces. I guess some things take a few centuries to sink in.<\/p>","created":"2010-07-09 10:20:39","url":"context-switching-in-the-18th-century","tags":["agile"],"comments":[{"name":"Russell","website":"http:\/\/rdjs.co.uk","comment":"Imagine doing the washing up then half way through someone asks you to do the hoovering. \r\nYou dry your hands, get the hoover out, plug it it in. \r\nThen half way through hoovering someone asks you to do the ironing. \r\nYou unplug the hoover and put it away, get the iron out wait for it to heat up. \r\nBy this time the water in the washing up has gone cold and you need to run the water again.\r\n\r\nIn any other context people can understand the need for finishing a task and only doing the most urgent thing at any one time. \r\nPerhaps because non-technical people don't understand the amount of mental effort it takes to switch between projects they are unable to appreciate that the same applies to web development.\r\n\r\nA solid development process and a good project \/ product manager should shield the dev team from most of these interruptions.","created":"2010-07-09 13:11:05"}]},{"title":"Top 5 Barclays Cycle Hire tips","content":"<p>It's been a couple of months now since the Barclays Cycle Hire scheme (a.k.a. Boris Bikes) launched here in London. I've used it nearly every day since then and picked up a few tricks along the way. Here are my top five tips for making the most of the scheme.<\/p>\r\n\r\n<div class=\"figure\">\r\n<a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/5096914181\/\" title=\"Hire bikes at Waterloo by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm5.static.flickr.com\/4132\/5096914181_0c6ae6eb8f.jpg\" width=\"500\" height=\"375\" alt=\"Hire bikes at Waterloo\" \/><\/a>\r\n<\/div>\r\n\r\n<h5>1. Get a mobile application<\/h5>\r\n\r\n<p>The main problem with the scheme since  it launched has been the lack of bikes at the docks when you need one, and the lack of spaces when you're out and about.<\/p>\r\n\r\n<p>Having a mobile app that lets you find the docking stations in the move makes a huge difference to how you use the scheme. While on my train to work I can decide whether there are bikes at the three docks near Vauxhall, or stay on the train to aim at one of the five docks near Waterloo.<\/p>\r\n\r\n<p>I have an iPhone and really love the <a href=\"http:\/\/cyclehireapp.com\/\">Cycle Hire App<\/a>.  It's completely free, not even ad supported, and the author keeps updating it with more and more features.  I particularly appreciate the preset 25-minute timer that let's you know when it's time to find a dock before you get charged!<\/p>\r\n\r\n<p>My Android-using friends assure me there are apps on the marketplace that are just a good.<\/p>\r\n\r\n<h5>2. Bounce the bike to release it<\/h5>\r\n\r\n<p>Stand near the docking stations in the morning and you'll see hoards of people huffing and puffing trying to tug their bikes out of the docks. However, there IS A BETTER WAY.<\/p>\r\n\r\n<p>When you have your green light, lift the back of the bike about 4-5cm and let it drop, the bike will bounce right out of the dock without any effort on your part.<\/p>\r\n\r\n<p>I was one of the tuggers before I saw someone use this method and now I'm a total convert. <\/p>\r\n\r\n<h5>3. Check the bike before you undock<\/h5>\r\n\r\n<p>So far the bikes I've ridden have mostly been in good nick, and I've certainly not seen many broken ones staying unrepaired, but it's worth giving the bike the once-over before taking it out.<\/p>\r\n\r\n<p>If you undock the bike before you notice something wrong, it can take about 5-10 minutes from the time you put it back before you can take another bike out of the system so it's very important to find any faults first. <\/p>\r\n\r\n<p>The main thing to check is the back wheel. If you do nothing else, do this! Lift the back of the bike and give the wheel a quick spin to check it's spinning freely. Quite a few of the bikes seem to have a lot of friction on the back wheel, possibly due to badly adjusted brakes, and will only turn a couple of times before coming to a complete stop. You should make sure that the wheel can keep spinning relatively freely. You seriously notice the difference after a couple of miles!<\/p>\r\n\r\n<p>Check the pedals are ok, a relatively common fault seems to be someone smashing the kickstand into the pedal and leaving it dangling half off so that it falls off for the unsuspecting cyclist halfway down the road. <\/p>\r\n\r\n<p>Lastly, have a quick check of the handlebar grips. If one is starting to work its way off, the best way to get it back on is to smack it hard on the end with an open hand.<\/p>\r\n\r\n<h5>4. Adjust the saddle<\/h5>\r\n\r\n<p>Learn to use the saddle adjust, I've seen people put their bikes back and press the repair light because they couldn't work out how to stop it dropping down. A complete waste of time for them and for the poor repair teams.<\/p>\r\n\r\n<p>The proper height for the saddle is probably a bit higher than what you expect. Most people shouldn't be able to put both feet on the ground at once. The key is that when you're pedalling you want your legs to be extending fully at the bottom of the rotation, otherwise you're only tiring yourself out.<\/p>\r\n\r\n<h5>5. Be safe<\/h5>\r\n\r\n<p>Not so much a tip, but vital advice. Hire bikes are a fantastic way to get from A to B, but please don't hop on one after 20 years of not cycling and try to make your way along main roads.<\/p>\r\n\r\n<p>Getting comfortable cycling in traffic is something that takes time and experience so it's a good idea to stick to side streets if the last time you got on a bike it had spokey-dokeys on the wheels.<\/p>\r\n\r\n<p>My top safety tips for commuters:<\/p>\r\n\r\n<ul>\r\n<li>Look around you. Lots of the new hire cyclists don't seem to ever look over their shoulder to check if there's a big truck coming before they do a spectacularly dangerous turn. Don't be one of them.<\/li>\r\n<li>Do hand signals in plenty of time. Just jabbing your hand in the vague direction as you do the turn isn't good enough. If you are one of these people who can't actually control the bike without two hands on the wheel, practice a bit first<\/li>\r\n<li>Match the speed of traffic. This means keep up with the flow, but also means don't zoom ahead. If you're at a relatively stable speed with respect to the traffic flow everyone knows where you are and can keep track of you. <\/li>\r\n<li>On the other hand don't push yourself too hard when things get tough, a knackered cyclist is less in control.<\/li>\r\n<\/ul>\r\n\r\n\r\n\r\n","created":"2010-10-19 20:02:22","url":"top-5-barclays-cycle-hire-tips"},{"title":"Using partial mocks in PHPUnit to test tricky code ","content":"<p>At work we've been going through the fairly painful process of adding unit tests to existing code. I'd like to share one technique I've found useful, a way of testing methods that at first glance look like they have too many dependencies to easily get under test.\r\n\r\n<p>I'll be giving these examples in PHPUnit but any xUnit framework should be able to do something similar.\r\n\r\n<p>Consider a method like the following, which is the sort of thing you might have trouble seeing how to test:\r\n\r\n<p><code><pre>\r\nclass MyClass\r\n{\r\n    public function getDataAndPublishRemotely()\r\n    {\r\n        $data = DataStore::getUnpublishedData();\r\n        \r\n        $service = new SoapClient($SOME_WSDL);\r\n        $service-&gt;publish(preg_replace('\/[^0-9a0z]+\/', '', $data));\r\n    }\r\n} \r\n<\/pre><\/code><\/p>\r\n\r\n<p>So this is doing some sort of DB call, then calling a SOAP service and publishing a cleaned-up version of the result. What makes this hard to test is the fact it's got two solid dependencies - a static call to some sort of DataStore layer and a direct instance of a SoapClient class.\r\n\r\n<p>Eventually the way to fix this sort of thing is to inject both of those dependencies separately, but that's too big a refactoring to tackle straight away. When you're modifying a class to get it under test you want to do small, easy-to-understand changes and get it under test ASAP.\r\n\r\n<p>One approach to getting it tested is to split the functionality that you think you can test into a separate method, like so:\r\n\r\n<p><code><pre>\r\nclass MyClass\r\n{\r\n    public function getDataAndPublishRemotely()\r\n    {\r\n        $data = DataStore::getUnpublishedData();\r\n        $cleanData = $this-&gt;processData($data);\r\n        \r\n        $service = new SoapClient($SOME_WSDL);\r\n        $service-&gt;publish($cleanData);\r\n    }\r\n    \r\n    public function processData($data)\r\n    {\r\n        return preg_replace('\/[^0-9a0z]+\/', '', $data);\r\n    }\r\n}\r\n<\/pre><\/code><\/p>\r\n\r\n<p>Testing that functionality becomes pretty simple:\r\n\r\n<p><code><pre>\r\nclass MyClassTest extends PHPUnit_Framework_Testcase\r\n{\r\n    public function testProcessData()\r\n    {\r\n        $data = ' hel123lo wo00rld    ';\r\n        $class = new MyClass();\r\n        \r\n        $result = $class-&gt;processData();\r\n        \r\n        $this-&gt;assertSame('hello world', $data);\r\n    }\r\n}\r\n<\/pre><\/code><\/p>\r\n\r\n<p>However there are a few things wrong with this approach, in my opinion. The first is that the new method has had to be public to be tested, so we've fundamentally changed the API of the class just for testing. The second is that we're not actually running the method we started off trying to test, which is unsatisfying. Thirdly, we're not aware whether the method is accessing the datastore or soap service at all, we're only testing the small bit of functionality we split off.\r\n\r\n<p>A better refactoring of the original class is to instead of splitting out the bits easy to test, split out the bits that are hard to test like so:\r\n\r\n<p><code><pre>\r\nclass MyClass\r\n{\r\n    public function getDataAndPublishRemotely()\r\n    {\r\n        $data = $this-&gt;_getUnpublishedDataFromDatastore();\r\n        $cleanData = preg_replace('\/[^0-9a0z]+\/', '', $data);\r\n        $this-&gt;_publishDataRemotely($cleanData);\r\n    }\r\n    \r\n    protected function _getUnpublishedDataFromDatastore()\r\n    {\r\n        return DataStore::getUnpublishedData();\r\n    }\r\n    \r\n    protected function _publishDataRemotely($data)\r\n    {\r\n        $service = new SoapClient($SOME_WSDL);\r\n        $service-&gt;publish($data);\r\n    }\r\n}\r\n<\/pre><\/code><\/p>\r\n\r\n<p>It's important to note, I suppose, that this is longer than the original class! However, the API of the class hasn't changed, and all of the dependencies have been removed from the method we're interested in. The small additional methods that have been generated can be refactored out later, the point is to do this simple change and get the system under test as soon as possible, then we can do our subsequent refactoring with a safety net in place.\r\n\r\n<p>If you have an IDE that can do refactorings like this (Extract Method) for you, then use the features! It's easy to make a mistake in even a little refactoring like this one and you should be very nervous about untested code.\r\n\r\n<p>To test the class we need to replace the two protected functions. One way of doing that would be to write a concrete MyTestableClass that extends MyClass and replace those methods and test that instead, but we can achieve effectively the same thing in PHPUnit using Partial Mocks. A partial mock is one that behaves exactly like the original class except when certain specific methods are called.\r\n\r\n<p>The test for the class could therefore look something like the following, note that all of the testing is done via expectations on the mock rather than via assertions:\r\n\r\n<p><code><pre>\r\nclass MyClassTest extends PHPUnit_Framework_Testcase\r\n{\r\n\r\n    public function testGetDataAndPublishRemotely()\r\n    {\r\n        $class = $this-&gt;getMock('MyClass', \r\n            array('_getUnpublishedDataFromDatastore', '_publishDataRemotely'));\r\n        \r\n        $class-&gt;expects($this-&gt;once())\r\n            -&gt;method('_getUnpublishedDataFromDatastore')\r\n            -&gt;will($this-&gt;returnValue(' hel123lo wo00rld    '));\r\n            \r\n        $class-&gt;Expects($this-&gt;once())\r\n            -&gt;method('_publishDataRemotely')\r\n            -&gt;with($this-&gt;equalTo('hello world'));\r\n        \r\n        $class-&gt;getDataAndPublishRemotely();\r\n    }\r\n\r\n}\r\n<\/pre><\/code><\/p>\r\n\r\n<p>A purist might say that's testing too much in one test and should be decomposed into different tests, but it's concise enough for me. Note we're testing more than the previous example, which only tested the string cleanup. In this test we are testing:\r\n\r\n<ul>\r\n<li>The string processing<\/li>\r\n<li>The fact it requests the data from the DB<\/li>\r\n<li>The fact it subsequently tries to publish the data<\/li>\r\n<\/ul>\r\n\r\n<p>This isn't the end of the story, because testing a mock seems a bit wrong, and it would be nice to clear up those dependencies properly. The point is that we've done the simplest thing necessary to get the method into a test harness, and subsequent refactorings can all be done with the test suite in place giving you the developer additional confidence to make changes.","created":"2011-04-30 11:21:57","url":"using-partial-mocks-in-phpunit-to-test-tricky-code ","tags":["php","unit-testing"],"comments":[{"name":"stephan","website":"","comment":"how do i mock a class and still have access to its constants.\r\n\r\nclass MockMePlz {\r\n\r\n const DOG = 'dog';\r\n const CAT = 'cat';\r\n\r\n public function getSome( $str ) {\r\n   if( $str == self::DOG) return 'its a dog';\r\n   if( $str == self::CAT) return 'its a cat';\r\n   return false;\r\n }\r\n}\r\n\r\nclass myclass{\r\n\r\n public function getCat() {\r\n   $class = new MockMePlz();\r\n   return $class->getSome( MockMePlz::CAT );\r\n }\r\n}\r\n\r\nclass MyClassTest extends PHPUnit_Framework_Testcase\r\n{\r\n\r\n public function testGetCat() {\r\n   \r\n }\r\n}","created":"2011-06-14 12:50:27"},{"name":"Ciaran McNulty","website":"http:\/\/ciaranmcnulty.com","comment":"@Stephan,\r\n\r\nBecause the mock extends MockMePlz you'd need to use static:: rather than self::","created":"2011-07-05 16:52:08"}]},{"title":"Use labelled groups in Regular Expressions for clearer code","content":"<p>I keep seeing this sort of pattern in PHP code, when people match on Regular Expressions:\r\n\r\n<p><code><pre>\r\n$orderNumber = 'CLK-TEST001-030';\r\n$pattern = '\/([a-z]+)-([a-z]+([0-9]+))?-([0-9]+)\/i';\r\n\r\nif (preg_match($pattern , $orderNumber, $matches)) {\r\n    echo \"Prefix was \".$matches[1].\" and duration was \".$matches[4];\r\n} \r\n<\/pre><\/code><\/p>\r\n\r\n<p>The problem here is that the numbers 4 and 1 are kind of cryptic. Furthermore if the expression changes in future I'll probably need to go through my code and redo the numbering.\r\n\r\n<p>A better alternative is to name the groups inside the expression:\r\n\r\n<p><code><pre>\r\n$orderNumber = 'CLK-TEST001-030';\r\n$pattern = '\/(?&lt;prefix&gt;[a-z]+)-([a-z]+([0-9]+))?-(?&lt;duration&gt;[0-9]+)\/i';\r\n\r\nif (preg_match($pattern , $orderNumber, $matches)) {\r\n    echo \"Prefix was \".$matches['prefix'].\r\n        \" and duration was \".$matches['duration'];\r\n} \r\n<\/pre><\/code><\/p>\r\n\r\n<p>This way if the expression gets changed, I can still use the same named fields in my matches in the subsequent code.\r\n\r\n<p>I don't know why this isn't done more often, except perhaps poor documentation means that people just aren't aware of it?\r\n\r\n\r\n","created":"2011-05-12 15:22:18","url":"use-labelled-groups-in-regular-expressions-for-clearer-code","tags":["php"],"comments":[{"name":"Simon Harris","website":"http:\/\/pointbeing.net\/","comment":"A useful tip indeed. It's worth noting that you still get the numerical as well as the labeled one - so one possible gotcha is that if you rely on count()ing $matches to see how many you got, you'll get misleading results.","created":"2011-06-15 16:21:16"}]},{"title":"A great customer service experience from Amazon","content":"<p>I got a Kindle around the start of the year, and I guess it's something I could write about separately but I'm fairly sure it's the device I've had that I've got the best entertainment value out of in terms of cost per pound.<\/p>\r\n\r\n<p>If you've seen the ads, you'll come away with the impression that the Kindle can be <a href=\"http:\/\/www.youtube.com\/watch?v=uLg817U9URM\">shoved in a draw, licked by a dog<\/a> and generally thrown around the place so that's how I treated mine.<\/p>\r\n\r\n<p>Last week I was talking about the Kindle to some workmates and really praised its rugged form and overall resilience - in retrospect it was asking for trouble. The very next morning I took it out of my bag and saw it looking like this:<\/p>\r\n\r\n<p><a href=\"http:\/\/www.flickr.com\/photos\/ciaranmcnulty\/5904816848\/\" title=\"Broken Kindle by CiaranJMcNulty, on Flickr\"><img src=\"http:\/\/farm7.static.flickr.com\/6011\/5904816848_b99d43a2b7.jpg\" width=\"374\" height=\"500\" alt=\"Broken Kindle\"><\/a><\/p>\r\n\r\n<p>My heart sank - what were the odds that Amazon would be able to honour that as a repair? It's fairly clear that it's been knocked around in my bag or something and the screen has failed.<\/p>\r\n\r\n<p>I thought I'd give it a punt anyway and rang Kindle Support. My first experience was not good - the lady on the other end of the line seemed to have trouble understanding me, and took me through a fairly silly 'turn it off and on again' routine. I then got put on hold for a few minutes during which I made <a href=\"http:\/\/twitter.com\/#!\/CiaranMcNulty\/status\/88166417123385344\">this angry tweet<\/a>.<\/p>\r\n\r\n<p>However as soon as I got put through to second line support, the whole process was a revelation! Even though I was honest about not having a case and the fact it was clearly damaged from being in my bag, Amazon are sending me a new Kindle immediately which will be here Thursday, after which I have to return the broken one in the box provided.<\/p>\r\n\r\n<p>I felt a bit embarrassed about the tweet so <a href=\"http:\/\/twitter.com\/#!\/CiaranMcNulty\/status\/88167696931364865\">tried to correct it<\/a>.<\/p>\r\n\r\n\r\n<p>What other hardware companies are this accommodating? Not many I'd warrant so a big thumbs up to Amazon from me. <\/p>\r\n\r\n<p>(Just hope they launch library lending soon in the UK!)<\/p>","created":"2011-07-05 13:04:37","url":"a-great-customer-service-experience-from-amazon","tags":["hardware","kindle"],"comments":[{"name":"Craig McGill","website":"http:\/\/www.contently-managed.com","comment":"I had a similar experience with them - case was cracked and I got in touch. While I thought the guy was just chatting for extra details he was actually organising a replacement Kindle for me. Top stuff (though reorganising all  my books was a nightmare).","created":"2011-07-05 13:15:13"},{"name":"Russell","website":"http:\/\/rdjs.co.uk","comment":"Everyone I know who has a Kindle loves it but for some reason I have absolutely no desire to get one. Call me a Luddite but I just love proper books. They have an irreplaceable tactile quality. I have heard all the arguments as to why they are better but remain unconvinced. I will no doubt crumble one day and end up buying one but for now I am happy with my traditional books, with their indefinite battery life and their smash-proof front covers. ;)","created":"2011-07-05 13:17:20"},{"name":"Ciaran McNulty","website":"http:\/\/ciaranmcnulty.com","comment":"@Russell I still like paper books but having a 'mixed' approach with some stuff on Kindle is best for me at the moment.\r\n\r\nKindle offers cloudyness, portability, compactness (it's smaller\/thinner than a book) so is perfect for my commute.\r\n\r\nReal books offer a better tactile experience, and much better flicking-back-and-forth so are a lot better for reading in a leisurely reading context.\r\n\r\nBottom line for me is that the Kindle has got me reading more books, which I think has to be a good thing!","created":"2011-07-05 13:22:36"},{"name":"Russell","website":"http:\/\/rdjs.co.uk","comment":"If kindle is encouraging people to read more then I am all for it. ","created":"2011-07-05 13:45:07"},{"name":"James","website":"","comment":"@Russell I like proper CD's still - all music that I buy is still a CD - but can't remember the last time (other than to rip a copy) that I actually put one in a CD player to play. I'm sure I'll come around soon and just buy digital versions, but at the moment, I still get the thrill of opening a CD, looking at the sleeve and art work, then adding it into the dusty collection on the shelf.\r\n\r\nBut I think kindle is to books what mp3s are to music.","created":"2011-07-05 17:53:55"}]},{"title":"Disabling comments on this blog","content":"<p>I'm getting really high volumes of comment spam at the moment, and don't really have the time to try and work out how they're evading the reCAPTCHA on the comments form, so I'm just turning it off for now.\r\n\r\n<p>I'm also in the process of thinking about what to do with this site, given that I'm not updating too regularly, I tend to stick to one-liners on Twitter a lot more, recently.","created":"2011-10-09 13:42:32","url":"disabling-comments-on-this-blog"},{"title":"Unix tips: handling script output","content":"<p>Wow I've not blogged in ages! Here's a couple of quickies that I seem to rediscover every 6 months and promptly forget - hopefully writing them here will make them stick in my head.\r\n\r\n<h4>Logging output to disk<\/h4>\r\n\r\n<p>Obviously to log the output of some process to disk you'd normally use <tt>&gt;<\/tt> or <tt>&gt;&gt;<\/tt>. However, sometimes you want to also use the output for some other process.\r\n\r\n<p>In instances like this you'd use <tt>tee<\/tt>:<\/p>\r\n\r\n<p><code><pre>\r\nphp my-script.php | tee -a \/var\/log\/my-script.log | other-script\r\n<\/pre><\/code>\r\n\r\n<p>The output of my my-script.php will be both written to my my-script.log, and piped to other-script for further processing (the -a flag means the output is appended to the log rather than it being overwritten).\r\n\r\n<h4>Emailing output when something happens<\/h4>\r\n\r\n<p>The <tt>mail<\/tt> command provides a simple way to mail the output of a script:\r\n\r\n<p><code><pre>\r\nphp myscript.php | mail -s \"A subject line\" address@example.com\r\n<\/pre><\/code>\r\n\r\n<p>However this gets annoying when your script runs every 5 minutes, so more recent implementations of <tt>mail<\/tt> have a <tt>-E<\/tt> flag that only sends the mail if the output wasn't empty:\r\n\r\n<p><code><pre>\r\nphp myscript.php 2&amp;&gt;1 | mail -E -s \"A subject line\" address@example.com\r\n<\/pre><\/code>\r\n\r\n<p>In this example the mail will only be sent if myscript.php output something (or an error, the 2&amp;&gt;1 redirects its error output to its standard output).\r\n\r\n<p>Unfortunately commenting is currently disabled, so hit me on twitter @CiaranMcNulty if you have any other tips for what to do with output and I'll maybe write a follow-up article.\r\n\r\n\r\n","created":"2012-01-06 11:28:55","url":"unix-tips-handing-script-output"},{"title":"Faster failing Unit Tests","content":"<p>One of the things about unit tests is that if they're going to fail, it's best if they fail quickly.\r\n\r\n<p>(This is also a key element of Scrum and other Agile approaches - if you're going to fail, do it as early as possible).\r\n\r\n<p>I was listening to <a href=\"http:\/\/www.se-radio.net\/2010\/09\/episode-167-the-history-of-junit-and-the-future-of-testing-with-kent-beck\/\">this old episode of Software Engineering Radio<\/a> and in it Kent Beck made the following observations:\r\n\r\n<ol>\r\n<li>Ideally you want to run the tests most likely to fail first, so that you get faster feedback\r\n<li>Statistically the most likely tests to fail are the ones that failed recently (i.e. if a test hasn't failed for a while it's less likely to fail next time).\r\n<\/ol>\r\n\r\n<p>This really clicked with me, especially for things like CI, so I knocked up the following hacky script to run my phpunit tests through:\r\n\r\n<p><code><pre>\r\n&lt;?php\r\n\r\n$run_full = true;\r\n\r\nif (file_exists('last_run_report.xml')) {\r\n    \r\n    $failures = array();\r\n    $xml = simplexml_load_file('last_run_report.xml');\r\n    \r\n    if ($res = $xml-&gt;xpath('\/\/error\/..\/@file')) {\r\n        foreach ($res as $file) {\r\n            $failures[] = (string)$file;\r\n        }\r\n    }\r\n\r\n    if ($failures) {\r\n        echo 'PREVIOUSLY FAILING TESTS', PHP_EOL;\r\n        echo '------------------------', PHP_EOL;\r\n        passthru('phpunit '.join(' ', $failures), $exit);\r\n        \r\n        if ($exit &gt; 0) { \r\n            $run_full = false; \r\n        }\r\n        else {\r\n            echo PHP_EOL;\r\n            echo 'FULL TEST SUITE', PHP_EOL;\r\n            echo '---------------', PHP_EOL;\r\n        }\r\n    }\r\n}\r\n\r\nif($run_full){\r\n    passthru('phpunit --log-junit last_run_report.xml');\r\n}\r\n<\/pre><\/code><\/p>\r\n\r\n<p>When I use this to run my test suite instead of straight phpunit, it results in a local file called last_run_report.xml being generated. Next time I run the report, if there were any errors, the report is parsed and the failing tests are executed first.\r\n\r\n<p>This is <em>really primitive<\/em> but is already saving me a little time. The next step would be to get a DB involved and maybe log the last few executions of the current suite, to get some stats on how unstable tests have been over the last few executions and prioritise them that way.\r\n\r\n<p>I'm sure there's a bunch of other analysis you could do to work out statistically which tests are likely to fail - you could even do some sort of static code analysis and work out which tests have ben potentially impacted since the last test run.\r\n\r\n<p>I'll be running this little script locally for now, but with an eye to including it in our CI environment once I've a bit more confidence that it's a valid approach.","created":"2012-02-08 09:16:36","url":"faster-failing-unit-tests","tags":["php","unit-testing"]}]